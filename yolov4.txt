Topologically Sorted ONNX Graph:

** Node: StatefulPartitionedCall/model/conv2d/Conv2D__46 | OpType: Transpose] **
  Inputs:
    input_1:0: dtype=FLOAT, shape=[4, 416, 416, 3], mreq=8,306,688
  Outputs:
StatefulPartitionedCall/model/conv2d/Conv2D__46:0
    StatefulPartitionedCall/model/conv2d/Conv2D__46:0: dtype=FLOAT, shape=[4, 3, 416, 416], mreq=8,306,688
  Node Mreq: 16,613,376 bytes

** Node: Transpose__1378 | OpType: Reshape] **
  Inputs:
    Reshape__1345:0: dtype=FLOAT, shape=[1, 1, 1, 1], mreq=4
    new_shape__2067: dtype=INT64, shape=[4], mreq=32
  Outputs:
Transpose__1378:0
    Transpose__1378:0: dtype=FLOAT, shape=[1, 1, 1, 1], mreq=4
  Node Mreq: 40 bytes

** Node: StatefulPartitionedCall/model/conv2d/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/conv2d/Conv2D__46:0: dtype=FLOAT, shape=[4, 3, 416, 416], mreq=8,306,688
    StatefulPartitionedCall/model/conv2d/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[32, 3, 3, 3], mreq=3,456
    StatefulPartitionedCall/model/conv2d/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[32], mreq=128
  Outputs:
StatefulPartitionedCall/model/batch_normalization/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 32, 416, 416], mreq=88,604,672
  Node Mreq: 96,914,944 bytes

** Node: StatefulPartitionedCall/model/lambda/Exp | OpType: Exp] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 32, 416, 416], mreq=88,604,672
  Outputs:
StatefulPartitionedCall/model/lambda/Exp:0
    StatefulPartitionedCall/model/lambda/Exp:0: dtype=FLOAT, shape=[4, 32, 416, 416], mreq=88,604,672
  Node Mreq: 177,209,344 bytes

** Node: StatefulPartitionedCall/model/lambda/add | OpType: Add] **
  Inputs:
    Transpose__1378:0: dtype=FLOAT, shape=[1, 1, 1, 1], mreq=4
    StatefulPartitionedCall/model/lambda/Exp:0: dtype=FLOAT, shape=[4, 32, 416, 416], mreq=88,604,672
  Outputs:
StatefulPartitionedCall/model/lambda/add:0
    StatefulPartitionedCall/model/lambda/add:0: dtype=FLOAT, shape=[4, 32, 416, 416], mreq=88,604,672
  Node Mreq: 177,209,348 bytes

** Node: StatefulPartitionedCall/model/lambda/Log | OpType: Log] **
  Inputs:
    StatefulPartitionedCall/model/lambda/add:0: dtype=FLOAT, shape=[4, 32, 416, 416], mreq=88,604,672
  Outputs:
StatefulPartitionedCall/model/lambda/Log:0
    StatefulPartitionedCall/model/lambda/Log:0: dtype=FLOAT, shape=[4, 32, 416, 416], mreq=88,604,672
  Node Mreq: 177,209,344 bytes

** Node: StatefulPartitionedCall/model/lambda/Tanh | OpType: Tanh] **
  Inputs:
    StatefulPartitionedCall/model/lambda/Log:0: dtype=FLOAT, shape=[4, 32, 416, 416], mreq=88,604,672
  Outputs:
StatefulPartitionedCall/model/lambda/Tanh:0
    StatefulPartitionedCall/model/lambda/Tanh:0: dtype=FLOAT, shape=[4, 32, 416, 416], mreq=88,604,672
  Node Mreq: 177,209,344 bytes

** Node: StatefulPartitionedCall/model/lambda/mul | OpType: Mul] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 32, 416, 416], mreq=88,604,672
    StatefulPartitionedCall/model/lambda/Tanh:0: dtype=FLOAT, shape=[4, 32, 416, 416], mreq=88,604,672
  Outputs:
StatefulPartitionedCall/model/lambda/mul:0
    StatefulPartitionedCall/model/lambda/mul:0: dtype=FLOAT, shape=[4, 32, 416, 416], mreq=88,604,672
  Node Mreq: 265,814,016 bytes

** Node: StatefulPartitionedCall/model/conv2d_1/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/lambda/mul:0: dtype=FLOAT, shape=[4, 32, 416, 416], mreq=88,604,672
    StatefulPartitionedCall/model/conv2d_1/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[64, 32, 3, 3], mreq=73,728
    StatefulPartitionedCall/model/conv2d_1/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[64], mreq=256
  Outputs:
StatefulPartitionedCall/model/batch_normalization_1/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_1/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 64, 208, 208], mreq=44,302,336
  Node Mreq: 132,980,992 bytes

** Node: StatefulPartitionedCall/model/lambda_1/Exp | OpType: Exp] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_1/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 64, 208, 208], mreq=44,302,336
  Outputs:
StatefulPartitionedCall/model/lambda_1/Exp:0
    StatefulPartitionedCall/model/lambda_1/Exp:0: dtype=FLOAT, shape=[4, 64, 208, 208], mreq=44,302,336
  Node Mreq: 88,604,672 bytes

** Node: StatefulPartitionedCall/model/lambda_1/add | OpType: Add] **
  Inputs:
    Transpose__1378:0: dtype=FLOAT, shape=[1, 1, 1, 1], mreq=4
    StatefulPartitionedCall/model/lambda_1/Exp:0: dtype=FLOAT, shape=[4, 64, 208, 208], mreq=44,302,336
  Outputs:
StatefulPartitionedCall/model/lambda_1/add:0
    StatefulPartitionedCall/model/lambda_1/add:0: dtype=FLOAT, shape=[4, 64, 208, 208], mreq=44,302,336
  Node Mreq: 88,604,676 bytes

** Node: StatefulPartitionedCall/model/lambda_1/Log | OpType: Log] **
  Inputs:
    StatefulPartitionedCall/model/lambda_1/add:0: dtype=FLOAT, shape=[4, 64, 208, 208], mreq=44,302,336
  Outputs:
StatefulPartitionedCall/model/lambda_1/Log:0
    StatefulPartitionedCall/model/lambda_1/Log:0: dtype=FLOAT, shape=[4, 64, 208, 208], mreq=44,302,336
  Node Mreq: 88,604,672 bytes

** Node: StatefulPartitionedCall/model/lambda_1/Tanh | OpType: Tanh] **
  Inputs:
    StatefulPartitionedCall/model/lambda_1/Log:0: dtype=FLOAT, shape=[4, 64, 208, 208], mreq=44,302,336
  Outputs:
StatefulPartitionedCall/model/lambda_1/Tanh:0
    StatefulPartitionedCall/model/lambda_1/Tanh:0: dtype=FLOAT, shape=[4, 64, 208, 208], mreq=44,302,336
  Node Mreq: 88,604,672 bytes

** Node: StatefulPartitionedCall/model/lambda_1/mul | OpType: Mul] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_1/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 64, 208, 208], mreq=44,302,336
    StatefulPartitionedCall/model/lambda_1/Tanh:0: dtype=FLOAT, shape=[4, 64, 208, 208], mreq=44,302,336
  Outputs:
StatefulPartitionedCall/model/lambda_1/mul:0
    StatefulPartitionedCall/model/lambda_1/mul:0: dtype=FLOAT, shape=[4, 64, 208, 208], mreq=44,302,336
  Node Mreq: 132,907,008 bytes

** Node: StatefulPartitionedCall/model/conv2d_3/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/lambda_1/mul:0: dtype=FLOAT, shape=[4, 64, 208, 208], mreq=44,302,336
    StatefulPartitionedCall/model/conv2d_3/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[64, 64, 1, 1], mreq=16,384
    StatefulPartitionedCall/model/conv2d_3/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[64], mreq=256
  Outputs:
StatefulPartitionedCall/model/batch_normalization_3/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_3/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 64, 208, 208], mreq=44,302,336
  Node Mreq: 88,621,312 bytes

** Node: StatefulPartitionedCall/model/conv2d_2/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/lambda_1/mul:0: dtype=FLOAT, shape=[4, 64, 208, 208], mreq=44,302,336
    StatefulPartitionedCall/model/conv2d_2/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[64, 64, 1, 1], mreq=16,384
    StatefulPartitionedCall/model/conv2d_2/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[64], mreq=256
  Outputs:
StatefulPartitionedCall/model/batch_normalization_2/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_2/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 64, 208, 208], mreq=44,302,336
  Node Mreq: 88,621,312 bytes

** Node: StatefulPartitionedCall/model/lambda_3/Exp | OpType: Exp] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_3/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 64, 208, 208], mreq=44,302,336
  Outputs:
StatefulPartitionedCall/model/lambda_3/Exp:0
    StatefulPartitionedCall/model/lambda_3/Exp:0: dtype=FLOAT, shape=[4, 64, 208, 208], mreq=44,302,336
  Node Mreq: 88,604,672 bytes

** Node: StatefulPartitionedCall/model/lambda_2/Exp | OpType: Exp] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_2/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 64, 208, 208], mreq=44,302,336
  Outputs:
StatefulPartitionedCall/model/lambda_2/Exp:0
    StatefulPartitionedCall/model/lambda_2/Exp:0: dtype=FLOAT, shape=[4, 64, 208, 208], mreq=44,302,336
  Node Mreq: 88,604,672 bytes

** Node: StatefulPartitionedCall/model/lambda_3/add | OpType: Add] **
  Inputs:
    Transpose__1378:0: dtype=FLOAT, shape=[1, 1, 1, 1], mreq=4
    StatefulPartitionedCall/model/lambda_3/Exp:0: dtype=FLOAT, shape=[4, 64, 208, 208], mreq=44,302,336
  Outputs:
StatefulPartitionedCall/model/lambda_3/add:0
    StatefulPartitionedCall/model/lambda_3/add:0: dtype=FLOAT, shape=[4, 64, 208, 208], mreq=44,302,336
  Node Mreq: 88,604,676 bytes

** Node: StatefulPartitionedCall/model/lambda_2/add | OpType: Add] **
  Inputs:
    Transpose__1378:0: dtype=FLOAT, shape=[1, 1, 1, 1], mreq=4
    StatefulPartitionedCall/model/lambda_2/Exp:0: dtype=FLOAT, shape=[4, 64, 208, 208], mreq=44,302,336
  Outputs:
StatefulPartitionedCall/model/lambda_2/add:0
    StatefulPartitionedCall/model/lambda_2/add:0: dtype=FLOAT, shape=[4, 64, 208, 208], mreq=44,302,336
  Node Mreq: 88,604,676 bytes

** Node: StatefulPartitionedCall/model/lambda_3/Log | OpType: Log] **
  Inputs:
    StatefulPartitionedCall/model/lambda_3/add:0: dtype=FLOAT, shape=[4, 64, 208, 208], mreq=44,302,336
  Outputs:
StatefulPartitionedCall/model/lambda_3/Log:0
    StatefulPartitionedCall/model/lambda_3/Log:0: dtype=FLOAT, shape=[4, 64, 208, 208], mreq=44,302,336
  Node Mreq: 88,604,672 bytes

** Node: StatefulPartitionedCall/model/lambda_2/Log | OpType: Log] **
  Inputs:
    StatefulPartitionedCall/model/lambda_2/add:0: dtype=FLOAT, shape=[4, 64, 208, 208], mreq=44,302,336
  Outputs:
StatefulPartitionedCall/model/lambda_2/Log:0
    StatefulPartitionedCall/model/lambda_2/Log:0: dtype=FLOAT, shape=[4, 64, 208, 208], mreq=44,302,336
  Node Mreq: 88,604,672 bytes

** Node: StatefulPartitionedCall/model/lambda_3/Tanh | OpType: Tanh] **
  Inputs:
    StatefulPartitionedCall/model/lambda_3/Log:0: dtype=FLOAT, shape=[4, 64, 208, 208], mreq=44,302,336
  Outputs:
StatefulPartitionedCall/model/lambda_3/Tanh:0
    StatefulPartitionedCall/model/lambda_3/Tanh:0: dtype=FLOAT, shape=[4, 64, 208, 208], mreq=44,302,336
  Node Mreq: 88,604,672 bytes

** Node: StatefulPartitionedCall/model/lambda_2/Tanh | OpType: Tanh] **
  Inputs:
    StatefulPartitionedCall/model/lambda_2/Log:0: dtype=FLOAT, shape=[4, 64, 208, 208], mreq=44,302,336
  Outputs:
StatefulPartitionedCall/model/lambda_2/Tanh:0
    StatefulPartitionedCall/model/lambda_2/Tanh:0: dtype=FLOAT, shape=[4, 64, 208, 208], mreq=44,302,336
  Node Mreq: 88,604,672 bytes

** Node: StatefulPartitionedCall/model/lambda_3/mul | OpType: Mul] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_3/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 64, 208, 208], mreq=44,302,336
    StatefulPartitionedCall/model/lambda_3/Tanh:0: dtype=FLOAT, shape=[4, 64, 208, 208], mreq=44,302,336
  Outputs:
StatefulPartitionedCall/model/lambda_3/mul:0
    StatefulPartitionedCall/model/lambda_3/mul:0: dtype=FLOAT, shape=[4, 64, 208, 208], mreq=44,302,336
  Node Mreq: 132,907,008 bytes

** Node: StatefulPartitionedCall/model/lambda_2/mul | OpType: Mul] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_2/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 64, 208, 208], mreq=44,302,336
    StatefulPartitionedCall/model/lambda_2/Tanh:0: dtype=FLOAT, shape=[4, 64, 208, 208], mreq=44,302,336
  Outputs:
StatefulPartitionedCall/model/lambda_2/mul:0
    StatefulPartitionedCall/model/lambda_2/mul:0: dtype=FLOAT, shape=[4, 64, 208, 208], mreq=44,302,336
  Node Mreq: 132,907,008 bytes

** Node: StatefulPartitionedCall/model/conv2d_4/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/lambda_3/mul:0: dtype=FLOAT, shape=[4, 64, 208, 208], mreq=44,302,336
    StatefulPartitionedCall/model/conv2d_4/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[32, 64, 1, 1], mreq=8,192
    StatefulPartitionedCall/model/conv2d_4/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[32], mreq=128
  Outputs:
StatefulPartitionedCall/model/batch_normalization_4/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_4/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 32, 208, 208], mreq=22,151,168
  Node Mreq: 66,461,824 bytes

** Node: StatefulPartitionedCall/model/lambda_4/Exp | OpType: Exp] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_4/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 32, 208, 208], mreq=22,151,168
  Outputs:
StatefulPartitionedCall/model/lambda_4/Exp:0
    StatefulPartitionedCall/model/lambda_4/Exp:0: dtype=FLOAT, shape=[4, 32, 208, 208], mreq=22,151,168
  Node Mreq: 44,302,336 bytes

** Node: StatefulPartitionedCall/model/lambda_4/add | OpType: Add] **
  Inputs:
    Transpose__1378:0: dtype=FLOAT, shape=[1, 1, 1, 1], mreq=4
    StatefulPartitionedCall/model/lambda_4/Exp:0: dtype=FLOAT, shape=[4, 32, 208, 208], mreq=22,151,168
  Outputs:
StatefulPartitionedCall/model/lambda_4/add:0
    StatefulPartitionedCall/model/lambda_4/add:0: dtype=FLOAT, shape=[4, 32, 208, 208], mreq=22,151,168
  Node Mreq: 44,302,340 bytes

** Node: StatefulPartitionedCall/model/lambda_4/Log | OpType: Log] **
  Inputs:
    StatefulPartitionedCall/model/lambda_4/add:0: dtype=FLOAT, shape=[4, 32, 208, 208], mreq=22,151,168
  Outputs:
StatefulPartitionedCall/model/lambda_4/Log:0
    StatefulPartitionedCall/model/lambda_4/Log:0: dtype=FLOAT, shape=[4, 32, 208, 208], mreq=22,151,168
  Node Mreq: 44,302,336 bytes

** Node: StatefulPartitionedCall/model/lambda_4/Tanh | OpType: Tanh] **
  Inputs:
    StatefulPartitionedCall/model/lambda_4/Log:0: dtype=FLOAT, shape=[4, 32, 208, 208], mreq=22,151,168
  Outputs:
StatefulPartitionedCall/model/lambda_4/Tanh:0
    StatefulPartitionedCall/model/lambda_4/Tanh:0: dtype=FLOAT, shape=[4, 32, 208, 208], mreq=22,151,168
  Node Mreq: 44,302,336 bytes

** Node: StatefulPartitionedCall/model/lambda_4/mul | OpType: Mul] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_4/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 32, 208, 208], mreq=22,151,168
    StatefulPartitionedCall/model/lambda_4/Tanh:0: dtype=FLOAT, shape=[4, 32, 208, 208], mreq=22,151,168
  Outputs:
StatefulPartitionedCall/model/lambda_4/mul:0
    StatefulPartitionedCall/model/lambda_4/mul:0: dtype=FLOAT, shape=[4, 32, 208, 208], mreq=22,151,168
  Node Mreq: 66,453,504 bytes

** Node: StatefulPartitionedCall/model/conv2d_5/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/lambda_4/mul:0: dtype=FLOAT, shape=[4, 32, 208, 208], mreq=22,151,168
    StatefulPartitionedCall/model/conv2d_5/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[64, 32, 3, 3], mreq=73,728
    StatefulPartitionedCall/model/conv2d_5/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[64], mreq=256
  Outputs:
StatefulPartitionedCall/model/batch_normalization_5/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_5/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 64, 208, 208], mreq=44,302,336
  Node Mreq: 66,527,488 bytes

** Node: StatefulPartitionedCall/model/lambda_5/Exp | OpType: Exp] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_5/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 64, 208, 208], mreq=44,302,336
  Outputs:
StatefulPartitionedCall/model/lambda_5/Exp:0
    StatefulPartitionedCall/model/lambda_5/Exp:0: dtype=FLOAT, shape=[4, 64, 208, 208], mreq=44,302,336
  Node Mreq: 88,604,672 bytes

** Node: StatefulPartitionedCall/model/lambda_5/add | OpType: Add] **
  Inputs:
    Transpose__1378:0: dtype=FLOAT, shape=[1, 1, 1, 1], mreq=4
    StatefulPartitionedCall/model/lambda_5/Exp:0: dtype=FLOAT, shape=[4, 64, 208, 208], mreq=44,302,336
  Outputs:
StatefulPartitionedCall/model/lambda_5/add:0
    StatefulPartitionedCall/model/lambda_5/add:0: dtype=FLOAT, shape=[4, 64, 208, 208], mreq=44,302,336
  Node Mreq: 88,604,676 bytes

** Node: StatefulPartitionedCall/model/lambda_5/Log | OpType: Log] **
  Inputs:
    StatefulPartitionedCall/model/lambda_5/add:0: dtype=FLOAT, shape=[4, 64, 208, 208], mreq=44,302,336
  Outputs:
StatefulPartitionedCall/model/lambda_5/Log:0
    StatefulPartitionedCall/model/lambda_5/Log:0: dtype=FLOAT, shape=[4, 64, 208, 208], mreq=44,302,336
  Node Mreq: 88,604,672 bytes

** Node: StatefulPartitionedCall/model/lambda_5/Tanh | OpType: Tanh] **
  Inputs:
    StatefulPartitionedCall/model/lambda_5/Log:0: dtype=FLOAT, shape=[4, 64, 208, 208], mreq=44,302,336
  Outputs:
StatefulPartitionedCall/model/lambda_5/Tanh:0
    StatefulPartitionedCall/model/lambda_5/Tanh:0: dtype=FLOAT, shape=[4, 64, 208, 208], mreq=44,302,336
  Node Mreq: 88,604,672 bytes

** Node: StatefulPartitionedCall/model/lambda_5/mul | OpType: Mul] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_5/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 64, 208, 208], mreq=44,302,336
    StatefulPartitionedCall/model/lambda_5/Tanh:0: dtype=FLOAT, shape=[4, 64, 208, 208], mreq=44,302,336
  Outputs:
StatefulPartitionedCall/model/lambda_5/mul:0
    StatefulPartitionedCall/model/lambda_5/mul:0: dtype=FLOAT, shape=[4, 64, 208, 208], mreq=44,302,336
  Node Mreq: 132,907,008 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_add/add | OpType: Add] **
  Inputs:
    StatefulPartitionedCall/model/lambda_3/mul:0: dtype=FLOAT, shape=[4, 64, 208, 208], mreq=44,302,336
    StatefulPartitionedCall/model/lambda_5/mul:0: dtype=FLOAT, shape=[4, 64, 208, 208], mreq=44,302,336
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_add/add:0
    StatefulPartitionedCall/model/tf_op_layer_add/add:0: dtype=FLOAT, shape=[4, 64, 208, 208], mreq=44,302,336
  Node Mreq: 132,907,008 bytes

** Node: StatefulPartitionedCall/model/conv2d_6/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_add/add:0: dtype=FLOAT, shape=[4, 64, 208, 208], mreq=44,302,336
    StatefulPartitionedCall/model/conv2d_6/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[64, 64, 1, 1], mreq=16,384
    StatefulPartitionedCall/model/conv2d_6/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[64], mreq=256
  Outputs:
StatefulPartitionedCall/model/batch_normalization_6/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_6/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 64, 208, 208], mreq=44,302,336
  Node Mreq: 88,621,312 bytes

** Node: StatefulPartitionedCall/model/lambda_6/Exp | OpType: Exp] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_6/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 64, 208, 208], mreq=44,302,336
  Outputs:
StatefulPartitionedCall/model/lambda_6/Exp:0
    StatefulPartitionedCall/model/lambda_6/Exp:0: dtype=FLOAT, shape=[4, 64, 208, 208], mreq=44,302,336
  Node Mreq: 88,604,672 bytes

** Node: StatefulPartitionedCall/model/lambda_6/add | OpType: Add] **
  Inputs:
    Transpose__1378:0: dtype=FLOAT, shape=[1, 1, 1, 1], mreq=4
    StatefulPartitionedCall/model/lambda_6/Exp:0: dtype=FLOAT, shape=[4, 64, 208, 208], mreq=44,302,336
  Outputs:
StatefulPartitionedCall/model/lambda_6/add:0
    StatefulPartitionedCall/model/lambda_6/add:0: dtype=FLOAT, shape=[4, 64, 208, 208], mreq=44,302,336
  Node Mreq: 88,604,676 bytes

** Node: StatefulPartitionedCall/model/lambda_6/Log | OpType: Log] **
  Inputs:
    StatefulPartitionedCall/model/lambda_6/add:0: dtype=FLOAT, shape=[4, 64, 208, 208], mreq=44,302,336
  Outputs:
StatefulPartitionedCall/model/lambda_6/Log:0
    StatefulPartitionedCall/model/lambda_6/Log:0: dtype=FLOAT, shape=[4, 64, 208, 208], mreq=44,302,336
  Node Mreq: 88,604,672 bytes

** Node: StatefulPartitionedCall/model/lambda_6/Tanh | OpType: Tanh] **
  Inputs:
    StatefulPartitionedCall/model/lambda_6/Log:0: dtype=FLOAT, shape=[4, 64, 208, 208], mreq=44,302,336
  Outputs:
StatefulPartitionedCall/model/lambda_6/Tanh:0
    StatefulPartitionedCall/model/lambda_6/Tanh:0: dtype=FLOAT, shape=[4, 64, 208, 208], mreq=44,302,336
  Node Mreq: 88,604,672 bytes

** Node: StatefulPartitionedCall/model/lambda_6/mul | OpType: Mul] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_6/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 64, 208, 208], mreq=44,302,336
    StatefulPartitionedCall/model/lambda_6/Tanh:0: dtype=FLOAT, shape=[4, 64, 208, 208], mreq=44,302,336
  Outputs:
StatefulPartitionedCall/model/lambda_6/mul:0
    StatefulPartitionedCall/model/lambda_6/mul:0: dtype=FLOAT, shape=[4, 64, 208, 208], mreq=44,302,336
  Node Mreq: 132,907,008 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_concat/concat | OpType: Concat] **
  Inputs:
    StatefulPartitionedCall/model/lambda_6/mul:0: dtype=FLOAT, shape=[4, 64, 208, 208], mreq=44,302,336
    StatefulPartitionedCall/model/lambda_2/mul:0: dtype=FLOAT, shape=[4, 64, 208, 208], mreq=44,302,336
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_concat/concat:0
    StatefulPartitionedCall/model/tf_op_layer_concat/concat:0: dtype=FLOAT, shape=[4, 128, 208, 208], mreq=88,604,672
  Node Mreq: 177,209,344 bytes

** Node: StatefulPartitionedCall/model/conv2d_7/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_concat/concat:0: dtype=FLOAT, shape=[4, 128, 208, 208], mreq=88,604,672
    StatefulPartitionedCall/model/conv2d_7/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[64, 128, 1, 1], mreq=32,768
    StatefulPartitionedCall/model/conv2d_7/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[64], mreq=256
  Outputs:
StatefulPartitionedCall/model/batch_normalization_7/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_7/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 64, 208, 208], mreq=44,302,336
  Node Mreq: 132,940,032 bytes

** Node: StatefulPartitionedCall/model/lambda_7/Exp | OpType: Exp] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_7/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 64, 208, 208], mreq=44,302,336
  Outputs:
StatefulPartitionedCall/model/lambda_7/Exp:0
    StatefulPartitionedCall/model/lambda_7/Exp:0: dtype=FLOAT, shape=[4, 64, 208, 208], mreq=44,302,336
  Node Mreq: 88,604,672 bytes

** Node: StatefulPartitionedCall/model/lambda_7/add | OpType: Add] **
  Inputs:
    Transpose__1378:0: dtype=FLOAT, shape=[1, 1, 1, 1], mreq=4
    StatefulPartitionedCall/model/lambda_7/Exp:0: dtype=FLOAT, shape=[4, 64, 208, 208], mreq=44,302,336
  Outputs:
StatefulPartitionedCall/model/lambda_7/add:0
    StatefulPartitionedCall/model/lambda_7/add:0: dtype=FLOAT, shape=[4, 64, 208, 208], mreq=44,302,336
  Node Mreq: 88,604,676 bytes

** Node: StatefulPartitionedCall/model/lambda_7/Log | OpType: Log] **
  Inputs:
    StatefulPartitionedCall/model/lambda_7/add:0: dtype=FLOAT, shape=[4, 64, 208, 208], mreq=44,302,336
  Outputs:
StatefulPartitionedCall/model/lambda_7/Log:0
    StatefulPartitionedCall/model/lambda_7/Log:0: dtype=FLOAT, shape=[4, 64, 208, 208], mreq=44,302,336
  Node Mreq: 88,604,672 bytes

** Node: StatefulPartitionedCall/model/lambda_7/Tanh | OpType: Tanh] **
  Inputs:
    StatefulPartitionedCall/model/lambda_7/Log:0: dtype=FLOAT, shape=[4, 64, 208, 208], mreq=44,302,336
  Outputs:
StatefulPartitionedCall/model/lambda_7/Tanh:0
    StatefulPartitionedCall/model/lambda_7/Tanh:0: dtype=FLOAT, shape=[4, 64, 208, 208], mreq=44,302,336
  Node Mreq: 88,604,672 bytes

** Node: StatefulPartitionedCall/model/lambda_7/mul | OpType: Mul] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_7/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 64, 208, 208], mreq=44,302,336
    StatefulPartitionedCall/model/lambda_7/Tanh:0: dtype=FLOAT, shape=[4, 64, 208, 208], mreq=44,302,336
  Outputs:
StatefulPartitionedCall/model/lambda_7/mul:0
    StatefulPartitionedCall/model/lambda_7/mul:0: dtype=FLOAT, shape=[4, 64, 208, 208], mreq=44,302,336
  Node Mreq: 132,907,008 bytes

** Node: StatefulPartitionedCall/model/conv2d_8/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/lambda_7/mul:0: dtype=FLOAT, shape=[4, 64, 208, 208], mreq=44,302,336
    StatefulPartitionedCall/model/conv2d_8/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[128, 64, 3, 3], mreq=294,912
    StatefulPartitionedCall/model/conv2d_8/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[128], mreq=512
  Outputs:
StatefulPartitionedCall/model/batch_normalization_8/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_8/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 128, 104, 104], mreq=22,151,168
  Node Mreq: 66,748,928 bytes

** Node: StatefulPartitionedCall/model/lambda_8/Exp | OpType: Exp] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_8/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 128, 104, 104], mreq=22,151,168
  Outputs:
StatefulPartitionedCall/model/lambda_8/Exp:0
    StatefulPartitionedCall/model/lambda_8/Exp:0: dtype=FLOAT, shape=[4, 128, 104, 104], mreq=22,151,168
  Node Mreq: 44,302,336 bytes

** Node: StatefulPartitionedCall/model/lambda_8/add | OpType: Add] **
  Inputs:
    Transpose__1378:0: dtype=FLOAT, shape=[1, 1, 1, 1], mreq=4
    StatefulPartitionedCall/model/lambda_8/Exp:0: dtype=FLOAT, shape=[4, 128, 104, 104], mreq=22,151,168
  Outputs:
StatefulPartitionedCall/model/lambda_8/add:0
    StatefulPartitionedCall/model/lambda_8/add:0: dtype=FLOAT, shape=[4, 128, 104, 104], mreq=22,151,168
  Node Mreq: 44,302,340 bytes

** Node: StatefulPartitionedCall/model/lambda_8/Log | OpType: Log] **
  Inputs:
    StatefulPartitionedCall/model/lambda_8/add:0: dtype=FLOAT, shape=[4, 128, 104, 104], mreq=22,151,168
  Outputs:
StatefulPartitionedCall/model/lambda_8/Log:0
    StatefulPartitionedCall/model/lambda_8/Log:0: dtype=FLOAT, shape=[4, 128, 104, 104], mreq=22,151,168
  Node Mreq: 44,302,336 bytes

** Node: StatefulPartitionedCall/model/lambda_8/Tanh | OpType: Tanh] **
  Inputs:
    StatefulPartitionedCall/model/lambda_8/Log:0: dtype=FLOAT, shape=[4, 128, 104, 104], mreq=22,151,168
  Outputs:
StatefulPartitionedCall/model/lambda_8/Tanh:0
    StatefulPartitionedCall/model/lambda_8/Tanh:0: dtype=FLOAT, shape=[4, 128, 104, 104], mreq=22,151,168
  Node Mreq: 44,302,336 bytes

** Node: StatefulPartitionedCall/model/lambda_8/mul | OpType: Mul] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_8/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 128, 104, 104], mreq=22,151,168
    StatefulPartitionedCall/model/lambda_8/Tanh:0: dtype=FLOAT, shape=[4, 128, 104, 104], mreq=22,151,168
  Outputs:
StatefulPartitionedCall/model/lambda_8/mul:0
    StatefulPartitionedCall/model/lambda_8/mul:0: dtype=FLOAT, shape=[4, 128, 104, 104], mreq=22,151,168
  Node Mreq: 66,453,504 bytes

** Node: StatefulPartitionedCall/model/conv2d_9/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/lambda_8/mul:0: dtype=FLOAT, shape=[4, 128, 104, 104], mreq=22,151,168
    StatefulPartitionedCall/model/conv2d_9/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[64, 128, 1, 1], mreq=32,768
    StatefulPartitionedCall/model/conv2d_9/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[64], mreq=256
  Outputs:
StatefulPartitionedCall/model/batch_normalization_9/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_9/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
  Node Mreq: 33,259,776 bytes

** Node: StatefulPartitionedCall/model/conv2d_10/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/lambda_8/mul:0: dtype=FLOAT, shape=[4, 128, 104, 104], mreq=22,151,168
    StatefulPartitionedCall/model/conv2d_10/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[64, 128, 1, 1], mreq=32,768
    StatefulPartitionedCall/model/conv2d_10/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[64], mreq=256
  Outputs:
StatefulPartitionedCall/model/batch_normalization_10/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_10/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
  Node Mreq: 33,259,776 bytes

** Node: StatefulPartitionedCall/model/lambda_9/Exp | OpType: Exp] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_9/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
  Outputs:
StatefulPartitionedCall/model/lambda_9/Exp:0
    StatefulPartitionedCall/model/lambda_9/Exp:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
  Node Mreq: 22,151,168 bytes

** Node: StatefulPartitionedCall/model/lambda_10/Exp | OpType: Exp] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_10/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
  Outputs:
StatefulPartitionedCall/model/lambda_10/Exp:0
    StatefulPartitionedCall/model/lambda_10/Exp:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
  Node Mreq: 22,151,168 bytes

** Node: StatefulPartitionedCall/model/lambda_9/add | OpType: Add] **
  Inputs:
    Transpose__1378:0: dtype=FLOAT, shape=[1, 1, 1, 1], mreq=4
    StatefulPartitionedCall/model/lambda_9/Exp:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
  Outputs:
StatefulPartitionedCall/model/lambda_9/add:0
    StatefulPartitionedCall/model/lambda_9/add:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
  Node Mreq: 22,151,172 bytes

** Node: StatefulPartitionedCall/model/lambda_10/add | OpType: Add] **
  Inputs:
    Transpose__1378:0: dtype=FLOAT, shape=[1, 1, 1, 1], mreq=4
    StatefulPartitionedCall/model/lambda_10/Exp:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
  Outputs:
StatefulPartitionedCall/model/lambda_10/add:0
    StatefulPartitionedCall/model/lambda_10/add:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
  Node Mreq: 22,151,172 bytes

** Node: StatefulPartitionedCall/model/lambda_9/Log | OpType: Log] **
  Inputs:
    StatefulPartitionedCall/model/lambda_9/add:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
  Outputs:
StatefulPartitionedCall/model/lambda_9/Log:0
    StatefulPartitionedCall/model/lambda_9/Log:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
  Node Mreq: 22,151,168 bytes

** Node: StatefulPartitionedCall/model/lambda_10/Log | OpType: Log] **
  Inputs:
    StatefulPartitionedCall/model/lambda_10/add:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
  Outputs:
StatefulPartitionedCall/model/lambda_10/Log:0
    StatefulPartitionedCall/model/lambda_10/Log:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
  Node Mreq: 22,151,168 bytes

** Node: StatefulPartitionedCall/model/lambda_9/Tanh | OpType: Tanh] **
  Inputs:
    StatefulPartitionedCall/model/lambda_9/Log:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
  Outputs:
StatefulPartitionedCall/model/lambda_9/Tanh:0
    StatefulPartitionedCall/model/lambda_9/Tanh:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
  Node Mreq: 22,151,168 bytes

** Node: StatefulPartitionedCall/model/lambda_10/Tanh | OpType: Tanh] **
  Inputs:
    StatefulPartitionedCall/model/lambda_10/Log:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
  Outputs:
StatefulPartitionedCall/model/lambda_10/Tanh:0
    StatefulPartitionedCall/model/lambda_10/Tanh:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
  Node Mreq: 22,151,168 bytes

** Node: StatefulPartitionedCall/model/lambda_9/mul | OpType: Mul] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_9/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
    StatefulPartitionedCall/model/lambda_9/Tanh:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
  Outputs:
StatefulPartitionedCall/model/lambda_9/mul:0
    StatefulPartitionedCall/model/lambda_9/mul:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
  Node Mreq: 33,226,752 bytes

** Node: StatefulPartitionedCall/model/lambda_10/mul | OpType: Mul] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_10/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
    StatefulPartitionedCall/model/lambda_10/Tanh:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
  Outputs:
StatefulPartitionedCall/model/lambda_10/mul:0
    StatefulPartitionedCall/model/lambda_10/mul:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
  Node Mreq: 33,226,752 bytes

** Node: StatefulPartitionedCall/model/conv2d_11/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/lambda_10/mul:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
    StatefulPartitionedCall/model/conv2d_11/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[64, 64, 1, 1], mreq=16,384
    StatefulPartitionedCall/model/conv2d_11/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[64], mreq=256
  Outputs:
StatefulPartitionedCall/model/batch_normalization_11/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_11/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
  Node Mreq: 22,167,808 bytes

** Node: StatefulPartitionedCall/model/lambda_11/Exp | OpType: Exp] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_11/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
  Outputs:
StatefulPartitionedCall/model/lambda_11/Exp:0
    StatefulPartitionedCall/model/lambda_11/Exp:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
  Node Mreq: 22,151,168 bytes

** Node: StatefulPartitionedCall/model/lambda_11/add | OpType: Add] **
  Inputs:
    Transpose__1378:0: dtype=FLOAT, shape=[1, 1, 1, 1], mreq=4
    StatefulPartitionedCall/model/lambda_11/Exp:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
  Outputs:
StatefulPartitionedCall/model/lambda_11/add:0
    StatefulPartitionedCall/model/lambda_11/add:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
  Node Mreq: 22,151,172 bytes

** Node: StatefulPartitionedCall/model/lambda_11/Log | OpType: Log] **
  Inputs:
    StatefulPartitionedCall/model/lambda_11/add:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
  Outputs:
StatefulPartitionedCall/model/lambda_11/Log:0
    StatefulPartitionedCall/model/lambda_11/Log:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
  Node Mreq: 22,151,168 bytes

** Node: StatefulPartitionedCall/model/lambda_11/Tanh | OpType: Tanh] **
  Inputs:
    StatefulPartitionedCall/model/lambda_11/Log:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
  Outputs:
StatefulPartitionedCall/model/lambda_11/Tanh:0
    StatefulPartitionedCall/model/lambda_11/Tanh:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
  Node Mreq: 22,151,168 bytes

** Node: StatefulPartitionedCall/model/lambda_11/mul | OpType: Mul] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_11/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
    StatefulPartitionedCall/model/lambda_11/Tanh:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
  Outputs:
StatefulPartitionedCall/model/lambda_11/mul:0
    StatefulPartitionedCall/model/lambda_11/mul:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
  Node Mreq: 33,226,752 bytes

** Node: StatefulPartitionedCall/model/conv2d_12/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/lambda_11/mul:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
    StatefulPartitionedCall/model/conv2d_12/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[64, 64, 3, 3], mreq=147,456
    StatefulPartitionedCall/model/conv2d_12/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[64], mreq=256
  Outputs:
StatefulPartitionedCall/model/batch_normalization_12/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_12/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
  Node Mreq: 22,298,880 bytes

** Node: StatefulPartitionedCall/model/lambda_12/Exp | OpType: Exp] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_12/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
  Outputs:
StatefulPartitionedCall/model/lambda_12/Exp:0
    StatefulPartitionedCall/model/lambda_12/Exp:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
  Node Mreq: 22,151,168 bytes

** Node: StatefulPartitionedCall/model/lambda_12/add | OpType: Add] **
  Inputs:
    Transpose__1378:0: dtype=FLOAT, shape=[1, 1, 1, 1], mreq=4
    StatefulPartitionedCall/model/lambda_12/Exp:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
  Outputs:
StatefulPartitionedCall/model/lambda_12/add:0
    StatefulPartitionedCall/model/lambda_12/add:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
  Node Mreq: 22,151,172 bytes

** Node: StatefulPartitionedCall/model/lambda_12/Log | OpType: Log] **
  Inputs:
    StatefulPartitionedCall/model/lambda_12/add:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
  Outputs:
StatefulPartitionedCall/model/lambda_12/Log:0
    StatefulPartitionedCall/model/lambda_12/Log:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
  Node Mreq: 22,151,168 bytes

** Node: StatefulPartitionedCall/model/lambda_12/Tanh | OpType: Tanh] **
  Inputs:
    StatefulPartitionedCall/model/lambda_12/Log:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
  Outputs:
StatefulPartitionedCall/model/lambda_12/Tanh:0
    StatefulPartitionedCall/model/lambda_12/Tanh:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
  Node Mreq: 22,151,168 bytes

** Node: StatefulPartitionedCall/model/lambda_12/mul | OpType: Mul] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_12/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
    StatefulPartitionedCall/model/lambda_12/Tanh:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
  Outputs:
StatefulPartitionedCall/model/lambda_12/mul:0
    StatefulPartitionedCall/model/lambda_12/mul:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
  Node Mreq: 33,226,752 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_add_1/add_1 | OpType: Add] **
  Inputs:
    StatefulPartitionedCall/model/lambda_10/mul:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
    StatefulPartitionedCall/model/lambda_12/mul:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_add_1/add_1:0
    StatefulPartitionedCall/model/tf_op_layer_add_1/add_1:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
  Node Mreq: 33,226,752 bytes

** Node: StatefulPartitionedCall/model/conv2d_13/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_add_1/add_1:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
    StatefulPartitionedCall/model/conv2d_13/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[64, 64, 1, 1], mreq=16,384
    StatefulPartitionedCall/model/conv2d_13/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[64], mreq=256
  Outputs:
StatefulPartitionedCall/model/batch_normalization_13/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_13/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
  Node Mreq: 22,167,808 bytes

** Node: StatefulPartitionedCall/model/lambda_13/Exp | OpType: Exp] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_13/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
  Outputs:
StatefulPartitionedCall/model/lambda_13/Exp:0
    StatefulPartitionedCall/model/lambda_13/Exp:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
  Node Mreq: 22,151,168 bytes

** Node: StatefulPartitionedCall/model/lambda_13/add | OpType: Add] **
  Inputs:
    Transpose__1378:0: dtype=FLOAT, shape=[1, 1, 1, 1], mreq=4
    StatefulPartitionedCall/model/lambda_13/Exp:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
  Outputs:
StatefulPartitionedCall/model/lambda_13/add:0
    StatefulPartitionedCall/model/lambda_13/add:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
  Node Mreq: 22,151,172 bytes

** Node: StatefulPartitionedCall/model/lambda_13/Log | OpType: Log] **
  Inputs:
    StatefulPartitionedCall/model/lambda_13/add:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
  Outputs:
StatefulPartitionedCall/model/lambda_13/Log:0
    StatefulPartitionedCall/model/lambda_13/Log:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
  Node Mreq: 22,151,168 bytes

** Node: StatefulPartitionedCall/model/lambda_13/Tanh | OpType: Tanh] **
  Inputs:
    StatefulPartitionedCall/model/lambda_13/Log:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
  Outputs:
StatefulPartitionedCall/model/lambda_13/Tanh:0
    StatefulPartitionedCall/model/lambda_13/Tanh:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
  Node Mreq: 22,151,168 bytes

** Node: StatefulPartitionedCall/model/lambda_13/mul | OpType: Mul] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_13/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
    StatefulPartitionedCall/model/lambda_13/Tanh:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
  Outputs:
StatefulPartitionedCall/model/lambda_13/mul:0
    StatefulPartitionedCall/model/lambda_13/mul:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
  Node Mreq: 33,226,752 bytes

** Node: StatefulPartitionedCall/model/conv2d_14/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/lambda_13/mul:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
    StatefulPartitionedCall/model/conv2d_14/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[64, 64, 3, 3], mreq=147,456
    StatefulPartitionedCall/model/conv2d_14/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[64], mreq=256
  Outputs:
StatefulPartitionedCall/model/batch_normalization_14/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_14/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
  Node Mreq: 22,298,880 bytes

** Node: StatefulPartitionedCall/model/lambda_14/Exp | OpType: Exp] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_14/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
  Outputs:
StatefulPartitionedCall/model/lambda_14/Exp:0
    StatefulPartitionedCall/model/lambda_14/Exp:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
  Node Mreq: 22,151,168 bytes

** Node: StatefulPartitionedCall/model/lambda_14/add | OpType: Add] **
  Inputs:
    Transpose__1378:0: dtype=FLOAT, shape=[1, 1, 1, 1], mreq=4
    StatefulPartitionedCall/model/lambda_14/Exp:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
  Outputs:
StatefulPartitionedCall/model/lambda_14/add:0
    StatefulPartitionedCall/model/lambda_14/add:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
  Node Mreq: 22,151,172 bytes

** Node: StatefulPartitionedCall/model/lambda_14/Log | OpType: Log] **
  Inputs:
    StatefulPartitionedCall/model/lambda_14/add:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
  Outputs:
StatefulPartitionedCall/model/lambda_14/Log:0
    StatefulPartitionedCall/model/lambda_14/Log:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
  Node Mreq: 22,151,168 bytes

** Node: StatefulPartitionedCall/model/lambda_14/Tanh | OpType: Tanh] **
  Inputs:
    StatefulPartitionedCall/model/lambda_14/Log:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
  Outputs:
StatefulPartitionedCall/model/lambda_14/Tanh:0
    StatefulPartitionedCall/model/lambda_14/Tanh:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
  Node Mreq: 22,151,168 bytes

** Node: StatefulPartitionedCall/model/lambda_14/mul | OpType: Mul] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_14/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
    StatefulPartitionedCall/model/lambda_14/Tanh:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
  Outputs:
StatefulPartitionedCall/model/lambda_14/mul:0
    StatefulPartitionedCall/model/lambda_14/mul:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
  Node Mreq: 33,226,752 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_add_2/add_2 | OpType: Add] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_add_1/add_1:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
    StatefulPartitionedCall/model/lambda_14/mul:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_add_2/add_2:0
    StatefulPartitionedCall/model/tf_op_layer_add_2/add_2:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
  Node Mreq: 33,226,752 bytes

** Node: StatefulPartitionedCall/model/conv2d_15/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_add_2/add_2:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
    StatefulPartitionedCall/model/conv2d_15/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[64, 64, 1, 1], mreq=16,384
    StatefulPartitionedCall/model/conv2d_15/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[64], mreq=256
  Outputs:
StatefulPartitionedCall/model/batch_normalization_15/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_15/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
  Node Mreq: 22,167,808 bytes

** Node: StatefulPartitionedCall/model/lambda_15/Exp | OpType: Exp] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_15/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
  Outputs:
StatefulPartitionedCall/model/lambda_15/Exp:0
    StatefulPartitionedCall/model/lambda_15/Exp:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
  Node Mreq: 22,151,168 bytes

** Node: StatefulPartitionedCall/model/lambda_15/add | OpType: Add] **
  Inputs:
    Transpose__1378:0: dtype=FLOAT, shape=[1, 1, 1, 1], mreq=4
    StatefulPartitionedCall/model/lambda_15/Exp:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
  Outputs:
StatefulPartitionedCall/model/lambda_15/add:0
    StatefulPartitionedCall/model/lambda_15/add:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
  Node Mreq: 22,151,172 bytes

** Node: StatefulPartitionedCall/model/lambda_15/Log | OpType: Log] **
  Inputs:
    StatefulPartitionedCall/model/lambda_15/add:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
  Outputs:
StatefulPartitionedCall/model/lambda_15/Log:0
    StatefulPartitionedCall/model/lambda_15/Log:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
  Node Mreq: 22,151,168 bytes

** Node: StatefulPartitionedCall/model/lambda_15/Tanh | OpType: Tanh] **
  Inputs:
    StatefulPartitionedCall/model/lambda_15/Log:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
  Outputs:
StatefulPartitionedCall/model/lambda_15/Tanh:0
    StatefulPartitionedCall/model/lambda_15/Tanh:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
  Node Mreq: 22,151,168 bytes

** Node: StatefulPartitionedCall/model/lambda_15/mul | OpType: Mul] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_15/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
    StatefulPartitionedCall/model/lambda_15/Tanh:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
  Outputs:
StatefulPartitionedCall/model/lambda_15/mul:0
    StatefulPartitionedCall/model/lambda_15/mul:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
  Node Mreq: 33,226,752 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_concat_1/concat_1 | OpType: Concat] **
  Inputs:
    StatefulPartitionedCall/model/lambda_15/mul:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
    StatefulPartitionedCall/model/lambda_9/mul:0: dtype=FLOAT, shape=[4, 64, 104, 104], mreq=11,075,584
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_concat_1/concat_1:0
    StatefulPartitionedCall/model/tf_op_layer_concat_1/concat_1:0: dtype=FLOAT, shape=[4, 128, 104, 104], mreq=22,151,168
  Node Mreq: 44,302,336 bytes

** Node: StatefulPartitionedCall/model/conv2d_16/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_concat_1/concat_1:0: dtype=FLOAT, shape=[4, 128, 104, 104], mreq=22,151,168
    StatefulPartitionedCall/model/conv2d_16/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[128, 128, 1, 1], mreq=65,536
    StatefulPartitionedCall/model/conv2d_16/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[128], mreq=512
  Outputs:
StatefulPartitionedCall/model/batch_normalization_16/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_16/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 128, 104, 104], mreq=22,151,168
  Node Mreq: 44,368,384 bytes

** Node: StatefulPartitionedCall/model/lambda_16/Exp | OpType: Exp] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_16/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 128, 104, 104], mreq=22,151,168
  Outputs:
StatefulPartitionedCall/model/lambda_16/Exp:0
    StatefulPartitionedCall/model/lambda_16/Exp:0: dtype=FLOAT, shape=[4, 128, 104, 104], mreq=22,151,168
  Node Mreq: 44,302,336 bytes

** Node: StatefulPartitionedCall/model/lambda_16/add | OpType: Add] **
  Inputs:
    Transpose__1378:0: dtype=FLOAT, shape=[1, 1, 1, 1], mreq=4
    StatefulPartitionedCall/model/lambda_16/Exp:0: dtype=FLOAT, shape=[4, 128, 104, 104], mreq=22,151,168
  Outputs:
StatefulPartitionedCall/model/lambda_16/add:0
    StatefulPartitionedCall/model/lambda_16/add:0: dtype=FLOAT, shape=[4, 128, 104, 104], mreq=22,151,168
  Node Mreq: 44,302,340 bytes

** Node: StatefulPartitionedCall/model/lambda_16/Log | OpType: Log] **
  Inputs:
    StatefulPartitionedCall/model/lambda_16/add:0: dtype=FLOAT, shape=[4, 128, 104, 104], mreq=22,151,168
  Outputs:
StatefulPartitionedCall/model/lambda_16/Log:0
    StatefulPartitionedCall/model/lambda_16/Log:0: dtype=FLOAT, shape=[4, 128, 104, 104], mreq=22,151,168
  Node Mreq: 44,302,336 bytes

** Node: StatefulPartitionedCall/model/lambda_16/Tanh | OpType: Tanh] **
  Inputs:
    StatefulPartitionedCall/model/lambda_16/Log:0: dtype=FLOAT, shape=[4, 128, 104, 104], mreq=22,151,168
  Outputs:
StatefulPartitionedCall/model/lambda_16/Tanh:0
    StatefulPartitionedCall/model/lambda_16/Tanh:0: dtype=FLOAT, shape=[4, 128, 104, 104], mreq=22,151,168
  Node Mreq: 44,302,336 bytes

** Node: StatefulPartitionedCall/model/lambda_16/mul | OpType: Mul] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_16/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 128, 104, 104], mreq=22,151,168
    StatefulPartitionedCall/model/lambda_16/Tanh:0: dtype=FLOAT, shape=[4, 128, 104, 104], mreq=22,151,168
  Outputs:
StatefulPartitionedCall/model/lambda_16/mul:0
    StatefulPartitionedCall/model/lambda_16/mul:0: dtype=FLOAT, shape=[4, 128, 104, 104], mreq=22,151,168
  Node Mreq: 66,453,504 bytes

** Node: StatefulPartitionedCall/model/conv2d_17/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/lambda_16/mul:0: dtype=FLOAT, shape=[4, 128, 104, 104], mreq=22,151,168
    StatefulPartitionedCall/model/conv2d_17/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[256, 128, 3, 3], mreq=1,179,648
    StatefulPartitionedCall/model/conv2d_17/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[256], mreq=1,024
  Outputs:
StatefulPartitionedCall/model/batch_normalization_17/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_17/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 256, 52, 52], mreq=11,075,584
  Node Mreq: 34,407,424 bytes

** Node: StatefulPartitionedCall/model/lambda_17/Exp | OpType: Exp] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_17/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 256, 52, 52], mreq=11,075,584
  Outputs:
StatefulPartitionedCall/model/lambda_17/Exp:0
    StatefulPartitionedCall/model/lambda_17/Exp:0: dtype=FLOAT, shape=[4, 256, 52, 52], mreq=11,075,584
  Node Mreq: 22,151,168 bytes

** Node: StatefulPartitionedCall/model/lambda_17/add | OpType: Add] **
  Inputs:
    Transpose__1378:0: dtype=FLOAT, shape=[1, 1, 1, 1], mreq=4
    StatefulPartitionedCall/model/lambda_17/Exp:0: dtype=FLOAT, shape=[4, 256, 52, 52], mreq=11,075,584
  Outputs:
StatefulPartitionedCall/model/lambda_17/add:0
    StatefulPartitionedCall/model/lambda_17/add:0: dtype=FLOAT, shape=[4, 256, 52, 52], mreq=11,075,584
  Node Mreq: 22,151,172 bytes

** Node: StatefulPartitionedCall/model/lambda_17/Log | OpType: Log] **
  Inputs:
    StatefulPartitionedCall/model/lambda_17/add:0: dtype=FLOAT, shape=[4, 256, 52, 52], mreq=11,075,584
  Outputs:
StatefulPartitionedCall/model/lambda_17/Log:0
    StatefulPartitionedCall/model/lambda_17/Log:0: dtype=FLOAT, shape=[4, 256, 52, 52], mreq=11,075,584
  Node Mreq: 22,151,168 bytes

** Node: StatefulPartitionedCall/model/lambda_17/Tanh | OpType: Tanh] **
  Inputs:
    StatefulPartitionedCall/model/lambda_17/Log:0: dtype=FLOAT, shape=[4, 256, 52, 52], mreq=11,075,584
  Outputs:
StatefulPartitionedCall/model/lambda_17/Tanh:0
    StatefulPartitionedCall/model/lambda_17/Tanh:0: dtype=FLOAT, shape=[4, 256, 52, 52], mreq=11,075,584
  Node Mreq: 22,151,168 bytes

** Node: StatefulPartitionedCall/model/lambda_17/mul | OpType: Mul] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_17/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 256, 52, 52], mreq=11,075,584
    StatefulPartitionedCall/model/lambda_17/Tanh:0: dtype=FLOAT, shape=[4, 256, 52, 52], mreq=11,075,584
  Outputs:
StatefulPartitionedCall/model/lambda_17/mul:0
    StatefulPartitionedCall/model/lambda_17/mul:0: dtype=FLOAT, shape=[4, 256, 52, 52], mreq=11,075,584
  Node Mreq: 33,226,752 bytes

** Node: StatefulPartitionedCall/model/conv2d_19/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/lambda_17/mul:0: dtype=FLOAT, shape=[4, 256, 52, 52], mreq=11,075,584
    StatefulPartitionedCall/model/conv2d_19/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[128, 256, 1, 1], mreq=131,072
    StatefulPartitionedCall/model/conv2d_19/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[128], mreq=512
  Outputs:
StatefulPartitionedCall/model/batch_normalization_19/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_19/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 16,744,960 bytes

** Node: StatefulPartitionedCall/model/conv2d_18/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/lambda_17/mul:0: dtype=FLOAT, shape=[4, 256, 52, 52], mreq=11,075,584
    StatefulPartitionedCall/model/conv2d_18/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[128, 256, 1, 1], mreq=131,072
    StatefulPartitionedCall/model/conv2d_18/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[128], mreq=512
  Outputs:
StatefulPartitionedCall/model/batch_normalization_18/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_18/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 16,744,960 bytes

** Node: StatefulPartitionedCall/model/lambda_19/Exp | OpType: Exp] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_19/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_19/Exp:0
    StatefulPartitionedCall/model/lambda_19/Exp:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,075,584 bytes

** Node: StatefulPartitionedCall/model/lambda_18/Exp | OpType: Exp] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_18/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_18/Exp:0
    StatefulPartitionedCall/model/lambda_18/Exp:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,075,584 bytes

** Node: StatefulPartitionedCall/model/lambda_19/add | OpType: Add] **
  Inputs:
    Transpose__1378:0: dtype=FLOAT, shape=[1, 1, 1, 1], mreq=4
    StatefulPartitionedCall/model/lambda_19/Exp:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_19/add:0
    StatefulPartitionedCall/model/lambda_19/add:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,075,588 bytes

** Node: StatefulPartitionedCall/model/lambda_18/add | OpType: Add] **
  Inputs:
    Transpose__1378:0: dtype=FLOAT, shape=[1, 1, 1, 1], mreq=4
    StatefulPartitionedCall/model/lambda_18/Exp:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_18/add:0
    StatefulPartitionedCall/model/lambda_18/add:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,075,588 bytes

** Node: StatefulPartitionedCall/model/lambda_19/Log | OpType: Log] **
  Inputs:
    StatefulPartitionedCall/model/lambda_19/add:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_19/Log:0
    StatefulPartitionedCall/model/lambda_19/Log:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,075,584 bytes

** Node: StatefulPartitionedCall/model/lambda_18/Log | OpType: Log] **
  Inputs:
    StatefulPartitionedCall/model/lambda_18/add:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_18/Log:0
    StatefulPartitionedCall/model/lambda_18/Log:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,075,584 bytes

** Node: StatefulPartitionedCall/model/lambda_19/Tanh | OpType: Tanh] **
  Inputs:
    StatefulPartitionedCall/model/lambda_19/Log:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_19/Tanh:0
    StatefulPartitionedCall/model/lambda_19/Tanh:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,075,584 bytes

** Node: StatefulPartitionedCall/model/lambda_18/Tanh | OpType: Tanh] **
  Inputs:
    StatefulPartitionedCall/model/lambda_18/Log:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_18/Tanh:0
    StatefulPartitionedCall/model/lambda_18/Tanh:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,075,584 bytes

** Node: StatefulPartitionedCall/model/lambda_19/mul | OpType: Mul] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_19/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
    StatefulPartitionedCall/model/lambda_19/Tanh:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_19/mul:0
    StatefulPartitionedCall/model/lambda_19/mul:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 16,613,376 bytes

** Node: StatefulPartitionedCall/model/lambda_18/mul | OpType: Mul] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_18/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
    StatefulPartitionedCall/model/lambda_18/Tanh:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_18/mul:0
    StatefulPartitionedCall/model/lambda_18/mul:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 16,613,376 bytes

** Node: StatefulPartitionedCall/model/conv2d_20/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/lambda_19/mul:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
    StatefulPartitionedCall/model/conv2d_20/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[128, 128, 1, 1], mreq=65,536
    StatefulPartitionedCall/model/conv2d_20/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[128], mreq=512
  Outputs:
StatefulPartitionedCall/model/batch_normalization_20/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_20/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,141,632 bytes

** Node: StatefulPartitionedCall/model/lambda_20/Exp | OpType: Exp] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_20/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_20/Exp:0
    StatefulPartitionedCall/model/lambda_20/Exp:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,075,584 bytes

** Node: StatefulPartitionedCall/model/lambda_20/add | OpType: Add] **
  Inputs:
    Transpose__1378:0: dtype=FLOAT, shape=[1, 1, 1, 1], mreq=4
    StatefulPartitionedCall/model/lambda_20/Exp:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_20/add:0
    StatefulPartitionedCall/model/lambda_20/add:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,075,588 bytes

** Node: StatefulPartitionedCall/model/lambda_20/Log | OpType: Log] **
  Inputs:
    StatefulPartitionedCall/model/lambda_20/add:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_20/Log:0
    StatefulPartitionedCall/model/lambda_20/Log:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,075,584 bytes

** Node: StatefulPartitionedCall/model/lambda_20/Tanh | OpType: Tanh] **
  Inputs:
    StatefulPartitionedCall/model/lambda_20/Log:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_20/Tanh:0
    StatefulPartitionedCall/model/lambda_20/Tanh:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,075,584 bytes

** Node: StatefulPartitionedCall/model/lambda_20/mul | OpType: Mul] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_20/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
    StatefulPartitionedCall/model/lambda_20/Tanh:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_20/mul:0
    StatefulPartitionedCall/model/lambda_20/mul:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 16,613,376 bytes

** Node: StatefulPartitionedCall/model/conv2d_21/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/lambda_20/mul:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
    StatefulPartitionedCall/model/conv2d_21/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[128, 128, 3, 3], mreq=589,824
    StatefulPartitionedCall/model/conv2d_21/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[128], mreq=512
  Outputs:
StatefulPartitionedCall/model/batch_normalization_21/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_21/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,665,920 bytes

** Node: StatefulPartitionedCall/model/lambda_21/Exp | OpType: Exp] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_21/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_21/Exp:0
    StatefulPartitionedCall/model/lambda_21/Exp:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,075,584 bytes

** Node: StatefulPartitionedCall/model/lambda_21/add | OpType: Add] **
  Inputs:
    Transpose__1378:0: dtype=FLOAT, shape=[1, 1, 1, 1], mreq=4
    StatefulPartitionedCall/model/lambda_21/Exp:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_21/add:0
    StatefulPartitionedCall/model/lambda_21/add:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,075,588 bytes

** Node: StatefulPartitionedCall/model/lambda_21/Log | OpType: Log] **
  Inputs:
    StatefulPartitionedCall/model/lambda_21/add:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_21/Log:0
    StatefulPartitionedCall/model/lambda_21/Log:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,075,584 bytes

** Node: StatefulPartitionedCall/model/lambda_21/Tanh | OpType: Tanh] **
  Inputs:
    StatefulPartitionedCall/model/lambda_21/Log:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_21/Tanh:0
    StatefulPartitionedCall/model/lambda_21/Tanh:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,075,584 bytes

** Node: StatefulPartitionedCall/model/lambda_21/mul | OpType: Mul] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_21/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
    StatefulPartitionedCall/model/lambda_21/Tanh:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_21/mul:0
    StatefulPartitionedCall/model/lambda_21/mul:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 16,613,376 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_add_3/add_3 | OpType: Add] **
  Inputs:
    StatefulPartitionedCall/model/lambda_19/mul:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
    StatefulPartitionedCall/model/lambda_21/mul:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_add_3/add_3:0
    StatefulPartitionedCall/model/tf_op_layer_add_3/add_3:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 16,613,376 bytes

** Node: StatefulPartitionedCall/model/conv2d_22/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_add_3/add_3:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
    StatefulPartitionedCall/model/conv2d_22/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[128, 128, 1, 1], mreq=65,536
    StatefulPartitionedCall/model/conv2d_22/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[128], mreq=512
  Outputs:
StatefulPartitionedCall/model/batch_normalization_22/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_22/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,141,632 bytes

** Node: StatefulPartitionedCall/model/lambda_22/Exp | OpType: Exp] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_22/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_22/Exp:0
    StatefulPartitionedCall/model/lambda_22/Exp:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,075,584 bytes

** Node: StatefulPartitionedCall/model/lambda_22/add | OpType: Add] **
  Inputs:
    Transpose__1378:0: dtype=FLOAT, shape=[1, 1, 1, 1], mreq=4
    StatefulPartitionedCall/model/lambda_22/Exp:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_22/add:0
    StatefulPartitionedCall/model/lambda_22/add:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,075,588 bytes

** Node: StatefulPartitionedCall/model/lambda_22/Log | OpType: Log] **
  Inputs:
    StatefulPartitionedCall/model/lambda_22/add:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_22/Log:0
    StatefulPartitionedCall/model/lambda_22/Log:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,075,584 bytes

** Node: StatefulPartitionedCall/model/lambda_22/Tanh | OpType: Tanh] **
  Inputs:
    StatefulPartitionedCall/model/lambda_22/Log:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_22/Tanh:0
    StatefulPartitionedCall/model/lambda_22/Tanh:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,075,584 bytes

** Node: StatefulPartitionedCall/model/lambda_22/mul | OpType: Mul] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_22/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
    StatefulPartitionedCall/model/lambda_22/Tanh:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_22/mul:0
    StatefulPartitionedCall/model/lambda_22/mul:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 16,613,376 bytes

** Node: StatefulPartitionedCall/model/conv2d_23/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/lambda_22/mul:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
    StatefulPartitionedCall/model/conv2d_23/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[128, 128, 3, 3], mreq=589,824
    StatefulPartitionedCall/model/conv2d_23/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[128], mreq=512
  Outputs:
StatefulPartitionedCall/model/batch_normalization_23/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_23/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,665,920 bytes

** Node: StatefulPartitionedCall/model/lambda_23/Exp | OpType: Exp] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_23/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_23/Exp:0
    StatefulPartitionedCall/model/lambda_23/Exp:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,075,584 bytes

** Node: StatefulPartitionedCall/model/lambda_23/add | OpType: Add] **
  Inputs:
    Transpose__1378:0: dtype=FLOAT, shape=[1, 1, 1, 1], mreq=4
    StatefulPartitionedCall/model/lambda_23/Exp:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_23/add:0
    StatefulPartitionedCall/model/lambda_23/add:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,075,588 bytes

** Node: StatefulPartitionedCall/model/lambda_23/Log | OpType: Log] **
  Inputs:
    StatefulPartitionedCall/model/lambda_23/add:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_23/Log:0
    StatefulPartitionedCall/model/lambda_23/Log:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,075,584 bytes

** Node: StatefulPartitionedCall/model/lambda_23/Tanh | OpType: Tanh] **
  Inputs:
    StatefulPartitionedCall/model/lambda_23/Log:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_23/Tanh:0
    StatefulPartitionedCall/model/lambda_23/Tanh:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,075,584 bytes

** Node: StatefulPartitionedCall/model/lambda_23/mul | OpType: Mul] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_23/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
    StatefulPartitionedCall/model/lambda_23/Tanh:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_23/mul:0
    StatefulPartitionedCall/model/lambda_23/mul:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 16,613,376 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_add_4/add_4 | OpType: Add] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_add_3/add_3:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
    StatefulPartitionedCall/model/lambda_23/mul:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_add_4/add_4:0
    StatefulPartitionedCall/model/tf_op_layer_add_4/add_4:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 16,613,376 bytes

** Node: StatefulPartitionedCall/model/conv2d_24/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_add_4/add_4:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
    StatefulPartitionedCall/model/conv2d_24/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[128, 128, 1, 1], mreq=65,536
    StatefulPartitionedCall/model/conv2d_24/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[128], mreq=512
  Outputs:
StatefulPartitionedCall/model/batch_normalization_24/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_24/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,141,632 bytes

** Node: StatefulPartitionedCall/model/lambda_24/Exp | OpType: Exp] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_24/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_24/Exp:0
    StatefulPartitionedCall/model/lambda_24/Exp:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,075,584 bytes

** Node: StatefulPartitionedCall/model/lambda_24/add | OpType: Add] **
  Inputs:
    Transpose__1378:0: dtype=FLOAT, shape=[1, 1, 1, 1], mreq=4
    StatefulPartitionedCall/model/lambda_24/Exp:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_24/add:0
    StatefulPartitionedCall/model/lambda_24/add:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,075,588 bytes

** Node: StatefulPartitionedCall/model/lambda_24/Log | OpType: Log] **
  Inputs:
    StatefulPartitionedCall/model/lambda_24/add:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_24/Log:0
    StatefulPartitionedCall/model/lambda_24/Log:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,075,584 bytes

** Node: StatefulPartitionedCall/model/lambda_24/Tanh | OpType: Tanh] **
  Inputs:
    StatefulPartitionedCall/model/lambda_24/Log:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_24/Tanh:0
    StatefulPartitionedCall/model/lambda_24/Tanh:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,075,584 bytes

** Node: StatefulPartitionedCall/model/lambda_24/mul | OpType: Mul] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_24/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
    StatefulPartitionedCall/model/lambda_24/Tanh:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_24/mul:0
    StatefulPartitionedCall/model/lambda_24/mul:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 16,613,376 bytes

** Node: StatefulPartitionedCall/model/conv2d_25/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/lambda_24/mul:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
    StatefulPartitionedCall/model/conv2d_25/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[128, 128, 3, 3], mreq=589,824
    StatefulPartitionedCall/model/conv2d_25/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[128], mreq=512
  Outputs:
StatefulPartitionedCall/model/batch_normalization_25/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_25/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,665,920 bytes

** Node: StatefulPartitionedCall/model/lambda_25/Exp | OpType: Exp] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_25/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_25/Exp:0
    StatefulPartitionedCall/model/lambda_25/Exp:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,075,584 bytes

** Node: StatefulPartitionedCall/model/lambda_25/add | OpType: Add] **
  Inputs:
    Transpose__1378:0: dtype=FLOAT, shape=[1, 1, 1, 1], mreq=4
    StatefulPartitionedCall/model/lambda_25/Exp:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_25/add:0
    StatefulPartitionedCall/model/lambda_25/add:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,075,588 bytes

** Node: StatefulPartitionedCall/model/lambda_25/Log | OpType: Log] **
  Inputs:
    StatefulPartitionedCall/model/lambda_25/add:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_25/Log:0
    StatefulPartitionedCall/model/lambda_25/Log:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,075,584 bytes

** Node: StatefulPartitionedCall/model/lambda_25/Tanh | OpType: Tanh] **
  Inputs:
    StatefulPartitionedCall/model/lambda_25/Log:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_25/Tanh:0
    StatefulPartitionedCall/model/lambda_25/Tanh:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,075,584 bytes

** Node: StatefulPartitionedCall/model/lambda_25/mul | OpType: Mul] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_25/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
    StatefulPartitionedCall/model/lambda_25/Tanh:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_25/mul:0
    StatefulPartitionedCall/model/lambda_25/mul:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 16,613,376 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_add_5/add_5 | OpType: Add] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_add_4/add_4:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
    StatefulPartitionedCall/model/lambda_25/mul:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_add_5/add_5:0
    StatefulPartitionedCall/model/tf_op_layer_add_5/add_5:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 16,613,376 bytes

** Node: StatefulPartitionedCall/model/conv2d_26/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_add_5/add_5:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
    StatefulPartitionedCall/model/conv2d_26/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[128, 128, 1, 1], mreq=65,536
    StatefulPartitionedCall/model/conv2d_26/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[128], mreq=512
  Outputs:
StatefulPartitionedCall/model/batch_normalization_26/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_26/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,141,632 bytes

** Node: StatefulPartitionedCall/model/lambda_26/Exp | OpType: Exp] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_26/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_26/Exp:0
    StatefulPartitionedCall/model/lambda_26/Exp:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,075,584 bytes

** Node: StatefulPartitionedCall/model/lambda_26/add | OpType: Add] **
  Inputs:
    Transpose__1378:0: dtype=FLOAT, shape=[1, 1, 1, 1], mreq=4
    StatefulPartitionedCall/model/lambda_26/Exp:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_26/add:0
    StatefulPartitionedCall/model/lambda_26/add:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,075,588 bytes

** Node: StatefulPartitionedCall/model/lambda_26/Log | OpType: Log] **
  Inputs:
    StatefulPartitionedCall/model/lambda_26/add:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_26/Log:0
    StatefulPartitionedCall/model/lambda_26/Log:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,075,584 bytes

** Node: StatefulPartitionedCall/model/lambda_26/Tanh | OpType: Tanh] **
  Inputs:
    StatefulPartitionedCall/model/lambda_26/Log:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_26/Tanh:0
    StatefulPartitionedCall/model/lambda_26/Tanh:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,075,584 bytes

** Node: StatefulPartitionedCall/model/lambda_26/mul | OpType: Mul] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_26/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
    StatefulPartitionedCall/model/lambda_26/Tanh:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_26/mul:0
    StatefulPartitionedCall/model/lambda_26/mul:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 16,613,376 bytes

** Node: StatefulPartitionedCall/model/conv2d_27/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/lambda_26/mul:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
    StatefulPartitionedCall/model/conv2d_27/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[128, 128, 3, 3], mreq=589,824
    StatefulPartitionedCall/model/conv2d_27/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[128], mreq=512
  Outputs:
StatefulPartitionedCall/model/batch_normalization_27/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_27/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,665,920 bytes

** Node: StatefulPartitionedCall/model/lambda_27/Exp | OpType: Exp] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_27/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_27/Exp:0
    StatefulPartitionedCall/model/lambda_27/Exp:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,075,584 bytes

** Node: StatefulPartitionedCall/model/lambda_27/add | OpType: Add] **
  Inputs:
    Transpose__1378:0: dtype=FLOAT, shape=[1, 1, 1, 1], mreq=4
    StatefulPartitionedCall/model/lambda_27/Exp:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_27/add:0
    StatefulPartitionedCall/model/lambda_27/add:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,075,588 bytes

** Node: StatefulPartitionedCall/model/lambda_27/Log | OpType: Log] **
  Inputs:
    StatefulPartitionedCall/model/lambda_27/add:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_27/Log:0
    StatefulPartitionedCall/model/lambda_27/Log:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,075,584 bytes

** Node: StatefulPartitionedCall/model/lambda_27/Tanh | OpType: Tanh] **
  Inputs:
    StatefulPartitionedCall/model/lambda_27/Log:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_27/Tanh:0
    StatefulPartitionedCall/model/lambda_27/Tanh:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,075,584 bytes

** Node: StatefulPartitionedCall/model/lambda_27/mul | OpType: Mul] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_27/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
    StatefulPartitionedCall/model/lambda_27/Tanh:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_27/mul:0
    StatefulPartitionedCall/model/lambda_27/mul:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 16,613,376 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_add_6/add_6 | OpType: Add] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_add_5/add_5:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
    StatefulPartitionedCall/model/lambda_27/mul:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_add_6/add_6:0
    StatefulPartitionedCall/model/tf_op_layer_add_6/add_6:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 16,613,376 bytes

** Node: StatefulPartitionedCall/model/conv2d_28/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_add_6/add_6:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
    StatefulPartitionedCall/model/conv2d_28/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[128, 128, 1, 1], mreq=65,536
    StatefulPartitionedCall/model/conv2d_28/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[128], mreq=512
  Outputs:
StatefulPartitionedCall/model/batch_normalization_28/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_28/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,141,632 bytes

** Node: StatefulPartitionedCall/model/lambda_28/Exp | OpType: Exp] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_28/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_28/Exp:0
    StatefulPartitionedCall/model/lambda_28/Exp:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,075,584 bytes

** Node: StatefulPartitionedCall/model/lambda_28/add | OpType: Add] **
  Inputs:
    Transpose__1378:0: dtype=FLOAT, shape=[1, 1, 1, 1], mreq=4
    StatefulPartitionedCall/model/lambda_28/Exp:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_28/add:0
    StatefulPartitionedCall/model/lambda_28/add:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,075,588 bytes

** Node: StatefulPartitionedCall/model/lambda_28/Log | OpType: Log] **
  Inputs:
    StatefulPartitionedCall/model/lambda_28/add:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_28/Log:0
    StatefulPartitionedCall/model/lambda_28/Log:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,075,584 bytes

** Node: StatefulPartitionedCall/model/lambda_28/Tanh | OpType: Tanh] **
  Inputs:
    StatefulPartitionedCall/model/lambda_28/Log:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_28/Tanh:0
    StatefulPartitionedCall/model/lambda_28/Tanh:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,075,584 bytes

** Node: StatefulPartitionedCall/model/lambda_28/mul | OpType: Mul] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_28/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
    StatefulPartitionedCall/model/lambda_28/Tanh:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_28/mul:0
    StatefulPartitionedCall/model/lambda_28/mul:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 16,613,376 bytes

** Node: StatefulPartitionedCall/model/conv2d_29/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/lambda_28/mul:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
    StatefulPartitionedCall/model/conv2d_29/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[128, 128, 3, 3], mreq=589,824
    StatefulPartitionedCall/model/conv2d_29/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[128], mreq=512
  Outputs:
StatefulPartitionedCall/model/batch_normalization_29/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_29/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,665,920 bytes

** Node: StatefulPartitionedCall/model/lambda_29/Exp | OpType: Exp] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_29/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_29/Exp:0
    StatefulPartitionedCall/model/lambda_29/Exp:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,075,584 bytes

** Node: StatefulPartitionedCall/model/lambda_29/add | OpType: Add] **
  Inputs:
    Transpose__1378:0: dtype=FLOAT, shape=[1, 1, 1, 1], mreq=4
    StatefulPartitionedCall/model/lambda_29/Exp:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_29/add:0
    StatefulPartitionedCall/model/lambda_29/add:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,075,588 bytes

** Node: StatefulPartitionedCall/model/lambda_29/Log | OpType: Log] **
  Inputs:
    StatefulPartitionedCall/model/lambda_29/add:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_29/Log:0
    StatefulPartitionedCall/model/lambda_29/Log:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,075,584 bytes

** Node: StatefulPartitionedCall/model/lambda_29/Tanh | OpType: Tanh] **
  Inputs:
    StatefulPartitionedCall/model/lambda_29/Log:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_29/Tanh:0
    StatefulPartitionedCall/model/lambda_29/Tanh:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,075,584 bytes

** Node: StatefulPartitionedCall/model/lambda_29/mul | OpType: Mul] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_29/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
    StatefulPartitionedCall/model/lambda_29/Tanh:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_29/mul:0
    StatefulPartitionedCall/model/lambda_29/mul:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 16,613,376 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_add_7/add_7 | OpType: Add] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_add_6/add_6:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
    StatefulPartitionedCall/model/lambda_29/mul:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_add_7/add_7:0
    StatefulPartitionedCall/model/tf_op_layer_add_7/add_7:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 16,613,376 bytes

** Node: StatefulPartitionedCall/model/conv2d_30/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_add_7/add_7:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
    StatefulPartitionedCall/model/conv2d_30/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[128, 128, 1, 1], mreq=65,536
    StatefulPartitionedCall/model/conv2d_30/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[128], mreq=512
  Outputs:
StatefulPartitionedCall/model/batch_normalization_30/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_30/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,141,632 bytes

** Node: StatefulPartitionedCall/model/lambda_30/Exp | OpType: Exp] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_30/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_30/Exp:0
    StatefulPartitionedCall/model/lambda_30/Exp:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,075,584 bytes

** Node: StatefulPartitionedCall/model/lambda_30/add | OpType: Add] **
  Inputs:
    Transpose__1378:0: dtype=FLOAT, shape=[1, 1, 1, 1], mreq=4
    StatefulPartitionedCall/model/lambda_30/Exp:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_30/add:0
    StatefulPartitionedCall/model/lambda_30/add:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,075,588 bytes

** Node: StatefulPartitionedCall/model/lambda_30/Log | OpType: Log] **
  Inputs:
    StatefulPartitionedCall/model/lambda_30/add:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_30/Log:0
    StatefulPartitionedCall/model/lambda_30/Log:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,075,584 bytes

** Node: StatefulPartitionedCall/model/lambda_30/Tanh | OpType: Tanh] **
  Inputs:
    StatefulPartitionedCall/model/lambda_30/Log:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_30/Tanh:0
    StatefulPartitionedCall/model/lambda_30/Tanh:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,075,584 bytes

** Node: StatefulPartitionedCall/model/lambda_30/mul | OpType: Mul] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_30/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
    StatefulPartitionedCall/model/lambda_30/Tanh:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_30/mul:0
    StatefulPartitionedCall/model/lambda_30/mul:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 16,613,376 bytes

** Node: StatefulPartitionedCall/model/conv2d_31/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/lambda_30/mul:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
    StatefulPartitionedCall/model/conv2d_31/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[128, 128, 3, 3], mreq=589,824
    StatefulPartitionedCall/model/conv2d_31/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[128], mreq=512
  Outputs:
StatefulPartitionedCall/model/batch_normalization_31/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_31/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,665,920 bytes

** Node: StatefulPartitionedCall/model/lambda_31/Exp | OpType: Exp] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_31/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_31/Exp:0
    StatefulPartitionedCall/model/lambda_31/Exp:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,075,584 bytes

** Node: StatefulPartitionedCall/model/lambda_31/add | OpType: Add] **
  Inputs:
    Transpose__1378:0: dtype=FLOAT, shape=[1, 1, 1, 1], mreq=4
    StatefulPartitionedCall/model/lambda_31/Exp:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_31/add:0
    StatefulPartitionedCall/model/lambda_31/add:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,075,588 bytes

** Node: StatefulPartitionedCall/model/lambda_31/Log | OpType: Log] **
  Inputs:
    StatefulPartitionedCall/model/lambda_31/add:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_31/Log:0
    StatefulPartitionedCall/model/lambda_31/Log:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,075,584 bytes

** Node: StatefulPartitionedCall/model/lambda_31/Tanh | OpType: Tanh] **
  Inputs:
    StatefulPartitionedCall/model/lambda_31/Log:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_31/Tanh:0
    StatefulPartitionedCall/model/lambda_31/Tanh:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,075,584 bytes

** Node: StatefulPartitionedCall/model/lambda_31/mul | OpType: Mul] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_31/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
    StatefulPartitionedCall/model/lambda_31/Tanh:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_31/mul:0
    StatefulPartitionedCall/model/lambda_31/mul:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 16,613,376 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_add_8/add_8 | OpType: Add] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_add_7/add_7:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
    StatefulPartitionedCall/model/lambda_31/mul:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_add_8/add_8:0
    StatefulPartitionedCall/model/tf_op_layer_add_8/add_8:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 16,613,376 bytes

** Node: StatefulPartitionedCall/model/conv2d_32/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_add_8/add_8:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
    StatefulPartitionedCall/model/conv2d_32/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[128, 128, 1, 1], mreq=65,536
    StatefulPartitionedCall/model/conv2d_32/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[128], mreq=512
  Outputs:
StatefulPartitionedCall/model/batch_normalization_32/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_32/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,141,632 bytes

** Node: StatefulPartitionedCall/model/lambda_32/Exp | OpType: Exp] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_32/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_32/Exp:0
    StatefulPartitionedCall/model/lambda_32/Exp:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,075,584 bytes

** Node: StatefulPartitionedCall/model/lambda_32/add | OpType: Add] **
  Inputs:
    Transpose__1378:0: dtype=FLOAT, shape=[1, 1, 1, 1], mreq=4
    StatefulPartitionedCall/model/lambda_32/Exp:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_32/add:0
    StatefulPartitionedCall/model/lambda_32/add:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,075,588 bytes

** Node: StatefulPartitionedCall/model/lambda_32/Log | OpType: Log] **
  Inputs:
    StatefulPartitionedCall/model/lambda_32/add:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_32/Log:0
    StatefulPartitionedCall/model/lambda_32/Log:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,075,584 bytes

** Node: StatefulPartitionedCall/model/lambda_32/Tanh | OpType: Tanh] **
  Inputs:
    StatefulPartitionedCall/model/lambda_32/Log:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_32/Tanh:0
    StatefulPartitionedCall/model/lambda_32/Tanh:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,075,584 bytes

** Node: StatefulPartitionedCall/model/lambda_32/mul | OpType: Mul] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_32/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
    StatefulPartitionedCall/model/lambda_32/Tanh:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_32/mul:0
    StatefulPartitionedCall/model/lambda_32/mul:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 16,613,376 bytes

** Node: StatefulPartitionedCall/model/conv2d_33/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/lambda_32/mul:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
    StatefulPartitionedCall/model/conv2d_33/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[128, 128, 3, 3], mreq=589,824
    StatefulPartitionedCall/model/conv2d_33/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[128], mreq=512
  Outputs:
StatefulPartitionedCall/model/batch_normalization_33/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_33/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,665,920 bytes

** Node: StatefulPartitionedCall/model/lambda_33/Exp | OpType: Exp] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_33/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_33/Exp:0
    StatefulPartitionedCall/model/lambda_33/Exp:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,075,584 bytes

** Node: StatefulPartitionedCall/model/lambda_33/add | OpType: Add] **
  Inputs:
    Transpose__1378:0: dtype=FLOAT, shape=[1, 1, 1, 1], mreq=4
    StatefulPartitionedCall/model/lambda_33/Exp:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_33/add:0
    StatefulPartitionedCall/model/lambda_33/add:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,075,588 bytes

** Node: StatefulPartitionedCall/model/lambda_33/Log | OpType: Log] **
  Inputs:
    StatefulPartitionedCall/model/lambda_33/add:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_33/Log:0
    StatefulPartitionedCall/model/lambda_33/Log:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,075,584 bytes

** Node: StatefulPartitionedCall/model/lambda_33/Tanh | OpType: Tanh] **
  Inputs:
    StatefulPartitionedCall/model/lambda_33/Log:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_33/Tanh:0
    StatefulPartitionedCall/model/lambda_33/Tanh:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,075,584 bytes

** Node: StatefulPartitionedCall/model/lambda_33/mul | OpType: Mul] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_33/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
    StatefulPartitionedCall/model/lambda_33/Tanh:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_33/mul:0
    StatefulPartitionedCall/model/lambda_33/mul:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 16,613,376 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_add_9/add_9 | OpType: Add] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_add_8/add_8:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
    StatefulPartitionedCall/model/lambda_33/mul:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_add_9/add_9:0
    StatefulPartitionedCall/model/tf_op_layer_add_9/add_9:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 16,613,376 bytes

** Node: StatefulPartitionedCall/model/conv2d_34/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_add_9/add_9:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
    StatefulPartitionedCall/model/conv2d_34/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[128, 128, 1, 1], mreq=65,536
    StatefulPartitionedCall/model/conv2d_34/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[128], mreq=512
  Outputs:
StatefulPartitionedCall/model/batch_normalization_34/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_34/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,141,632 bytes

** Node: StatefulPartitionedCall/model/lambda_34/Exp | OpType: Exp] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_34/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_34/Exp:0
    StatefulPartitionedCall/model/lambda_34/Exp:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,075,584 bytes

** Node: StatefulPartitionedCall/model/lambda_34/add | OpType: Add] **
  Inputs:
    Transpose__1378:0: dtype=FLOAT, shape=[1, 1, 1, 1], mreq=4
    StatefulPartitionedCall/model/lambda_34/Exp:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_34/add:0
    StatefulPartitionedCall/model/lambda_34/add:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,075,588 bytes

** Node: StatefulPartitionedCall/model/lambda_34/Log | OpType: Log] **
  Inputs:
    StatefulPartitionedCall/model/lambda_34/add:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_34/Log:0
    StatefulPartitionedCall/model/lambda_34/Log:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,075,584 bytes

** Node: StatefulPartitionedCall/model/lambda_34/Tanh | OpType: Tanh] **
  Inputs:
    StatefulPartitionedCall/model/lambda_34/Log:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_34/Tanh:0
    StatefulPartitionedCall/model/lambda_34/Tanh:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,075,584 bytes

** Node: StatefulPartitionedCall/model/lambda_34/mul | OpType: Mul] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_34/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
    StatefulPartitionedCall/model/lambda_34/Tanh:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_34/mul:0
    StatefulPartitionedCall/model/lambda_34/mul:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 16,613,376 bytes

** Node: StatefulPartitionedCall/model/conv2d_35/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/lambda_34/mul:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
    StatefulPartitionedCall/model/conv2d_35/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[128, 128, 3, 3], mreq=589,824
    StatefulPartitionedCall/model/conv2d_35/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[128], mreq=512
  Outputs:
StatefulPartitionedCall/model/batch_normalization_35/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_35/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,665,920 bytes

** Node: StatefulPartitionedCall/model/lambda_35/Exp | OpType: Exp] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_35/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_35/Exp:0
    StatefulPartitionedCall/model/lambda_35/Exp:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,075,584 bytes

** Node: StatefulPartitionedCall/model/lambda_35/add | OpType: Add] **
  Inputs:
    Transpose__1378:0: dtype=FLOAT, shape=[1, 1, 1, 1], mreq=4
    StatefulPartitionedCall/model/lambda_35/Exp:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_35/add:0
    StatefulPartitionedCall/model/lambda_35/add:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,075,588 bytes

** Node: StatefulPartitionedCall/model/lambda_35/Log | OpType: Log] **
  Inputs:
    StatefulPartitionedCall/model/lambda_35/add:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_35/Log:0
    StatefulPartitionedCall/model/lambda_35/Log:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,075,584 bytes

** Node: StatefulPartitionedCall/model/lambda_35/Tanh | OpType: Tanh] **
  Inputs:
    StatefulPartitionedCall/model/lambda_35/Log:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_35/Tanh:0
    StatefulPartitionedCall/model/lambda_35/Tanh:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,075,584 bytes

** Node: StatefulPartitionedCall/model/lambda_35/mul | OpType: Mul] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_35/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
    StatefulPartitionedCall/model/lambda_35/Tanh:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_35/mul:0
    StatefulPartitionedCall/model/lambda_35/mul:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 16,613,376 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_add_10/add_10 | OpType: Add] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_add_9/add_9:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
    StatefulPartitionedCall/model/lambda_35/mul:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_add_10/add_10:0
    StatefulPartitionedCall/model/tf_op_layer_add_10/add_10:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 16,613,376 bytes

** Node: StatefulPartitionedCall/model/conv2d_36/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_add_10/add_10:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
    StatefulPartitionedCall/model/conv2d_36/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[128, 128, 1, 1], mreq=65,536
    StatefulPartitionedCall/model/conv2d_36/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[128], mreq=512
  Outputs:
StatefulPartitionedCall/model/batch_normalization_36/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_36/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,141,632 bytes

** Node: StatefulPartitionedCall/model/lambda_36/Exp | OpType: Exp] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_36/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_36/Exp:0
    StatefulPartitionedCall/model/lambda_36/Exp:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,075,584 bytes

** Node: StatefulPartitionedCall/model/lambda_36/add | OpType: Add] **
  Inputs:
    Transpose__1378:0: dtype=FLOAT, shape=[1, 1, 1, 1], mreq=4
    StatefulPartitionedCall/model/lambda_36/Exp:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_36/add:0
    StatefulPartitionedCall/model/lambda_36/add:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,075,588 bytes

** Node: StatefulPartitionedCall/model/lambda_36/Log | OpType: Log] **
  Inputs:
    StatefulPartitionedCall/model/lambda_36/add:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_36/Log:0
    StatefulPartitionedCall/model/lambda_36/Log:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,075,584 bytes

** Node: StatefulPartitionedCall/model/lambda_36/Tanh | OpType: Tanh] **
  Inputs:
    StatefulPartitionedCall/model/lambda_36/Log:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_36/Tanh:0
    StatefulPartitionedCall/model/lambda_36/Tanh:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,075,584 bytes

** Node: StatefulPartitionedCall/model/lambda_36/mul | OpType: Mul] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_36/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
    StatefulPartitionedCall/model/lambda_36/Tanh:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_36/mul:0
    StatefulPartitionedCall/model/lambda_36/mul:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 16,613,376 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_concat_2/concat_2 | OpType: Concat] **
  Inputs:
    StatefulPartitionedCall/model/lambda_36/mul:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
    StatefulPartitionedCall/model/lambda_18/mul:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_concat_2/concat_2:0
    StatefulPartitionedCall/model/tf_op_layer_concat_2/concat_2:0: dtype=FLOAT, shape=[4, 256, 52, 52], mreq=11,075,584
  Node Mreq: 22,151,168 bytes

** Node: StatefulPartitionedCall/model/conv2d_37/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_concat_2/concat_2:0: dtype=FLOAT, shape=[4, 256, 52, 52], mreq=11,075,584
    StatefulPartitionedCall/model/conv2d_37/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[256, 256, 1, 1], mreq=262,144
    StatefulPartitionedCall/model/conv2d_37/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[256], mreq=1,024
  Outputs:
StatefulPartitionedCall/model/batch_normalization_37/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_37/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 256, 52, 52], mreq=11,075,584
  Node Mreq: 22,414,336 bytes

** Node: StatefulPartitionedCall/model/lambda_37/Exp | OpType: Exp] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_37/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 256, 52, 52], mreq=11,075,584
  Outputs:
StatefulPartitionedCall/model/lambda_37/Exp:0
    StatefulPartitionedCall/model/lambda_37/Exp:0: dtype=FLOAT, shape=[4, 256, 52, 52], mreq=11,075,584
  Node Mreq: 22,151,168 bytes

** Node: StatefulPartitionedCall/model/lambda_37/add | OpType: Add] **
  Inputs:
    Transpose__1378:0: dtype=FLOAT, shape=[1, 1, 1, 1], mreq=4
    StatefulPartitionedCall/model/lambda_37/Exp:0: dtype=FLOAT, shape=[4, 256, 52, 52], mreq=11,075,584
  Outputs:
StatefulPartitionedCall/model/lambda_37/add:0
    StatefulPartitionedCall/model/lambda_37/add:0: dtype=FLOAT, shape=[4, 256, 52, 52], mreq=11,075,584
  Node Mreq: 22,151,172 bytes

** Node: StatefulPartitionedCall/model/lambda_37/Log | OpType: Log] **
  Inputs:
    StatefulPartitionedCall/model/lambda_37/add:0: dtype=FLOAT, shape=[4, 256, 52, 52], mreq=11,075,584
  Outputs:
StatefulPartitionedCall/model/lambda_37/Log:0
    StatefulPartitionedCall/model/lambda_37/Log:0: dtype=FLOAT, shape=[4, 256, 52, 52], mreq=11,075,584
  Node Mreq: 22,151,168 bytes

** Node: StatefulPartitionedCall/model/lambda_37/Tanh | OpType: Tanh] **
  Inputs:
    StatefulPartitionedCall/model/lambda_37/Log:0: dtype=FLOAT, shape=[4, 256, 52, 52], mreq=11,075,584
  Outputs:
StatefulPartitionedCall/model/lambda_37/Tanh:0
    StatefulPartitionedCall/model/lambda_37/Tanh:0: dtype=FLOAT, shape=[4, 256, 52, 52], mreq=11,075,584
  Node Mreq: 22,151,168 bytes

** Node: StatefulPartitionedCall/model/lambda_37/mul | OpType: Mul] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_37/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 256, 52, 52], mreq=11,075,584
    StatefulPartitionedCall/model/lambda_37/Tanh:0: dtype=FLOAT, shape=[4, 256, 52, 52], mreq=11,075,584
  Outputs:
StatefulPartitionedCall/model/lambda_37/mul:0
    StatefulPartitionedCall/model/lambda_37/mul:0: dtype=FLOAT, shape=[4, 256, 52, 52], mreq=11,075,584
  Node Mreq: 33,226,752 bytes

** Node: StatefulPartitionedCall/model/conv2d_86/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/lambda_37/mul:0: dtype=FLOAT, shape=[4, 256, 52, 52], mreq=11,075,584
    StatefulPartitionedCall/model/conv2d_86/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[128, 256, 1, 1], mreq=131,072
    StatefulPartitionedCall/model/conv2d_86/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[128], mreq=512
  Outputs:
StatefulPartitionedCall/model/batch_normalization_86/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_86/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 16,744,960 bytes

** Node: StatefulPartitionedCall/model/conv2d_38/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/lambda_37/mul:0: dtype=FLOAT, shape=[4, 256, 52, 52], mreq=11,075,584
    StatefulPartitionedCall/model/conv2d_38/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[512, 256, 3, 3], mreq=4,718,592
    StatefulPartitionedCall/model/conv2d_38/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[512], mreq=2,048
  Outputs:
StatefulPartitionedCall/model/batch_normalization_38/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_38/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 512, 26, 26], mreq=5,537,792
  Node Mreq: 21,334,016 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_14/LeakyRelu_14 | OpType: LeakyRelu] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_86/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_14/LeakyRelu_14:0
    StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_14/LeakyRelu_14:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,075,584 bytes

** Node: StatefulPartitionedCall/model/lambda_38/Exp | OpType: Exp] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_38/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 512, 26, 26], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_38/Exp:0
    StatefulPartitionedCall/model/lambda_38/Exp:0: dtype=FLOAT, shape=[4, 512, 26, 26], mreq=5,537,792
  Node Mreq: 11,075,584 bytes

** Node: StatefulPartitionedCall/model/lambda_38/add | OpType: Add] **
  Inputs:
    Transpose__1378:0: dtype=FLOAT, shape=[1, 1, 1, 1], mreq=4
    StatefulPartitionedCall/model/lambda_38/Exp:0: dtype=FLOAT, shape=[4, 512, 26, 26], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_38/add:0
    StatefulPartitionedCall/model/lambda_38/add:0: dtype=FLOAT, shape=[4, 512, 26, 26], mreq=5,537,792
  Node Mreq: 11,075,588 bytes

** Node: StatefulPartitionedCall/model/lambda_38/Log | OpType: Log] **
  Inputs:
    StatefulPartitionedCall/model/lambda_38/add:0: dtype=FLOAT, shape=[4, 512, 26, 26], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_38/Log:0
    StatefulPartitionedCall/model/lambda_38/Log:0: dtype=FLOAT, shape=[4, 512, 26, 26], mreq=5,537,792
  Node Mreq: 11,075,584 bytes

** Node: StatefulPartitionedCall/model/lambda_38/Tanh | OpType: Tanh] **
  Inputs:
    StatefulPartitionedCall/model/lambda_38/Log:0: dtype=FLOAT, shape=[4, 512, 26, 26], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_38/Tanh:0
    StatefulPartitionedCall/model/lambda_38/Tanh:0: dtype=FLOAT, shape=[4, 512, 26, 26], mreq=5,537,792
  Node Mreq: 11,075,584 bytes

** Node: StatefulPartitionedCall/model/lambda_38/mul | OpType: Mul] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_38/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 512, 26, 26], mreq=5,537,792
    StatefulPartitionedCall/model/lambda_38/Tanh:0: dtype=FLOAT, shape=[4, 512, 26, 26], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_38/mul:0
    StatefulPartitionedCall/model/lambda_38/mul:0: dtype=FLOAT, shape=[4, 512, 26, 26], mreq=5,537,792
  Node Mreq: 16,613,376 bytes

** Node: StatefulPartitionedCall/model/conv2d_40/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/lambda_38/mul:0: dtype=FLOAT, shape=[4, 512, 26, 26], mreq=5,537,792
    StatefulPartitionedCall/model/conv2d_40/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[256, 512, 1, 1], mreq=524,288
    StatefulPartitionedCall/model/conv2d_40/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[256], mreq=1,024
  Outputs:
StatefulPartitionedCall/model/batch_normalization_40/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_40/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 8,832,000 bytes

** Node: StatefulPartitionedCall/model/conv2d_39/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/lambda_38/mul:0: dtype=FLOAT, shape=[4, 512, 26, 26], mreq=5,537,792
    StatefulPartitionedCall/model/conv2d_39/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[256, 512, 1, 1], mreq=524,288
    StatefulPartitionedCall/model/conv2d_39/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[256], mreq=1,024
  Outputs:
StatefulPartitionedCall/model/batch_normalization_39/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_39/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 8,832,000 bytes

** Node: StatefulPartitionedCall/model/lambda_40/Exp | OpType: Exp] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_40/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_40/Exp:0
    StatefulPartitionedCall/model/lambda_40/Exp:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,537,792 bytes

** Node: StatefulPartitionedCall/model/lambda_39/Exp | OpType: Exp] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_39/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_39/Exp:0
    StatefulPartitionedCall/model/lambda_39/Exp:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,537,792 bytes

** Node: StatefulPartitionedCall/model/lambda_40/add | OpType: Add] **
  Inputs:
    Transpose__1378:0: dtype=FLOAT, shape=[1, 1, 1, 1], mreq=4
    StatefulPartitionedCall/model/lambda_40/Exp:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_40/add:0
    StatefulPartitionedCall/model/lambda_40/add:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,537,796 bytes

** Node: StatefulPartitionedCall/model/lambda_39/add | OpType: Add] **
  Inputs:
    Transpose__1378:0: dtype=FLOAT, shape=[1, 1, 1, 1], mreq=4
    StatefulPartitionedCall/model/lambda_39/Exp:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_39/add:0
    StatefulPartitionedCall/model/lambda_39/add:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,537,796 bytes

** Node: StatefulPartitionedCall/model/lambda_40/Log | OpType: Log] **
  Inputs:
    StatefulPartitionedCall/model/lambda_40/add:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_40/Log:0
    StatefulPartitionedCall/model/lambda_40/Log:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,537,792 bytes

** Node: StatefulPartitionedCall/model/lambda_39/Log | OpType: Log] **
  Inputs:
    StatefulPartitionedCall/model/lambda_39/add:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_39/Log:0
    StatefulPartitionedCall/model/lambda_39/Log:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,537,792 bytes

** Node: StatefulPartitionedCall/model/lambda_40/Tanh | OpType: Tanh] **
  Inputs:
    StatefulPartitionedCall/model/lambda_40/Log:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_40/Tanh:0
    StatefulPartitionedCall/model/lambda_40/Tanh:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,537,792 bytes

** Node: StatefulPartitionedCall/model/lambda_39/Tanh | OpType: Tanh] **
  Inputs:
    StatefulPartitionedCall/model/lambda_39/Log:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_39/Tanh:0
    StatefulPartitionedCall/model/lambda_39/Tanh:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,537,792 bytes

** Node: StatefulPartitionedCall/model/lambda_40/mul | OpType: Mul] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_40/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
    StatefulPartitionedCall/model/lambda_40/Tanh:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_40/mul:0
    StatefulPartitionedCall/model/lambda_40/mul:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 8,306,688 bytes

** Node: StatefulPartitionedCall/model/lambda_39/mul | OpType: Mul] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_39/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
    StatefulPartitionedCall/model/lambda_39/Tanh:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_39/mul:0
    StatefulPartitionedCall/model/lambda_39/mul:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 8,306,688 bytes

** Node: StatefulPartitionedCall/model/conv2d_41/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/lambda_40/mul:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
    StatefulPartitionedCall/model/conv2d_41/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[256, 256, 1, 1], mreq=262,144
    StatefulPartitionedCall/model/conv2d_41/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[256], mreq=1,024
  Outputs:
StatefulPartitionedCall/model/batch_normalization_41/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_41/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,800,960 bytes

** Node: StatefulPartitionedCall/model/lambda_41/Exp | OpType: Exp] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_41/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_41/Exp:0
    StatefulPartitionedCall/model/lambda_41/Exp:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,537,792 bytes

** Node: StatefulPartitionedCall/model/lambda_41/add | OpType: Add] **
  Inputs:
    Transpose__1378:0: dtype=FLOAT, shape=[1, 1, 1, 1], mreq=4
    StatefulPartitionedCall/model/lambda_41/Exp:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_41/add:0
    StatefulPartitionedCall/model/lambda_41/add:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,537,796 bytes

** Node: StatefulPartitionedCall/model/lambda_41/Log | OpType: Log] **
  Inputs:
    StatefulPartitionedCall/model/lambda_41/add:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_41/Log:0
    StatefulPartitionedCall/model/lambda_41/Log:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,537,792 bytes

** Node: StatefulPartitionedCall/model/lambda_41/Tanh | OpType: Tanh] **
  Inputs:
    StatefulPartitionedCall/model/lambda_41/Log:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_41/Tanh:0
    StatefulPartitionedCall/model/lambda_41/Tanh:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,537,792 bytes

** Node: StatefulPartitionedCall/model/lambda_41/mul | OpType: Mul] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_41/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
    StatefulPartitionedCall/model/lambda_41/Tanh:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_41/mul:0
    StatefulPartitionedCall/model/lambda_41/mul:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 8,306,688 bytes

** Node: StatefulPartitionedCall/model/conv2d_42/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/lambda_41/mul:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
    StatefulPartitionedCall/model/conv2d_42/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[256, 256, 3, 3], mreq=2,359,296
    StatefulPartitionedCall/model/conv2d_42/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[256], mreq=1,024
  Outputs:
StatefulPartitionedCall/model/batch_normalization_42/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_42/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 7,898,112 bytes

** Node: StatefulPartitionedCall/model/lambda_42/Exp | OpType: Exp] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_42/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_42/Exp:0
    StatefulPartitionedCall/model/lambda_42/Exp:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,537,792 bytes

** Node: StatefulPartitionedCall/model/lambda_42/add | OpType: Add] **
  Inputs:
    Transpose__1378:0: dtype=FLOAT, shape=[1, 1, 1, 1], mreq=4
    StatefulPartitionedCall/model/lambda_42/Exp:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_42/add:0
    StatefulPartitionedCall/model/lambda_42/add:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,537,796 bytes

** Node: StatefulPartitionedCall/model/lambda_42/Log | OpType: Log] **
  Inputs:
    StatefulPartitionedCall/model/lambda_42/add:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_42/Log:0
    StatefulPartitionedCall/model/lambda_42/Log:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,537,792 bytes

** Node: StatefulPartitionedCall/model/lambda_42/Tanh | OpType: Tanh] **
  Inputs:
    StatefulPartitionedCall/model/lambda_42/Log:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_42/Tanh:0
    StatefulPartitionedCall/model/lambda_42/Tanh:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,537,792 bytes

** Node: StatefulPartitionedCall/model/lambda_42/mul | OpType: Mul] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_42/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
    StatefulPartitionedCall/model/lambda_42/Tanh:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_42/mul:0
    StatefulPartitionedCall/model/lambda_42/mul:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 8,306,688 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_add_11/add_11 | OpType: Add] **
  Inputs:
    StatefulPartitionedCall/model/lambda_40/mul:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
    StatefulPartitionedCall/model/lambda_42/mul:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_add_11/add_11:0
    StatefulPartitionedCall/model/tf_op_layer_add_11/add_11:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 8,306,688 bytes

** Node: StatefulPartitionedCall/model/conv2d_43/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_add_11/add_11:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
    StatefulPartitionedCall/model/conv2d_43/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[256, 256, 1, 1], mreq=262,144
    StatefulPartitionedCall/model/conv2d_43/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[256], mreq=1,024
  Outputs:
StatefulPartitionedCall/model/batch_normalization_43/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_43/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,800,960 bytes

** Node: StatefulPartitionedCall/model/lambda_43/Exp | OpType: Exp] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_43/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_43/Exp:0
    StatefulPartitionedCall/model/lambda_43/Exp:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,537,792 bytes

** Node: StatefulPartitionedCall/model/lambda_43/add | OpType: Add] **
  Inputs:
    Transpose__1378:0: dtype=FLOAT, shape=[1, 1, 1, 1], mreq=4
    StatefulPartitionedCall/model/lambda_43/Exp:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_43/add:0
    StatefulPartitionedCall/model/lambda_43/add:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,537,796 bytes

** Node: StatefulPartitionedCall/model/lambda_43/Log | OpType: Log] **
  Inputs:
    StatefulPartitionedCall/model/lambda_43/add:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_43/Log:0
    StatefulPartitionedCall/model/lambda_43/Log:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,537,792 bytes

** Node: StatefulPartitionedCall/model/lambda_43/Tanh | OpType: Tanh] **
  Inputs:
    StatefulPartitionedCall/model/lambda_43/Log:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_43/Tanh:0
    StatefulPartitionedCall/model/lambda_43/Tanh:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,537,792 bytes

** Node: StatefulPartitionedCall/model/lambda_43/mul | OpType: Mul] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_43/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
    StatefulPartitionedCall/model/lambda_43/Tanh:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_43/mul:0
    StatefulPartitionedCall/model/lambda_43/mul:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 8,306,688 bytes

** Node: StatefulPartitionedCall/model/conv2d_44/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/lambda_43/mul:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
    StatefulPartitionedCall/model/conv2d_44/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[256, 256, 3, 3], mreq=2,359,296
    StatefulPartitionedCall/model/conv2d_44/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[256], mreq=1,024
  Outputs:
StatefulPartitionedCall/model/batch_normalization_44/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_44/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 7,898,112 bytes

** Node: StatefulPartitionedCall/model/lambda_44/Exp | OpType: Exp] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_44/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_44/Exp:0
    StatefulPartitionedCall/model/lambda_44/Exp:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,537,792 bytes

** Node: StatefulPartitionedCall/model/lambda_44/add | OpType: Add] **
  Inputs:
    Transpose__1378:0: dtype=FLOAT, shape=[1, 1, 1, 1], mreq=4
    StatefulPartitionedCall/model/lambda_44/Exp:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_44/add:0
    StatefulPartitionedCall/model/lambda_44/add:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,537,796 bytes

** Node: StatefulPartitionedCall/model/lambda_44/Log | OpType: Log] **
  Inputs:
    StatefulPartitionedCall/model/lambda_44/add:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_44/Log:0
    StatefulPartitionedCall/model/lambda_44/Log:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,537,792 bytes

** Node: StatefulPartitionedCall/model/lambda_44/Tanh | OpType: Tanh] **
  Inputs:
    StatefulPartitionedCall/model/lambda_44/Log:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_44/Tanh:0
    StatefulPartitionedCall/model/lambda_44/Tanh:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,537,792 bytes

** Node: StatefulPartitionedCall/model/lambda_44/mul | OpType: Mul] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_44/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
    StatefulPartitionedCall/model/lambda_44/Tanh:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_44/mul:0
    StatefulPartitionedCall/model/lambda_44/mul:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 8,306,688 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_add_12/add_12 | OpType: Add] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_add_11/add_11:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
    StatefulPartitionedCall/model/lambda_44/mul:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_add_12/add_12:0
    StatefulPartitionedCall/model/tf_op_layer_add_12/add_12:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 8,306,688 bytes

** Node: StatefulPartitionedCall/model/conv2d_45/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_add_12/add_12:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
    StatefulPartitionedCall/model/conv2d_45/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[256, 256, 1, 1], mreq=262,144
    StatefulPartitionedCall/model/conv2d_45/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[256], mreq=1,024
  Outputs:
StatefulPartitionedCall/model/batch_normalization_45/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_45/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,800,960 bytes

** Node: StatefulPartitionedCall/model/lambda_45/Exp | OpType: Exp] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_45/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_45/Exp:0
    StatefulPartitionedCall/model/lambda_45/Exp:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,537,792 bytes

** Node: StatefulPartitionedCall/model/lambda_45/add | OpType: Add] **
  Inputs:
    Transpose__1378:0: dtype=FLOAT, shape=[1, 1, 1, 1], mreq=4
    StatefulPartitionedCall/model/lambda_45/Exp:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_45/add:0
    StatefulPartitionedCall/model/lambda_45/add:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,537,796 bytes

** Node: StatefulPartitionedCall/model/lambda_45/Log | OpType: Log] **
  Inputs:
    StatefulPartitionedCall/model/lambda_45/add:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_45/Log:0
    StatefulPartitionedCall/model/lambda_45/Log:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,537,792 bytes

** Node: StatefulPartitionedCall/model/lambda_45/Tanh | OpType: Tanh] **
  Inputs:
    StatefulPartitionedCall/model/lambda_45/Log:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_45/Tanh:0
    StatefulPartitionedCall/model/lambda_45/Tanh:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,537,792 bytes

** Node: StatefulPartitionedCall/model/lambda_45/mul | OpType: Mul] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_45/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
    StatefulPartitionedCall/model/lambda_45/Tanh:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_45/mul:0
    StatefulPartitionedCall/model/lambda_45/mul:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 8,306,688 bytes

** Node: StatefulPartitionedCall/model/conv2d_46/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/lambda_45/mul:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
    StatefulPartitionedCall/model/conv2d_46/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[256, 256, 3, 3], mreq=2,359,296
    StatefulPartitionedCall/model/conv2d_46/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[256], mreq=1,024
  Outputs:
StatefulPartitionedCall/model/batch_normalization_46/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_46/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 7,898,112 bytes

** Node: StatefulPartitionedCall/model/lambda_46/Exp | OpType: Exp] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_46/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_46/Exp:0
    StatefulPartitionedCall/model/lambda_46/Exp:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,537,792 bytes

** Node: StatefulPartitionedCall/model/lambda_46/add | OpType: Add] **
  Inputs:
    Transpose__1378:0: dtype=FLOAT, shape=[1, 1, 1, 1], mreq=4
    StatefulPartitionedCall/model/lambda_46/Exp:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_46/add:0
    StatefulPartitionedCall/model/lambda_46/add:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,537,796 bytes

** Node: StatefulPartitionedCall/model/lambda_46/Log | OpType: Log] **
  Inputs:
    StatefulPartitionedCall/model/lambda_46/add:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_46/Log:0
    StatefulPartitionedCall/model/lambda_46/Log:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,537,792 bytes

** Node: StatefulPartitionedCall/model/lambda_46/Tanh | OpType: Tanh] **
  Inputs:
    StatefulPartitionedCall/model/lambda_46/Log:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_46/Tanh:0
    StatefulPartitionedCall/model/lambda_46/Tanh:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,537,792 bytes

** Node: StatefulPartitionedCall/model/lambda_46/mul | OpType: Mul] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_46/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
    StatefulPartitionedCall/model/lambda_46/Tanh:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_46/mul:0
    StatefulPartitionedCall/model/lambda_46/mul:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 8,306,688 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_add_13/add_13 | OpType: Add] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_add_12/add_12:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
    StatefulPartitionedCall/model/lambda_46/mul:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_add_13/add_13:0
    StatefulPartitionedCall/model/tf_op_layer_add_13/add_13:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 8,306,688 bytes

** Node: StatefulPartitionedCall/model/conv2d_47/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_add_13/add_13:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
    StatefulPartitionedCall/model/conv2d_47/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[256, 256, 1, 1], mreq=262,144
    StatefulPartitionedCall/model/conv2d_47/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[256], mreq=1,024
  Outputs:
StatefulPartitionedCall/model/batch_normalization_47/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_47/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,800,960 bytes

** Node: StatefulPartitionedCall/model/lambda_47/Exp | OpType: Exp] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_47/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_47/Exp:0
    StatefulPartitionedCall/model/lambda_47/Exp:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,537,792 bytes

** Node: StatefulPartitionedCall/model/lambda_47/add | OpType: Add] **
  Inputs:
    Transpose__1378:0: dtype=FLOAT, shape=[1, 1, 1, 1], mreq=4
    StatefulPartitionedCall/model/lambda_47/Exp:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_47/add:0
    StatefulPartitionedCall/model/lambda_47/add:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,537,796 bytes

** Node: StatefulPartitionedCall/model/lambda_47/Log | OpType: Log] **
  Inputs:
    StatefulPartitionedCall/model/lambda_47/add:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_47/Log:0
    StatefulPartitionedCall/model/lambda_47/Log:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,537,792 bytes

** Node: StatefulPartitionedCall/model/lambda_47/Tanh | OpType: Tanh] **
  Inputs:
    StatefulPartitionedCall/model/lambda_47/Log:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_47/Tanh:0
    StatefulPartitionedCall/model/lambda_47/Tanh:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,537,792 bytes

** Node: StatefulPartitionedCall/model/lambda_47/mul | OpType: Mul] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_47/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
    StatefulPartitionedCall/model/lambda_47/Tanh:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_47/mul:0
    StatefulPartitionedCall/model/lambda_47/mul:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 8,306,688 bytes

** Node: StatefulPartitionedCall/model/conv2d_48/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/lambda_47/mul:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
    StatefulPartitionedCall/model/conv2d_48/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[256, 256, 3, 3], mreq=2,359,296
    StatefulPartitionedCall/model/conv2d_48/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[256], mreq=1,024
  Outputs:
StatefulPartitionedCall/model/batch_normalization_48/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_48/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 7,898,112 bytes

** Node: StatefulPartitionedCall/model/lambda_48/Exp | OpType: Exp] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_48/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_48/Exp:0
    StatefulPartitionedCall/model/lambda_48/Exp:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,537,792 bytes

** Node: StatefulPartitionedCall/model/lambda_48/add | OpType: Add] **
  Inputs:
    Transpose__1378:0: dtype=FLOAT, shape=[1, 1, 1, 1], mreq=4
    StatefulPartitionedCall/model/lambda_48/Exp:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_48/add:0
    StatefulPartitionedCall/model/lambda_48/add:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,537,796 bytes

** Node: StatefulPartitionedCall/model/lambda_48/Log | OpType: Log] **
  Inputs:
    StatefulPartitionedCall/model/lambda_48/add:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_48/Log:0
    StatefulPartitionedCall/model/lambda_48/Log:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,537,792 bytes

** Node: StatefulPartitionedCall/model/lambda_48/Tanh | OpType: Tanh] **
  Inputs:
    StatefulPartitionedCall/model/lambda_48/Log:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_48/Tanh:0
    StatefulPartitionedCall/model/lambda_48/Tanh:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,537,792 bytes

** Node: StatefulPartitionedCall/model/lambda_48/mul | OpType: Mul] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_48/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
    StatefulPartitionedCall/model/lambda_48/Tanh:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_48/mul:0
    StatefulPartitionedCall/model/lambda_48/mul:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 8,306,688 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_add_14/add_14 | OpType: Add] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_add_13/add_13:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
    StatefulPartitionedCall/model/lambda_48/mul:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_add_14/add_14:0
    StatefulPartitionedCall/model/tf_op_layer_add_14/add_14:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 8,306,688 bytes

** Node: StatefulPartitionedCall/model/conv2d_49/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_add_14/add_14:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
    StatefulPartitionedCall/model/conv2d_49/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[256, 256, 1, 1], mreq=262,144
    StatefulPartitionedCall/model/conv2d_49/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[256], mreq=1,024
  Outputs:
StatefulPartitionedCall/model/batch_normalization_49/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_49/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,800,960 bytes

** Node: StatefulPartitionedCall/model/lambda_49/Exp | OpType: Exp] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_49/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_49/Exp:0
    StatefulPartitionedCall/model/lambda_49/Exp:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,537,792 bytes

** Node: StatefulPartitionedCall/model/lambda_49/add | OpType: Add] **
  Inputs:
    Transpose__1378:0: dtype=FLOAT, shape=[1, 1, 1, 1], mreq=4
    StatefulPartitionedCall/model/lambda_49/Exp:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_49/add:0
    StatefulPartitionedCall/model/lambda_49/add:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,537,796 bytes

** Node: StatefulPartitionedCall/model/lambda_49/Log | OpType: Log] **
  Inputs:
    StatefulPartitionedCall/model/lambda_49/add:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_49/Log:0
    StatefulPartitionedCall/model/lambda_49/Log:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,537,792 bytes

** Node: StatefulPartitionedCall/model/lambda_49/Tanh | OpType: Tanh] **
  Inputs:
    StatefulPartitionedCall/model/lambda_49/Log:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_49/Tanh:0
    StatefulPartitionedCall/model/lambda_49/Tanh:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,537,792 bytes

** Node: StatefulPartitionedCall/model/lambda_49/mul | OpType: Mul] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_49/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
    StatefulPartitionedCall/model/lambda_49/Tanh:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_49/mul:0
    StatefulPartitionedCall/model/lambda_49/mul:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 8,306,688 bytes

** Node: StatefulPartitionedCall/model/conv2d_50/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/lambda_49/mul:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
    StatefulPartitionedCall/model/conv2d_50/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[256, 256, 3, 3], mreq=2,359,296
    StatefulPartitionedCall/model/conv2d_50/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[256], mreq=1,024
  Outputs:
StatefulPartitionedCall/model/batch_normalization_50/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_50/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 7,898,112 bytes

** Node: StatefulPartitionedCall/model/lambda_50/Exp | OpType: Exp] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_50/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_50/Exp:0
    StatefulPartitionedCall/model/lambda_50/Exp:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,537,792 bytes

** Node: StatefulPartitionedCall/model/lambda_50/add | OpType: Add] **
  Inputs:
    Transpose__1378:0: dtype=FLOAT, shape=[1, 1, 1, 1], mreq=4
    StatefulPartitionedCall/model/lambda_50/Exp:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_50/add:0
    StatefulPartitionedCall/model/lambda_50/add:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,537,796 bytes

** Node: StatefulPartitionedCall/model/lambda_50/Log | OpType: Log] **
  Inputs:
    StatefulPartitionedCall/model/lambda_50/add:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_50/Log:0
    StatefulPartitionedCall/model/lambda_50/Log:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,537,792 bytes

** Node: StatefulPartitionedCall/model/lambda_50/Tanh | OpType: Tanh] **
  Inputs:
    StatefulPartitionedCall/model/lambda_50/Log:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_50/Tanh:0
    StatefulPartitionedCall/model/lambda_50/Tanh:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,537,792 bytes

** Node: StatefulPartitionedCall/model/lambda_50/mul | OpType: Mul] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_50/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
    StatefulPartitionedCall/model/lambda_50/Tanh:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_50/mul:0
    StatefulPartitionedCall/model/lambda_50/mul:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 8,306,688 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_add_15/add_15 | OpType: Add] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_add_14/add_14:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
    StatefulPartitionedCall/model/lambda_50/mul:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_add_15/add_15:0
    StatefulPartitionedCall/model/tf_op_layer_add_15/add_15:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 8,306,688 bytes

** Node: StatefulPartitionedCall/model/conv2d_51/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_add_15/add_15:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
    StatefulPartitionedCall/model/conv2d_51/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[256, 256, 1, 1], mreq=262,144
    StatefulPartitionedCall/model/conv2d_51/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[256], mreq=1,024
  Outputs:
StatefulPartitionedCall/model/batch_normalization_51/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_51/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,800,960 bytes

** Node: StatefulPartitionedCall/model/lambda_51/Exp | OpType: Exp] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_51/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_51/Exp:0
    StatefulPartitionedCall/model/lambda_51/Exp:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,537,792 bytes

** Node: StatefulPartitionedCall/model/lambda_51/add | OpType: Add] **
  Inputs:
    Transpose__1378:0: dtype=FLOAT, shape=[1, 1, 1, 1], mreq=4
    StatefulPartitionedCall/model/lambda_51/Exp:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_51/add:0
    StatefulPartitionedCall/model/lambda_51/add:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,537,796 bytes

** Node: StatefulPartitionedCall/model/lambda_51/Log | OpType: Log] **
  Inputs:
    StatefulPartitionedCall/model/lambda_51/add:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_51/Log:0
    StatefulPartitionedCall/model/lambda_51/Log:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,537,792 bytes

** Node: StatefulPartitionedCall/model/lambda_51/Tanh | OpType: Tanh] **
  Inputs:
    StatefulPartitionedCall/model/lambda_51/Log:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_51/Tanh:0
    StatefulPartitionedCall/model/lambda_51/Tanh:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,537,792 bytes

** Node: StatefulPartitionedCall/model/lambda_51/mul | OpType: Mul] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_51/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
    StatefulPartitionedCall/model/lambda_51/Tanh:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_51/mul:0
    StatefulPartitionedCall/model/lambda_51/mul:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 8,306,688 bytes

** Node: StatefulPartitionedCall/model/conv2d_52/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/lambda_51/mul:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
    StatefulPartitionedCall/model/conv2d_52/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[256, 256, 3, 3], mreq=2,359,296
    StatefulPartitionedCall/model/conv2d_52/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[256], mreq=1,024
  Outputs:
StatefulPartitionedCall/model/batch_normalization_52/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_52/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 7,898,112 bytes

** Node: StatefulPartitionedCall/model/lambda_52/Exp | OpType: Exp] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_52/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_52/Exp:0
    StatefulPartitionedCall/model/lambda_52/Exp:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,537,792 bytes

** Node: StatefulPartitionedCall/model/lambda_52/add | OpType: Add] **
  Inputs:
    Transpose__1378:0: dtype=FLOAT, shape=[1, 1, 1, 1], mreq=4
    StatefulPartitionedCall/model/lambda_52/Exp:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_52/add:0
    StatefulPartitionedCall/model/lambda_52/add:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,537,796 bytes

** Node: StatefulPartitionedCall/model/lambda_52/Log | OpType: Log] **
  Inputs:
    StatefulPartitionedCall/model/lambda_52/add:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_52/Log:0
    StatefulPartitionedCall/model/lambda_52/Log:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,537,792 bytes

** Node: StatefulPartitionedCall/model/lambda_52/Tanh | OpType: Tanh] **
  Inputs:
    StatefulPartitionedCall/model/lambda_52/Log:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_52/Tanh:0
    StatefulPartitionedCall/model/lambda_52/Tanh:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,537,792 bytes

** Node: StatefulPartitionedCall/model/lambda_52/mul | OpType: Mul] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_52/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
    StatefulPartitionedCall/model/lambda_52/Tanh:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_52/mul:0
    StatefulPartitionedCall/model/lambda_52/mul:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 8,306,688 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_add_16/add_16 | OpType: Add] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_add_15/add_15:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
    StatefulPartitionedCall/model/lambda_52/mul:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_add_16/add_16:0
    StatefulPartitionedCall/model/tf_op_layer_add_16/add_16:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 8,306,688 bytes

** Node: StatefulPartitionedCall/model/conv2d_53/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_add_16/add_16:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
    StatefulPartitionedCall/model/conv2d_53/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[256, 256, 1, 1], mreq=262,144
    StatefulPartitionedCall/model/conv2d_53/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[256], mreq=1,024
  Outputs:
StatefulPartitionedCall/model/batch_normalization_53/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_53/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,800,960 bytes

** Node: StatefulPartitionedCall/model/lambda_53/Exp | OpType: Exp] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_53/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_53/Exp:0
    StatefulPartitionedCall/model/lambda_53/Exp:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,537,792 bytes

** Node: StatefulPartitionedCall/model/lambda_53/add | OpType: Add] **
  Inputs:
    Transpose__1378:0: dtype=FLOAT, shape=[1, 1, 1, 1], mreq=4
    StatefulPartitionedCall/model/lambda_53/Exp:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_53/add:0
    StatefulPartitionedCall/model/lambda_53/add:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,537,796 bytes

** Node: StatefulPartitionedCall/model/lambda_53/Log | OpType: Log] **
  Inputs:
    StatefulPartitionedCall/model/lambda_53/add:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_53/Log:0
    StatefulPartitionedCall/model/lambda_53/Log:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,537,792 bytes

** Node: StatefulPartitionedCall/model/lambda_53/Tanh | OpType: Tanh] **
  Inputs:
    StatefulPartitionedCall/model/lambda_53/Log:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_53/Tanh:0
    StatefulPartitionedCall/model/lambda_53/Tanh:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,537,792 bytes

** Node: StatefulPartitionedCall/model/lambda_53/mul | OpType: Mul] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_53/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
    StatefulPartitionedCall/model/lambda_53/Tanh:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_53/mul:0
    StatefulPartitionedCall/model/lambda_53/mul:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 8,306,688 bytes

** Node: StatefulPartitionedCall/model/conv2d_54/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/lambda_53/mul:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
    StatefulPartitionedCall/model/conv2d_54/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[256, 256, 3, 3], mreq=2,359,296
    StatefulPartitionedCall/model/conv2d_54/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[256], mreq=1,024
  Outputs:
StatefulPartitionedCall/model/batch_normalization_54/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_54/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 7,898,112 bytes

** Node: StatefulPartitionedCall/model/lambda_54/Exp | OpType: Exp] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_54/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_54/Exp:0
    StatefulPartitionedCall/model/lambda_54/Exp:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,537,792 bytes

** Node: StatefulPartitionedCall/model/lambda_54/add | OpType: Add] **
  Inputs:
    Transpose__1378:0: dtype=FLOAT, shape=[1, 1, 1, 1], mreq=4
    StatefulPartitionedCall/model/lambda_54/Exp:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_54/add:0
    StatefulPartitionedCall/model/lambda_54/add:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,537,796 bytes

** Node: StatefulPartitionedCall/model/lambda_54/Log | OpType: Log] **
  Inputs:
    StatefulPartitionedCall/model/lambda_54/add:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_54/Log:0
    StatefulPartitionedCall/model/lambda_54/Log:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,537,792 bytes

** Node: StatefulPartitionedCall/model/lambda_54/Tanh | OpType: Tanh] **
  Inputs:
    StatefulPartitionedCall/model/lambda_54/Log:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_54/Tanh:0
    StatefulPartitionedCall/model/lambda_54/Tanh:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,537,792 bytes

** Node: StatefulPartitionedCall/model/lambda_54/mul | OpType: Mul] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_54/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
    StatefulPartitionedCall/model/lambda_54/Tanh:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_54/mul:0
    StatefulPartitionedCall/model/lambda_54/mul:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 8,306,688 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_add_17/add_17 | OpType: Add] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_add_16/add_16:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
    StatefulPartitionedCall/model/lambda_54/mul:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_add_17/add_17:0
    StatefulPartitionedCall/model/tf_op_layer_add_17/add_17:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 8,306,688 bytes

** Node: StatefulPartitionedCall/model/conv2d_55/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_add_17/add_17:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
    StatefulPartitionedCall/model/conv2d_55/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[256, 256, 1, 1], mreq=262,144
    StatefulPartitionedCall/model/conv2d_55/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[256], mreq=1,024
  Outputs:
StatefulPartitionedCall/model/batch_normalization_55/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_55/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,800,960 bytes

** Node: StatefulPartitionedCall/model/lambda_55/Exp | OpType: Exp] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_55/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_55/Exp:0
    StatefulPartitionedCall/model/lambda_55/Exp:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,537,792 bytes

** Node: StatefulPartitionedCall/model/lambda_55/add | OpType: Add] **
  Inputs:
    Transpose__1378:0: dtype=FLOAT, shape=[1, 1, 1, 1], mreq=4
    StatefulPartitionedCall/model/lambda_55/Exp:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_55/add:0
    StatefulPartitionedCall/model/lambda_55/add:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,537,796 bytes

** Node: StatefulPartitionedCall/model/lambda_55/Log | OpType: Log] **
  Inputs:
    StatefulPartitionedCall/model/lambda_55/add:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_55/Log:0
    StatefulPartitionedCall/model/lambda_55/Log:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,537,792 bytes

** Node: StatefulPartitionedCall/model/lambda_55/Tanh | OpType: Tanh] **
  Inputs:
    StatefulPartitionedCall/model/lambda_55/Log:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_55/Tanh:0
    StatefulPartitionedCall/model/lambda_55/Tanh:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,537,792 bytes

** Node: StatefulPartitionedCall/model/lambda_55/mul | OpType: Mul] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_55/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
    StatefulPartitionedCall/model/lambda_55/Tanh:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_55/mul:0
    StatefulPartitionedCall/model/lambda_55/mul:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 8,306,688 bytes

** Node: StatefulPartitionedCall/model/conv2d_56/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/lambda_55/mul:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
    StatefulPartitionedCall/model/conv2d_56/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[256, 256, 3, 3], mreq=2,359,296
    StatefulPartitionedCall/model/conv2d_56/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[256], mreq=1,024
  Outputs:
StatefulPartitionedCall/model/batch_normalization_56/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_56/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 7,898,112 bytes

** Node: StatefulPartitionedCall/model/lambda_56/Exp | OpType: Exp] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_56/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_56/Exp:0
    StatefulPartitionedCall/model/lambda_56/Exp:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,537,792 bytes

** Node: StatefulPartitionedCall/model/lambda_56/add | OpType: Add] **
  Inputs:
    Transpose__1378:0: dtype=FLOAT, shape=[1, 1, 1, 1], mreq=4
    StatefulPartitionedCall/model/lambda_56/Exp:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_56/add:0
    StatefulPartitionedCall/model/lambda_56/add:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,537,796 bytes

** Node: StatefulPartitionedCall/model/lambda_56/Log | OpType: Log] **
  Inputs:
    StatefulPartitionedCall/model/lambda_56/add:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_56/Log:0
    StatefulPartitionedCall/model/lambda_56/Log:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,537,792 bytes

** Node: StatefulPartitionedCall/model/lambda_56/Tanh | OpType: Tanh] **
  Inputs:
    StatefulPartitionedCall/model/lambda_56/Log:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_56/Tanh:0
    StatefulPartitionedCall/model/lambda_56/Tanh:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,537,792 bytes

** Node: StatefulPartitionedCall/model/lambda_56/mul | OpType: Mul] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_56/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
    StatefulPartitionedCall/model/lambda_56/Tanh:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_56/mul:0
    StatefulPartitionedCall/model/lambda_56/mul:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 8,306,688 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_add_18/add_18 | OpType: Add] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_add_17/add_17:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
    StatefulPartitionedCall/model/lambda_56/mul:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_add_18/add_18:0
    StatefulPartitionedCall/model/tf_op_layer_add_18/add_18:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 8,306,688 bytes

** Node: StatefulPartitionedCall/model/conv2d_57/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_add_18/add_18:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
    StatefulPartitionedCall/model/conv2d_57/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[256, 256, 1, 1], mreq=262,144
    StatefulPartitionedCall/model/conv2d_57/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[256], mreq=1,024
  Outputs:
StatefulPartitionedCall/model/batch_normalization_57/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_57/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,800,960 bytes

** Node: StatefulPartitionedCall/model/lambda_57/Exp | OpType: Exp] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_57/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_57/Exp:0
    StatefulPartitionedCall/model/lambda_57/Exp:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,537,792 bytes

** Node: StatefulPartitionedCall/model/lambda_57/add | OpType: Add] **
  Inputs:
    Transpose__1378:0: dtype=FLOAT, shape=[1, 1, 1, 1], mreq=4
    StatefulPartitionedCall/model/lambda_57/Exp:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_57/add:0
    StatefulPartitionedCall/model/lambda_57/add:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,537,796 bytes

** Node: StatefulPartitionedCall/model/lambda_57/Log | OpType: Log] **
  Inputs:
    StatefulPartitionedCall/model/lambda_57/add:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_57/Log:0
    StatefulPartitionedCall/model/lambda_57/Log:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,537,792 bytes

** Node: StatefulPartitionedCall/model/lambda_57/Tanh | OpType: Tanh] **
  Inputs:
    StatefulPartitionedCall/model/lambda_57/Log:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_57/Tanh:0
    StatefulPartitionedCall/model/lambda_57/Tanh:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,537,792 bytes

** Node: StatefulPartitionedCall/model/lambda_57/mul | OpType: Mul] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_57/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
    StatefulPartitionedCall/model/lambda_57/Tanh:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_57/mul:0
    StatefulPartitionedCall/model/lambda_57/mul:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 8,306,688 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_concat_3/concat_3 | OpType: Concat] **
  Inputs:
    StatefulPartitionedCall/model/lambda_57/mul:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
    StatefulPartitionedCall/model/lambda_39/mul:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_concat_3/concat_3:0
    StatefulPartitionedCall/model/tf_op_layer_concat_3/concat_3:0: dtype=FLOAT, shape=[4, 512, 26, 26], mreq=5,537,792
  Node Mreq: 11,075,584 bytes

** Node: StatefulPartitionedCall/model/conv2d_58/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_concat_3/concat_3:0: dtype=FLOAT, shape=[4, 512, 26, 26], mreq=5,537,792
    StatefulPartitionedCall/model/conv2d_58/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[512, 512, 1, 1], mreq=1,048,576
    StatefulPartitionedCall/model/conv2d_58/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[512], mreq=2,048
  Outputs:
StatefulPartitionedCall/model/batch_normalization_58/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_58/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 512, 26, 26], mreq=5,537,792
  Node Mreq: 12,126,208 bytes

** Node: StatefulPartitionedCall/model/lambda_58/Exp | OpType: Exp] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_58/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 512, 26, 26], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_58/Exp:0
    StatefulPartitionedCall/model/lambda_58/Exp:0: dtype=FLOAT, shape=[4, 512, 26, 26], mreq=5,537,792
  Node Mreq: 11,075,584 bytes

** Node: StatefulPartitionedCall/model/lambda_58/add | OpType: Add] **
  Inputs:
    Transpose__1378:0: dtype=FLOAT, shape=[1, 1, 1, 1], mreq=4
    StatefulPartitionedCall/model/lambda_58/Exp:0: dtype=FLOAT, shape=[4, 512, 26, 26], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_58/add:0
    StatefulPartitionedCall/model/lambda_58/add:0: dtype=FLOAT, shape=[4, 512, 26, 26], mreq=5,537,792
  Node Mreq: 11,075,588 bytes

** Node: StatefulPartitionedCall/model/lambda_58/Log | OpType: Log] **
  Inputs:
    StatefulPartitionedCall/model/lambda_58/add:0: dtype=FLOAT, shape=[4, 512, 26, 26], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_58/Log:0
    StatefulPartitionedCall/model/lambda_58/Log:0: dtype=FLOAT, shape=[4, 512, 26, 26], mreq=5,537,792
  Node Mreq: 11,075,584 bytes

** Node: StatefulPartitionedCall/model/lambda_58/Tanh | OpType: Tanh] **
  Inputs:
    StatefulPartitionedCall/model/lambda_58/Log:0: dtype=FLOAT, shape=[4, 512, 26, 26], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_58/Tanh:0
    StatefulPartitionedCall/model/lambda_58/Tanh:0: dtype=FLOAT, shape=[4, 512, 26, 26], mreq=5,537,792
  Node Mreq: 11,075,584 bytes

** Node: StatefulPartitionedCall/model/lambda_58/mul | OpType: Mul] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_58/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 512, 26, 26], mreq=5,537,792
    StatefulPartitionedCall/model/lambda_58/Tanh:0: dtype=FLOAT, shape=[4, 512, 26, 26], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/lambda_58/mul:0
    StatefulPartitionedCall/model/lambda_58/mul:0: dtype=FLOAT, shape=[4, 512, 26, 26], mreq=5,537,792
  Node Mreq: 16,613,376 bytes

** Node: StatefulPartitionedCall/model/conv2d_79/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/lambda_58/mul:0: dtype=FLOAT, shape=[4, 512, 26, 26], mreq=5,537,792
    StatefulPartitionedCall/model/conv2d_79/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[256, 512, 1, 1], mreq=524,288
    StatefulPartitionedCall/model/conv2d_79/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[256], mreq=1,024
  Outputs:
StatefulPartitionedCall/model/batch_normalization_79/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_79/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 8,832,000 bytes

** Node: StatefulPartitionedCall/model/conv2d_59/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/lambda_58/mul:0: dtype=FLOAT, shape=[4, 512, 26, 26], mreq=5,537,792
    StatefulPartitionedCall/model/conv2d_59/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[1024, 512, 3, 3], mreq=18,874,368
    StatefulPartitionedCall/model/conv2d_59/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[1024], mreq=4,096
  Outputs:
StatefulPartitionedCall/model/batch_normalization_59/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_59/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 1024, 13, 13], mreq=2,768,896
  Node Mreq: 27,185,152 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_7/LeakyRelu_7 | OpType: LeakyRelu] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_79/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_7/LeakyRelu_7:0
    StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_7/LeakyRelu_7:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,537,792 bytes

** Node: StatefulPartitionedCall/model/lambda_59/Exp | OpType: Exp] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_59/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 1024, 13, 13], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_59/Exp:0
    StatefulPartitionedCall/model/lambda_59/Exp:0: dtype=FLOAT, shape=[4, 1024, 13, 13], mreq=2,768,896
  Node Mreq: 5,537,792 bytes

** Node: StatefulPartitionedCall/model/lambda_59/add | OpType: Add] **
  Inputs:
    Transpose__1378:0: dtype=FLOAT, shape=[1, 1, 1, 1], mreq=4
    StatefulPartitionedCall/model/lambda_59/Exp:0: dtype=FLOAT, shape=[4, 1024, 13, 13], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_59/add:0
    StatefulPartitionedCall/model/lambda_59/add:0: dtype=FLOAT, shape=[4, 1024, 13, 13], mreq=2,768,896
  Node Mreq: 5,537,796 bytes

** Node: StatefulPartitionedCall/model/lambda_59/Log | OpType: Log] **
  Inputs:
    StatefulPartitionedCall/model/lambda_59/add:0: dtype=FLOAT, shape=[4, 1024, 13, 13], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_59/Log:0
    StatefulPartitionedCall/model/lambda_59/Log:0: dtype=FLOAT, shape=[4, 1024, 13, 13], mreq=2,768,896
  Node Mreq: 5,537,792 bytes

** Node: StatefulPartitionedCall/model/lambda_59/Tanh | OpType: Tanh] **
  Inputs:
    StatefulPartitionedCall/model/lambda_59/Log:0: dtype=FLOAT, shape=[4, 1024, 13, 13], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_59/Tanh:0
    StatefulPartitionedCall/model/lambda_59/Tanh:0: dtype=FLOAT, shape=[4, 1024, 13, 13], mreq=2,768,896
  Node Mreq: 5,537,792 bytes

** Node: StatefulPartitionedCall/model/lambda_59/mul | OpType: Mul] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_59/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 1024, 13, 13], mreq=2,768,896
    StatefulPartitionedCall/model/lambda_59/Tanh:0: dtype=FLOAT, shape=[4, 1024, 13, 13], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_59/mul:0
    StatefulPartitionedCall/model/lambda_59/mul:0: dtype=FLOAT, shape=[4, 1024, 13, 13], mreq=2,768,896
  Node Mreq: 8,306,688 bytes

** Node: StatefulPartitionedCall/model/conv2d_61/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/lambda_59/mul:0: dtype=FLOAT, shape=[4, 1024, 13, 13], mreq=2,768,896
    StatefulPartitionedCall/model/conv2d_61/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[512, 1024, 1, 1], mreq=2,097,152
    StatefulPartitionedCall/model/conv2d_61/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[512], mreq=2,048
  Outputs:
StatefulPartitionedCall/model/batch_normalization_61/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_61/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Node Mreq: 6,252,544 bytes

** Node: StatefulPartitionedCall/model/conv2d_60/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/lambda_59/mul:0: dtype=FLOAT, shape=[4, 1024, 13, 13], mreq=2,768,896
    StatefulPartitionedCall/model/conv2d_60/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[512, 1024, 1, 1], mreq=2,097,152
    StatefulPartitionedCall/model/conv2d_60/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[512], mreq=2,048
  Outputs:
StatefulPartitionedCall/model/batch_normalization_60/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_60/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Node Mreq: 6,252,544 bytes

** Node: StatefulPartitionedCall/model/lambda_61/Exp | OpType: Exp] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_61/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Outputs:
StatefulPartitionedCall/model/lambda_61/Exp:0
    StatefulPartitionedCall/model/lambda_61/Exp:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Node Mreq: 2,768,896 bytes

** Node: StatefulPartitionedCall/model/lambda_60/Exp | OpType: Exp] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_60/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Outputs:
StatefulPartitionedCall/model/lambda_60/Exp:0
    StatefulPartitionedCall/model/lambda_60/Exp:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Node Mreq: 2,768,896 bytes

** Node: StatefulPartitionedCall/model/lambda_61/add | OpType: Add] **
  Inputs:
    Transpose__1378:0: dtype=FLOAT, shape=[1, 1, 1, 1], mreq=4
    StatefulPartitionedCall/model/lambda_61/Exp:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Outputs:
StatefulPartitionedCall/model/lambda_61/add:0
    StatefulPartitionedCall/model/lambda_61/add:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Node Mreq: 2,768,900 bytes

** Node: StatefulPartitionedCall/model/lambda_60/add | OpType: Add] **
  Inputs:
    Transpose__1378:0: dtype=FLOAT, shape=[1, 1, 1, 1], mreq=4
    StatefulPartitionedCall/model/lambda_60/Exp:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Outputs:
StatefulPartitionedCall/model/lambda_60/add:0
    StatefulPartitionedCall/model/lambda_60/add:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Node Mreq: 2,768,900 bytes

** Node: StatefulPartitionedCall/model/lambda_61/Log | OpType: Log] **
  Inputs:
    StatefulPartitionedCall/model/lambda_61/add:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Outputs:
StatefulPartitionedCall/model/lambda_61/Log:0
    StatefulPartitionedCall/model/lambda_61/Log:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Node Mreq: 2,768,896 bytes

** Node: StatefulPartitionedCall/model/lambda_60/Log | OpType: Log] **
  Inputs:
    StatefulPartitionedCall/model/lambda_60/add:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Outputs:
StatefulPartitionedCall/model/lambda_60/Log:0
    StatefulPartitionedCall/model/lambda_60/Log:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Node Mreq: 2,768,896 bytes

** Node: StatefulPartitionedCall/model/lambda_61/Tanh | OpType: Tanh] **
  Inputs:
    StatefulPartitionedCall/model/lambda_61/Log:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Outputs:
StatefulPartitionedCall/model/lambda_61/Tanh:0
    StatefulPartitionedCall/model/lambda_61/Tanh:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Node Mreq: 2,768,896 bytes

** Node: StatefulPartitionedCall/model/lambda_60/Tanh | OpType: Tanh] **
  Inputs:
    StatefulPartitionedCall/model/lambda_60/Log:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Outputs:
StatefulPartitionedCall/model/lambda_60/Tanh:0
    StatefulPartitionedCall/model/lambda_60/Tanh:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Node Mreq: 2,768,896 bytes

** Node: StatefulPartitionedCall/model/lambda_61/mul | OpType: Mul] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_61/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
    StatefulPartitionedCall/model/lambda_61/Tanh:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Outputs:
StatefulPartitionedCall/model/lambda_61/mul:0
    StatefulPartitionedCall/model/lambda_61/mul:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Node Mreq: 4,153,344 bytes

** Node: StatefulPartitionedCall/model/lambda_60/mul | OpType: Mul] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_60/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
    StatefulPartitionedCall/model/lambda_60/Tanh:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Outputs:
StatefulPartitionedCall/model/lambda_60/mul:0
    StatefulPartitionedCall/model/lambda_60/mul:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Node Mreq: 4,153,344 bytes

** Node: StatefulPartitionedCall/model/conv2d_62/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/lambda_61/mul:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
    StatefulPartitionedCall/model/conv2d_62/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[512, 512, 1, 1], mreq=1,048,576
    StatefulPartitionedCall/model/conv2d_62/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[512], mreq=2,048
  Outputs:
StatefulPartitionedCall/model/batch_normalization_62/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_62/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Node Mreq: 3,819,520 bytes

** Node: StatefulPartitionedCall/model/lambda_62/Exp | OpType: Exp] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_62/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Outputs:
StatefulPartitionedCall/model/lambda_62/Exp:0
    StatefulPartitionedCall/model/lambda_62/Exp:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Node Mreq: 2,768,896 bytes

** Node: StatefulPartitionedCall/model/lambda_62/add | OpType: Add] **
  Inputs:
    Transpose__1378:0: dtype=FLOAT, shape=[1, 1, 1, 1], mreq=4
    StatefulPartitionedCall/model/lambda_62/Exp:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Outputs:
StatefulPartitionedCall/model/lambda_62/add:0
    StatefulPartitionedCall/model/lambda_62/add:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Node Mreq: 2,768,900 bytes

** Node: StatefulPartitionedCall/model/lambda_62/Log | OpType: Log] **
  Inputs:
    StatefulPartitionedCall/model/lambda_62/add:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Outputs:
StatefulPartitionedCall/model/lambda_62/Log:0
    StatefulPartitionedCall/model/lambda_62/Log:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Node Mreq: 2,768,896 bytes

** Node: StatefulPartitionedCall/model/lambda_62/Tanh | OpType: Tanh] **
  Inputs:
    StatefulPartitionedCall/model/lambda_62/Log:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Outputs:
StatefulPartitionedCall/model/lambda_62/Tanh:0
    StatefulPartitionedCall/model/lambda_62/Tanh:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Node Mreq: 2,768,896 bytes

** Node: StatefulPartitionedCall/model/lambda_62/mul | OpType: Mul] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_62/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
    StatefulPartitionedCall/model/lambda_62/Tanh:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Outputs:
StatefulPartitionedCall/model/lambda_62/mul:0
    StatefulPartitionedCall/model/lambda_62/mul:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Node Mreq: 4,153,344 bytes

** Node: StatefulPartitionedCall/model/conv2d_63/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/lambda_62/mul:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
    StatefulPartitionedCall/model/conv2d_63/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[512, 512, 3, 3], mreq=9,437,184
    StatefulPartitionedCall/model/conv2d_63/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[512], mreq=2,048
  Outputs:
StatefulPartitionedCall/model/batch_normalization_63/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_63/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Node Mreq: 12,208,128 bytes

** Node: StatefulPartitionedCall/model/lambda_63/Exp | OpType: Exp] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_63/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Outputs:
StatefulPartitionedCall/model/lambda_63/Exp:0
    StatefulPartitionedCall/model/lambda_63/Exp:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Node Mreq: 2,768,896 bytes

** Node: StatefulPartitionedCall/model/lambda_63/add | OpType: Add] **
  Inputs:
    Transpose__1378:0: dtype=FLOAT, shape=[1, 1, 1, 1], mreq=4
    StatefulPartitionedCall/model/lambda_63/Exp:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Outputs:
StatefulPartitionedCall/model/lambda_63/add:0
    StatefulPartitionedCall/model/lambda_63/add:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Node Mreq: 2,768,900 bytes

** Node: StatefulPartitionedCall/model/lambda_63/Log | OpType: Log] **
  Inputs:
    StatefulPartitionedCall/model/lambda_63/add:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Outputs:
StatefulPartitionedCall/model/lambda_63/Log:0
    StatefulPartitionedCall/model/lambda_63/Log:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Node Mreq: 2,768,896 bytes

** Node: StatefulPartitionedCall/model/lambda_63/Tanh | OpType: Tanh] **
  Inputs:
    StatefulPartitionedCall/model/lambda_63/Log:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Outputs:
StatefulPartitionedCall/model/lambda_63/Tanh:0
    StatefulPartitionedCall/model/lambda_63/Tanh:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Node Mreq: 2,768,896 bytes

** Node: StatefulPartitionedCall/model/lambda_63/mul | OpType: Mul] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_63/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
    StatefulPartitionedCall/model/lambda_63/Tanh:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Outputs:
StatefulPartitionedCall/model/lambda_63/mul:0
    StatefulPartitionedCall/model/lambda_63/mul:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Node Mreq: 4,153,344 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_add_19/add_19 | OpType: Add] **
  Inputs:
    StatefulPartitionedCall/model/lambda_61/mul:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
    StatefulPartitionedCall/model/lambda_63/mul:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_add_19/add_19:0
    StatefulPartitionedCall/model/tf_op_layer_add_19/add_19:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Node Mreq: 4,153,344 bytes

** Node: StatefulPartitionedCall/model/conv2d_64/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_add_19/add_19:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
    StatefulPartitionedCall/model/conv2d_64/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[512, 512, 1, 1], mreq=1,048,576
    StatefulPartitionedCall/model/conv2d_64/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[512], mreq=2,048
  Outputs:
StatefulPartitionedCall/model/batch_normalization_64/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_64/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Node Mreq: 3,819,520 bytes

** Node: StatefulPartitionedCall/model/lambda_64/Exp | OpType: Exp] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_64/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Outputs:
StatefulPartitionedCall/model/lambda_64/Exp:0
    StatefulPartitionedCall/model/lambda_64/Exp:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Node Mreq: 2,768,896 bytes

** Node: StatefulPartitionedCall/model/lambda_64/add | OpType: Add] **
  Inputs:
    Transpose__1378:0: dtype=FLOAT, shape=[1, 1, 1, 1], mreq=4
    StatefulPartitionedCall/model/lambda_64/Exp:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Outputs:
StatefulPartitionedCall/model/lambda_64/add:0
    StatefulPartitionedCall/model/lambda_64/add:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Node Mreq: 2,768,900 bytes

** Node: StatefulPartitionedCall/model/lambda_64/Log | OpType: Log] **
  Inputs:
    StatefulPartitionedCall/model/lambda_64/add:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Outputs:
StatefulPartitionedCall/model/lambda_64/Log:0
    StatefulPartitionedCall/model/lambda_64/Log:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Node Mreq: 2,768,896 bytes

** Node: StatefulPartitionedCall/model/lambda_64/Tanh | OpType: Tanh] **
  Inputs:
    StatefulPartitionedCall/model/lambda_64/Log:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Outputs:
StatefulPartitionedCall/model/lambda_64/Tanh:0
    StatefulPartitionedCall/model/lambda_64/Tanh:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Node Mreq: 2,768,896 bytes

** Node: StatefulPartitionedCall/model/lambda_64/mul | OpType: Mul] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_64/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
    StatefulPartitionedCall/model/lambda_64/Tanh:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Outputs:
StatefulPartitionedCall/model/lambda_64/mul:0
    StatefulPartitionedCall/model/lambda_64/mul:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Node Mreq: 4,153,344 bytes

** Node: StatefulPartitionedCall/model/conv2d_65/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/lambda_64/mul:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
    StatefulPartitionedCall/model/conv2d_65/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[512, 512, 3, 3], mreq=9,437,184
    StatefulPartitionedCall/model/conv2d_65/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[512], mreq=2,048
  Outputs:
StatefulPartitionedCall/model/batch_normalization_65/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_65/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Node Mreq: 12,208,128 bytes

** Node: StatefulPartitionedCall/model/lambda_65/Exp | OpType: Exp] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_65/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Outputs:
StatefulPartitionedCall/model/lambda_65/Exp:0
    StatefulPartitionedCall/model/lambda_65/Exp:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Node Mreq: 2,768,896 bytes

** Node: StatefulPartitionedCall/model/lambda_65/add | OpType: Add] **
  Inputs:
    Transpose__1378:0: dtype=FLOAT, shape=[1, 1, 1, 1], mreq=4
    StatefulPartitionedCall/model/lambda_65/Exp:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Outputs:
StatefulPartitionedCall/model/lambda_65/add:0
    StatefulPartitionedCall/model/lambda_65/add:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Node Mreq: 2,768,900 bytes

** Node: StatefulPartitionedCall/model/lambda_65/Log | OpType: Log] **
  Inputs:
    StatefulPartitionedCall/model/lambda_65/add:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Outputs:
StatefulPartitionedCall/model/lambda_65/Log:0
    StatefulPartitionedCall/model/lambda_65/Log:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Node Mreq: 2,768,896 bytes

** Node: StatefulPartitionedCall/model/lambda_65/Tanh | OpType: Tanh] **
  Inputs:
    StatefulPartitionedCall/model/lambda_65/Log:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Outputs:
StatefulPartitionedCall/model/lambda_65/Tanh:0
    StatefulPartitionedCall/model/lambda_65/Tanh:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Node Mreq: 2,768,896 bytes

** Node: StatefulPartitionedCall/model/lambda_65/mul | OpType: Mul] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_65/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
    StatefulPartitionedCall/model/lambda_65/Tanh:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Outputs:
StatefulPartitionedCall/model/lambda_65/mul:0
    StatefulPartitionedCall/model/lambda_65/mul:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Node Mreq: 4,153,344 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_add_20/add_20 | OpType: Add] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_add_19/add_19:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
    StatefulPartitionedCall/model/lambda_65/mul:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_add_20/add_20:0
    StatefulPartitionedCall/model/tf_op_layer_add_20/add_20:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Node Mreq: 4,153,344 bytes

** Node: StatefulPartitionedCall/model/conv2d_66/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_add_20/add_20:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
    StatefulPartitionedCall/model/conv2d_66/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[512, 512, 1, 1], mreq=1,048,576
    StatefulPartitionedCall/model/conv2d_66/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[512], mreq=2,048
  Outputs:
StatefulPartitionedCall/model/batch_normalization_66/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_66/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Node Mreq: 3,819,520 bytes

** Node: StatefulPartitionedCall/model/lambda_66/Exp | OpType: Exp] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_66/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Outputs:
StatefulPartitionedCall/model/lambda_66/Exp:0
    StatefulPartitionedCall/model/lambda_66/Exp:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Node Mreq: 2,768,896 bytes

** Node: StatefulPartitionedCall/model/lambda_66/add | OpType: Add] **
  Inputs:
    Transpose__1378:0: dtype=FLOAT, shape=[1, 1, 1, 1], mreq=4
    StatefulPartitionedCall/model/lambda_66/Exp:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Outputs:
StatefulPartitionedCall/model/lambda_66/add:0
    StatefulPartitionedCall/model/lambda_66/add:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Node Mreq: 2,768,900 bytes

** Node: StatefulPartitionedCall/model/lambda_66/Log | OpType: Log] **
  Inputs:
    StatefulPartitionedCall/model/lambda_66/add:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Outputs:
StatefulPartitionedCall/model/lambda_66/Log:0
    StatefulPartitionedCall/model/lambda_66/Log:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Node Mreq: 2,768,896 bytes

** Node: StatefulPartitionedCall/model/lambda_66/Tanh | OpType: Tanh] **
  Inputs:
    StatefulPartitionedCall/model/lambda_66/Log:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Outputs:
StatefulPartitionedCall/model/lambda_66/Tanh:0
    StatefulPartitionedCall/model/lambda_66/Tanh:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Node Mreq: 2,768,896 bytes

** Node: StatefulPartitionedCall/model/lambda_66/mul | OpType: Mul] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_66/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
    StatefulPartitionedCall/model/lambda_66/Tanh:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Outputs:
StatefulPartitionedCall/model/lambda_66/mul:0
    StatefulPartitionedCall/model/lambda_66/mul:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Node Mreq: 4,153,344 bytes

** Node: StatefulPartitionedCall/model/conv2d_67/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/lambda_66/mul:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
    StatefulPartitionedCall/model/conv2d_67/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[512, 512, 3, 3], mreq=9,437,184
    StatefulPartitionedCall/model/conv2d_67/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[512], mreq=2,048
  Outputs:
StatefulPartitionedCall/model/batch_normalization_67/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_67/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Node Mreq: 12,208,128 bytes

** Node: StatefulPartitionedCall/model/lambda_67/Exp | OpType: Exp] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_67/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Outputs:
StatefulPartitionedCall/model/lambda_67/Exp:0
    StatefulPartitionedCall/model/lambda_67/Exp:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Node Mreq: 2,768,896 bytes

** Node: StatefulPartitionedCall/model/lambda_67/add | OpType: Add] **
  Inputs:
    Transpose__1378:0: dtype=FLOAT, shape=[1, 1, 1, 1], mreq=4
    StatefulPartitionedCall/model/lambda_67/Exp:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Outputs:
StatefulPartitionedCall/model/lambda_67/add:0
    StatefulPartitionedCall/model/lambda_67/add:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Node Mreq: 2,768,900 bytes

** Node: StatefulPartitionedCall/model/lambda_67/Log | OpType: Log] **
  Inputs:
    StatefulPartitionedCall/model/lambda_67/add:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Outputs:
StatefulPartitionedCall/model/lambda_67/Log:0
    StatefulPartitionedCall/model/lambda_67/Log:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Node Mreq: 2,768,896 bytes

** Node: StatefulPartitionedCall/model/lambda_67/Tanh | OpType: Tanh] **
  Inputs:
    StatefulPartitionedCall/model/lambda_67/Log:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Outputs:
StatefulPartitionedCall/model/lambda_67/Tanh:0
    StatefulPartitionedCall/model/lambda_67/Tanh:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Node Mreq: 2,768,896 bytes

** Node: StatefulPartitionedCall/model/lambda_67/mul | OpType: Mul] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_67/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
    StatefulPartitionedCall/model/lambda_67/Tanh:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Outputs:
StatefulPartitionedCall/model/lambda_67/mul:0
    StatefulPartitionedCall/model/lambda_67/mul:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Node Mreq: 4,153,344 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_add_21/add_21 | OpType: Add] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_add_20/add_20:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
    StatefulPartitionedCall/model/lambda_67/mul:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_add_21/add_21:0
    StatefulPartitionedCall/model/tf_op_layer_add_21/add_21:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Node Mreq: 4,153,344 bytes

** Node: StatefulPartitionedCall/model/conv2d_68/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_add_21/add_21:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
    StatefulPartitionedCall/model/conv2d_68/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[512, 512, 1, 1], mreq=1,048,576
    StatefulPartitionedCall/model/conv2d_68/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[512], mreq=2,048
  Outputs:
StatefulPartitionedCall/model/batch_normalization_68/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_68/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Node Mreq: 3,819,520 bytes

** Node: StatefulPartitionedCall/model/lambda_68/Exp | OpType: Exp] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_68/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Outputs:
StatefulPartitionedCall/model/lambda_68/Exp:0
    StatefulPartitionedCall/model/lambda_68/Exp:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Node Mreq: 2,768,896 bytes

** Node: StatefulPartitionedCall/model/lambda_68/add | OpType: Add] **
  Inputs:
    Transpose__1378:0: dtype=FLOAT, shape=[1, 1, 1, 1], mreq=4
    StatefulPartitionedCall/model/lambda_68/Exp:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Outputs:
StatefulPartitionedCall/model/lambda_68/add:0
    StatefulPartitionedCall/model/lambda_68/add:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Node Mreq: 2,768,900 bytes

** Node: StatefulPartitionedCall/model/lambda_68/Log | OpType: Log] **
  Inputs:
    StatefulPartitionedCall/model/lambda_68/add:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Outputs:
StatefulPartitionedCall/model/lambda_68/Log:0
    StatefulPartitionedCall/model/lambda_68/Log:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Node Mreq: 2,768,896 bytes

** Node: StatefulPartitionedCall/model/lambda_68/Tanh | OpType: Tanh] **
  Inputs:
    StatefulPartitionedCall/model/lambda_68/Log:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Outputs:
StatefulPartitionedCall/model/lambda_68/Tanh:0
    StatefulPartitionedCall/model/lambda_68/Tanh:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Node Mreq: 2,768,896 bytes

** Node: StatefulPartitionedCall/model/lambda_68/mul | OpType: Mul] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_68/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
    StatefulPartitionedCall/model/lambda_68/Tanh:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Outputs:
StatefulPartitionedCall/model/lambda_68/mul:0
    StatefulPartitionedCall/model/lambda_68/mul:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Node Mreq: 4,153,344 bytes

** Node: StatefulPartitionedCall/model/conv2d_69/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/lambda_68/mul:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
    StatefulPartitionedCall/model/conv2d_69/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[512, 512, 3, 3], mreq=9,437,184
    StatefulPartitionedCall/model/conv2d_69/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[512], mreq=2,048
  Outputs:
StatefulPartitionedCall/model/batch_normalization_69/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_69/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Node Mreq: 12,208,128 bytes

** Node: StatefulPartitionedCall/model/lambda_69/Exp | OpType: Exp] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_69/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Outputs:
StatefulPartitionedCall/model/lambda_69/Exp:0
    StatefulPartitionedCall/model/lambda_69/Exp:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Node Mreq: 2,768,896 bytes

** Node: StatefulPartitionedCall/model/lambda_69/add | OpType: Add] **
  Inputs:
    Transpose__1378:0: dtype=FLOAT, shape=[1, 1, 1, 1], mreq=4
    StatefulPartitionedCall/model/lambda_69/Exp:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Outputs:
StatefulPartitionedCall/model/lambda_69/add:0
    StatefulPartitionedCall/model/lambda_69/add:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Node Mreq: 2,768,900 bytes

** Node: StatefulPartitionedCall/model/lambda_69/Log | OpType: Log] **
  Inputs:
    StatefulPartitionedCall/model/lambda_69/add:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Outputs:
StatefulPartitionedCall/model/lambda_69/Log:0
    StatefulPartitionedCall/model/lambda_69/Log:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Node Mreq: 2,768,896 bytes

** Node: StatefulPartitionedCall/model/lambda_69/Tanh | OpType: Tanh] **
  Inputs:
    StatefulPartitionedCall/model/lambda_69/Log:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Outputs:
StatefulPartitionedCall/model/lambda_69/Tanh:0
    StatefulPartitionedCall/model/lambda_69/Tanh:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Node Mreq: 2,768,896 bytes

** Node: StatefulPartitionedCall/model/lambda_69/mul | OpType: Mul] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_69/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
    StatefulPartitionedCall/model/lambda_69/Tanh:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Outputs:
StatefulPartitionedCall/model/lambda_69/mul:0
    StatefulPartitionedCall/model/lambda_69/mul:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Node Mreq: 4,153,344 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_add_22/add_22 | OpType: Add] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_add_21/add_21:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
    StatefulPartitionedCall/model/lambda_69/mul:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_add_22/add_22:0
    StatefulPartitionedCall/model/tf_op_layer_add_22/add_22:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Node Mreq: 4,153,344 bytes

** Node: StatefulPartitionedCall/model/conv2d_70/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_add_22/add_22:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
    StatefulPartitionedCall/model/conv2d_70/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[512, 512, 1, 1], mreq=1,048,576
    StatefulPartitionedCall/model/conv2d_70/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[512], mreq=2,048
  Outputs:
StatefulPartitionedCall/model/batch_normalization_70/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_70/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Node Mreq: 3,819,520 bytes

** Node: StatefulPartitionedCall/model/lambda_70/Exp | OpType: Exp] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_70/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Outputs:
StatefulPartitionedCall/model/lambda_70/Exp:0
    StatefulPartitionedCall/model/lambda_70/Exp:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Node Mreq: 2,768,896 bytes

** Node: StatefulPartitionedCall/model/lambda_70/add | OpType: Add] **
  Inputs:
    Transpose__1378:0: dtype=FLOAT, shape=[1, 1, 1, 1], mreq=4
    StatefulPartitionedCall/model/lambda_70/Exp:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Outputs:
StatefulPartitionedCall/model/lambda_70/add:0
    StatefulPartitionedCall/model/lambda_70/add:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Node Mreq: 2,768,900 bytes

** Node: StatefulPartitionedCall/model/lambda_70/Log | OpType: Log] **
  Inputs:
    StatefulPartitionedCall/model/lambda_70/add:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Outputs:
StatefulPartitionedCall/model/lambda_70/Log:0
    StatefulPartitionedCall/model/lambda_70/Log:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Node Mreq: 2,768,896 bytes

** Node: StatefulPartitionedCall/model/lambda_70/Tanh | OpType: Tanh] **
  Inputs:
    StatefulPartitionedCall/model/lambda_70/Log:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Outputs:
StatefulPartitionedCall/model/lambda_70/Tanh:0
    StatefulPartitionedCall/model/lambda_70/Tanh:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Node Mreq: 2,768,896 bytes

** Node: StatefulPartitionedCall/model/lambda_70/mul | OpType: Mul] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_70/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
    StatefulPartitionedCall/model/lambda_70/Tanh:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Outputs:
StatefulPartitionedCall/model/lambda_70/mul:0
    StatefulPartitionedCall/model/lambda_70/mul:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Node Mreq: 4,153,344 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_concat_4/concat_4 | OpType: Concat] **
  Inputs:
    StatefulPartitionedCall/model/lambda_70/mul:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
    StatefulPartitionedCall/model/lambda_60/mul:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_concat_4/concat_4:0
    StatefulPartitionedCall/model/tf_op_layer_concat_4/concat_4:0: dtype=FLOAT, shape=[4, 1024, 13, 13], mreq=2,768,896
  Node Mreq: 5,537,792 bytes

** Node: StatefulPartitionedCall/model/conv2d_71/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_concat_4/concat_4:0: dtype=FLOAT, shape=[4, 1024, 13, 13], mreq=2,768,896
    StatefulPartitionedCall/model/conv2d_71/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[1024, 1024, 1, 1], mreq=4,194,304
    StatefulPartitionedCall/model/conv2d_71/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[1024], mreq=4,096
  Outputs:
StatefulPartitionedCall/model/batch_normalization_71/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_71/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 1024, 13, 13], mreq=2,768,896
  Node Mreq: 9,736,192 bytes

** Node: StatefulPartitionedCall/model/lambda_71/Exp | OpType: Exp] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_71/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 1024, 13, 13], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_71/Exp:0
    StatefulPartitionedCall/model/lambda_71/Exp:0: dtype=FLOAT, shape=[4, 1024, 13, 13], mreq=2,768,896
  Node Mreq: 5,537,792 bytes

** Node: StatefulPartitionedCall/model/lambda_71/add | OpType: Add] **
  Inputs:
    Transpose__1378:0: dtype=FLOAT, shape=[1, 1, 1, 1], mreq=4
    StatefulPartitionedCall/model/lambda_71/Exp:0: dtype=FLOAT, shape=[4, 1024, 13, 13], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_71/add:0
    StatefulPartitionedCall/model/lambda_71/add:0: dtype=FLOAT, shape=[4, 1024, 13, 13], mreq=2,768,896
  Node Mreq: 5,537,796 bytes

** Node: StatefulPartitionedCall/model/lambda_71/Log | OpType: Log] **
  Inputs:
    StatefulPartitionedCall/model/lambda_71/add:0: dtype=FLOAT, shape=[4, 1024, 13, 13], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_71/Log:0
    StatefulPartitionedCall/model/lambda_71/Log:0: dtype=FLOAT, shape=[4, 1024, 13, 13], mreq=2,768,896
  Node Mreq: 5,537,792 bytes

** Node: StatefulPartitionedCall/model/lambda_71/Tanh | OpType: Tanh] **
  Inputs:
    StatefulPartitionedCall/model/lambda_71/Log:0: dtype=FLOAT, shape=[4, 1024, 13, 13], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_71/Tanh:0
    StatefulPartitionedCall/model/lambda_71/Tanh:0: dtype=FLOAT, shape=[4, 1024, 13, 13], mreq=2,768,896
  Node Mreq: 5,537,792 bytes

** Node: StatefulPartitionedCall/model/lambda_71/mul | OpType: Mul] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_71/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 1024, 13, 13], mreq=2,768,896
    StatefulPartitionedCall/model/lambda_71/Tanh:0: dtype=FLOAT, shape=[4, 1024, 13, 13], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/lambda_71/mul:0
    StatefulPartitionedCall/model/lambda_71/mul:0: dtype=FLOAT, shape=[4, 1024, 13, 13], mreq=2,768,896
  Node Mreq: 8,306,688 bytes

** Node: StatefulPartitionedCall/model/conv2d_72/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/lambda_71/mul:0: dtype=FLOAT, shape=[4, 1024, 13, 13], mreq=2,768,896
    StatefulPartitionedCall/model/conv2d_72/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[512, 1024, 1, 1], mreq=2,097,152
    StatefulPartitionedCall/model/conv2d_72/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[512], mreq=2,048
  Outputs:
StatefulPartitionedCall/model/batch_normalization_72/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_72/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Node Mreq: 6,252,544 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_LeakyRelu/LeakyRelu | OpType: LeakyRelu] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_72/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_LeakyRelu/LeakyRelu:0
    StatefulPartitionedCall/model/tf_op_layer_LeakyRelu/LeakyRelu:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Node Mreq: 2,768,896 bytes

** Node: StatefulPartitionedCall/model/conv2d_73/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_LeakyRelu/LeakyRelu:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
    StatefulPartitionedCall/model/conv2d_73/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[1024, 512, 3, 3], mreq=18,874,368
    StatefulPartitionedCall/model/conv2d_73/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[1024], mreq=4,096
  Outputs:
StatefulPartitionedCall/model/batch_normalization_73/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_73/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 1024, 13, 13], mreq=2,768,896
  Node Mreq: 23,031,808 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_1/LeakyRelu_1 | OpType: LeakyRelu] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_73/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 1024, 13, 13], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_1/LeakyRelu_1:0
    StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_1/LeakyRelu_1:0: dtype=FLOAT, shape=[4, 1024, 13, 13], mreq=2,768,896
  Node Mreq: 5,537,792 bytes

** Node: StatefulPartitionedCall/model/conv2d_74/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_1/LeakyRelu_1:0: dtype=FLOAT, shape=[4, 1024, 13, 13], mreq=2,768,896
    StatefulPartitionedCall/model/conv2d_74/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[512, 1024, 1, 1], mreq=2,097,152
    StatefulPartitionedCall/model/conv2d_74/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[512], mreq=2,048
  Outputs:
StatefulPartitionedCall/model/batch_normalization_74/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_74/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Node Mreq: 6,252,544 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_2/LeakyRelu_2 | OpType: LeakyRelu] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_74/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_2/LeakyRelu_2:0
    StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_2/LeakyRelu_2:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Node Mreq: 2,768,896 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_MaxPool_2/MaxPool_2 | OpType: MaxPool] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_2/LeakyRelu_2:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_MaxPool_2/MaxPool_2:0
    StatefulPartitionedCall/model/tf_op_layer_MaxPool_2/MaxPool_2:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Node Mreq: 2,768,896 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_MaxPool_1/MaxPool_1 | OpType: MaxPool] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_2/LeakyRelu_2:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_MaxPool_1/MaxPool_1:0
    StatefulPartitionedCall/model/tf_op_layer_MaxPool_1/MaxPool_1:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Node Mreq: 2,768,896 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_MaxPool/MaxPool | OpType: MaxPool] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_2/LeakyRelu_2:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_MaxPool/MaxPool:0
    StatefulPartitionedCall/model/tf_op_layer_MaxPool/MaxPool:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Node Mreq: 2,768,896 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_concat_5/concat_5 | OpType: Concat] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_MaxPool/MaxPool:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
    StatefulPartitionedCall/model/tf_op_layer_MaxPool_1/MaxPool_1:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
    StatefulPartitionedCall/model/tf_op_layer_MaxPool_2/MaxPool_2:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
    StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_2/LeakyRelu_2:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_concat_5/concat_5:0
    StatefulPartitionedCall/model/tf_op_layer_concat_5/concat_5:0: dtype=FLOAT, shape=[4, 2048, 13, 13], mreq=5,537,792
  Node Mreq: 11,075,584 bytes

** Node: StatefulPartitionedCall/model/conv2d_75/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_concat_5/concat_5:0: dtype=FLOAT, shape=[4, 2048, 13, 13], mreq=5,537,792
    StatefulPartitionedCall/model/conv2d_75/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[512, 2048, 1, 1], mreq=4,194,304
    StatefulPartitionedCall/model/conv2d_75/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[512], mreq=2,048
  Outputs:
StatefulPartitionedCall/model/batch_normalization_75/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_75/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Node Mreq: 11,118,592 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_3/LeakyRelu_3 | OpType: LeakyRelu] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_75/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_3/LeakyRelu_3:0
    StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_3/LeakyRelu_3:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Node Mreq: 2,768,896 bytes

** Node: StatefulPartitionedCall/model/conv2d_76/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_3/LeakyRelu_3:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
    StatefulPartitionedCall/model/conv2d_76/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[1024, 512, 3, 3], mreq=18,874,368
    StatefulPartitionedCall/model/conv2d_76/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[1024], mreq=4,096
  Outputs:
StatefulPartitionedCall/model/batch_normalization_76/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_76/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 1024, 13, 13], mreq=2,768,896
  Node Mreq: 23,031,808 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_4/LeakyRelu_4 | OpType: LeakyRelu] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_76/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 1024, 13, 13], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_4/LeakyRelu_4:0
    StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_4/LeakyRelu_4:0: dtype=FLOAT, shape=[4, 1024, 13, 13], mreq=2,768,896
  Node Mreq: 5,537,792 bytes

** Node: StatefulPartitionedCall/model/conv2d_77/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_4/LeakyRelu_4:0: dtype=FLOAT, shape=[4, 1024, 13, 13], mreq=2,768,896
    StatefulPartitionedCall/model/conv2d_77/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[512, 1024, 1, 1], mreq=2,097,152
    StatefulPartitionedCall/model/conv2d_77/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[512], mreq=2,048
  Outputs:
StatefulPartitionedCall/model/batch_normalization_77/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_77/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Node Mreq: 6,252,544 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_5/LeakyRelu_5 | OpType: LeakyRelu] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_77/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_5/LeakyRelu_5:0
    StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_5/LeakyRelu_5:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Node Mreq: 2,768,896 bytes

** Node: StatefulPartitionedCall/model/conv2d_78/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_5/LeakyRelu_5:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
    StatefulPartitionedCall/model/conv2d_78/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[256, 512, 1, 1], mreq=524,288
    StatefulPartitionedCall/model/conv2d_78/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[256], mreq=1,024
  Outputs:
StatefulPartitionedCall/model/batch_normalization_78/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_78/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 256, 13, 13], mreq=692,224
  Node Mreq: 2,601,984 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_6/LeakyRelu_6 | OpType: LeakyRelu] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_78/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 256, 13, 13], mreq=692,224
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_6/LeakyRelu_6:0
    StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_6/LeakyRelu_6:0: dtype=FLOAT, shape=[4, 256, 13, 13], mreq=692,224
  Node Mreq: 1,384,448 bytes

** Node: Shape__692 | OpType: Shape] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_6/LeakyRelu_6:0: dtype=FLOAT, shape=[4, 256, 13, 13], mreq=692,224
  Outputs:
Shape__692:0
    Shape__692:0: dtype=INT64, shape=[4], mreq=32
  Node Mreq: 692,256 bytes

** Node: Slice__694 | OpType: Slice] **
  Inputs:
    Shape__692:0: dtype=INT64, shape=[4], mreq=32
    const_slice__931: dtype=INT64, shape=[1], mreq=8
    const_slice__930: dtype=INT64, shape=[1], mreq=8
  Outputs:
Slice__694:0
    Slice__694:0: dtype=INT64, shape=[2], mreq=16
  Node Mreq: 64 bytes

** Node: Concat__696 | OpType: Concat] **
  Inputs:
    Slice__694:0: dtype=INT64, shape=[2], mreq=16
    const_fold_opt__2097: dtype=INT64, shape=[2], mreq=16
  Outputs:
Concat__696:0
    Concat__696:0: dtype=INT64, shape=[4], mreq=32
  Node Mreq: 64 bytes

** Node: Resize__697 | OpType: Resize] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_6/LeakyRelu_6:0: dtype=FLOAT, shape=[4, 256, 13, 13], mreq=692,224
    const_empty_float__689: dtype=FLOAT, shape=[0], mreq=0
    const_empty_float__689: dtype=FLOAT, shape=[0], mreq=0
    Concat__696:0: dtype=INT64, shape=[4], mreq=32
  Outputs:
Resize__697:0
    Resize__697:0: dtype=FLOAT, shape=[4, 4, 4, 4], mreq=1,024
  Node Mreq: 693,280 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_concat_6/concat_6 | OpType: Concat] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_7/LeakyRelu_7:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
    Resize__697:0: dtype=FLOAT, shape=[4, 4, 4, 4], mreq=1,024
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_concat_6/concat_6:0
    StatefulPartitionedCall/model/tf_op_layer_concat_6/concat_6:0: dtype=FLOAT, shape=[4, 4, 26, 26], mreq=43,264
  Node Mreq: 2,813,184 bytes

** Node: StatefulPartitionedCall/model/conv2d_80/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_concat_6/concat_6:0: dtype=FLOAT, shape=[4, 4, 26, 26], mreq=43,264
    StatefulPartitionedCall/model/conv2d_80/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[256, 512, 1, 1], mreq=524,288
    StatefulPartitionedCall/model/conv2d_80/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[256], mreq=1,024
  Outputs:
StatefulPartitionedCall/model/batch_normalization_80/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_80/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 3,337,472 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_8/LeakyRelu_8 | OpType: LeakyRelu] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_80/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_8/LeakyRelu_8:0
    StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_8/LeakyRelu_8:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,537,792 bytes

** Node: StatefulPartitionedCall/model/conv2d_81/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_8/LeakyRelu_8:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
    StatefulPartitionedCall/model/conv2d_81/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[512, 256, 3, 3], mreq=4,718,592
    StatefulPartitionedCall/model/conv2d_81/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[512], mreq=2,048
  Outputs:
StatefulPartitionedCall/model/batch_normalization_81/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_81/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 512, 26, 26], mreq=5,537,792
  Node Mreq: 13,027,328 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_9/LeakyRelu_9 | OpType: LeakyRelu] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_81/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 512, 26, 26], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_9/LeakyRelu_9:0
    StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_9/LeakyRelu_9:0: dtype=FLOAT, shape=[4, 512, 26, 26], mreq=5,537,792
  Node Mreq: 11,075,584 bytes

** Node: StatefulPartitionedCall/model/conv2d_82/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_9/LeakyRelu_9:0: dtype=FLOAT, shape=[4, 512, 26, 26], mreq=5,537,792
    StatefulPartitionedCall/model/conv2d_82/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[256, 512, 1, 1], mreq=524,288
    StatefulPartitionedCall/model/conv2d_82/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[256], mreq=1,024
  Outputs:
StatefulPartitionedCall/model/batch_normalization_82/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_82/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 8,832,000 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_10/LeakyRelu_10 | OpType: LeakyRelu] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_82/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_10/LeakyRelu_10:0
    StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_10/LeakyRelu_10:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,537,792 bytes

** Node: StatefulPartitionedCall/model/conv2d_83/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_10/LeakyRelu_10:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
    StatefulPartitionedCall/model/conv2d_83/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[512, 256, 3, 3], mreq=4,718,592
    StatefulPartitionedCall/model/conv2d_83/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[512], mreq=2,048
  Outputs:
StatefulPartitionedCall/model/batch_normalization_83/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_83/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 512, 26, 26], mreq=5,537,792
  Node Mreq: 13,027,328 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_11/LeakyRelu_11 | OpType: LeakyRelu] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_83/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 512, 26, 26], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_11/LeakyRelu_11:0
    StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_11/LeakyRelu_11:0: dtype=FLOAT, shape=[4, 512, 26, 26], mreq=5,537,792
  Node Mreq: 11,075,584 bytes

** Node: StatefulPartitionedCall/model/conv2d_84/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_11/LeakyRelu_11:0: dtype=FLOAT, shape=[4, 512, 26, 26], mreq=5,537,792
    StatefulPartitionedCall/model/conv2d_84/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[256, 512, 1, 1], mreq=524,288
    StatefulPartitionedCall/model/conv2d_84/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[256], mreq=1,024
  Outputs:
StatefulPartitionedCall/model/batch_normalization_84/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_84/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 8,832,000 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_12/LeakyRelu_12 | OpType: LeakyRelu] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_84/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_12/LeakyRelu_12:0
    StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_12/LeakyRelu_12:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,537,792 bytes

** Node: StatefulPartitionedCall/model/conv2d_85/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_12/LeakyRelu_12:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
    StatefulPartitionedCall/model/conv2d_85/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[128, 256, 1, 1], mreq=131,072
    StatefulPartitionedCall/model/conv2d_85/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[128], mreq=512
  Outputs:
StatefulPartitionedCall/model/batch_normalization_85/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_85/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 128, 26, 26], mreq=1,384,448
  Node Mreq: 4,284,928 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_13/LeakyRelu_13 | OpType: LeakyRelu] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_85/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 128, 26, 26], mreq=1,384,448
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_13/LeakyRelu_13:0
    StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_13/LeakyRelu_13:0: dtype=FLOAT, shape=[4, 128, 26, 26], mreq=1,384,448
  Node Mreq: 2,768,896 bytes

** Node: Shape__753 | OpType: Shape] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_13/LeakyRelu_13:0: dtype=FLOAT, shape=[4, 128, 26, 26], mreq=1,384,448
  Outputs:
Shape__753:0
    Shape__753:0: dtype=INT64, shape=[4], mreq=32
  Node Mreq: 1,384,480 bytes

** Node: Slice__755 | OpType: Slice] **
  Inputs:
    Shape__753:0: dtype=INT64, shape=[4], mreq=32
    const_slice__931: dtype=INT64, shape=[1], mreq=8
    const_slice__930: dtype=INT64, shape=[1], mreq=8
  Outputs:
Slice__755:0
    Slice__755:0: dtype=INT64, shape=[2], mreq=16
  Node Mreq: 64 bytes

** Node: Concat__757 | OpType: Concat] **
  Inputs:
    Slice__755:0: dtype=INT64, shape=[2], mreq=16
    const_fold_opt__2102: dtype=INT64, shape=[2], mreq=16
  Outputs:
Concat__757:0
    Concat__757:0: dtype=INT64, shape=[4], mreq=32
  Node Mreq: 64 bytes

** Node: Resize__758 | OpType: Resize] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_13/LeakyRelu_13:0: dtype=FLOAT, shape=[4, 128, 26, 26], mreq=1,384,448
    const_empty_float__689: dtype=FLOAT, shape=[0], mreq=0
    const_empty_float__689: dtype=FLOAT, shape=[0], mreq=0
    Concat__757:0: dtype=INT64, shape=[4], mreq=32
  Outputs:
Resize__758:0
    Resize__758:0: dtype=FLOAT, shape=[4, 4, 4, 4], mreq=1,024
  Node Mreq: 1,385,504 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_concat_7/concat_7 | OpType: Concat] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_14/LeakyRelu_14:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
    Resize__758:0: dtype=FLOAT, shape=[4, 4, 4, 4], mreq=1,024
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_concat_7/concat_7:0
    StatefulPartitionedCall/model/tf_op_layer_concat_7/concat_7:0: dtype=FLOAT, shape=[4, 4, 52, 52], mreq=173,056
  Node Mreq: 5,711,872 bytes

** Node: StatefulPartitionedCall/model/conv2d_87/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_concat_7/concat_7:0: dtype=FLOAT, shape=[4, 4, 52, 52], mreq=173,056
    StatefulPartitionedCall/model/conv2d_87/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[128, 256, 1, 1], mreq=131,072
    StatefulPartitionedCall/model/conv2d_87/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[128], mreq=512
  Outputs:
StatefulPartitionedCall/model/batch_normalization_87/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_87/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 5,842,432 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_15/LeakyRelu_15 | OpType: LeakyRelu] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_87/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_15/LeakyRelu_15:0
    StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_15/LeakyRelu_15:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,075,584 bytes

** Node: StatefulPartitionedCall/model/conv2d_88/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_15/LeakyRelu_15:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
    StatefulPartitionedCall/model/conv2d_88/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[256, 128, 3, 3], mreq=1,179,648
    StatefulPartitionedCall/model/conv2d_88/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[256], mreq=1,024
  Outputs:
StatefulPartitionedCall/model/batch_normalization_88/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_88/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 256, 52, 52], mreq=11,075,584
  Node Mreq: 17,794,048 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_16/LeakyRelu_16 | OpType: LeakyRelu] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_88/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 256, 52, 52], mreq=11,075,584
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_16/LeakyRelu_16:0
    StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_16/LeakyRelu_16:0: dtype=FLOAT, shape=[4, 256, 52, 52], mreq=11,075,584
  Node Mreq: 22,151,168 bytes

** Node: StatefulPartitionedCall/model/conv2d_89/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_16/LeakyRelu_16:0: dtype=FLOAT, shape=[4, 256, 52, 52], mreq=11,075,584
    StatefulPartitionedCall/model/conv2d_89/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[128, 256, 1, 1], mreq=131,072
    StatefulPartitionedCall/model/conv2d_89/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[128], mreq=512
  Outputs:
StatefulPartitionedCall/model/batch_normalization_89/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_89/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 16,744,960 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_17/LeakyRelu_17 | OpType: LeakyRelu] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_89/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_17/LeakyRelu_17:0
    StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_17/LeakyRelu_17:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,075,584 bytes

** Node: StatefulPartitionedCall/model/conv2d_90/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_17/LeakyRelu_17:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
    StatefulPartitionedCall/model/conv2d_90/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[256, 128, 3, 3], mreq=1,179,648
    StatefulPartitionedCall/model/conv2d_90/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[256], mreq=1,024
  Outputs:
StatefulPartitionedCall/model/batch_normalization_90/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_90/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 256, 52, 52], mreq=11,075,584
  Node Mreq: 17,794,048 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_18/LeakyRelu_18 | OpType: LeakyRelu] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_90/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 256, 52, 52], mreq=11,075,584
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_18/LeakyRelu_18:0
    StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_18/LeakyRelu_18:0: dtype=FLOAT, shape=[4, 256, 52, 52], mreq=11,075,584
  Node Mreq: 22,151,168 bytes

** Node: StatefulPartitionedCall/model/conv2d_91/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_18/LeakyRelu_18:0: dtype=FLOAT, shape=[4, 256, 52, 52], mreq=11,075,584
    StatefulPartitionedCall/model/conv2d_91/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[128, 256, 1, 1], mreq=131,072
    StatefulPartitionedCall/model/conv2d_91/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[128], mreq=512
  Outputs:
StatefulPartitionedCall/model/batch_normalization_91/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_91/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 16,744,960 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_19/LeakyRelu_19 | OpType: LeakyRelu] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_91/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_19/LeakyRelu_19:0
    StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_19/LeakyRelu_19:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
  Node Mreq: 11,075,584 bytes

** Node: StatefulPartitionedCall/model/conv2d_94/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_19/LeakyRelu_19:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
    StatefulPartitionedCall/model/conv2d_94/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[256, 128, 3, 3], mreq=1,179,648
    StatefulPartitionedCall/model/conv2d_94/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[256], mreq=1,024
  Outputs:
StatefulPartitionedCall/model/batch_normalization_93/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_93/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 9,487,360 bytes

** Node: StatefulPartitionedCall/model/conv2d_92/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_19/LeakyRelu_19:0: dtype=FLOAT, shape=[4, 128, 52, 52], mreq=5,537,792
    StatefulPartitionedCall/model/conv2d_92/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[256, 128, 3, 3], mreq=1,179,648
    StatefulPartitionedCall/model/conv2d_92/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[256], mreq=1,024
  Outputs:
StatefulPartitionedCall/model/batch_normalization_92/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_92/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 256, 52, 52], mreq=11,075,584
  Node Mreq: 17,794,048 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_21/LeakyRelu_21 | OpType: LeakyRelu] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_93/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_21/LeakyRelu_21:0
    StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_21/LeakyRelu_21:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,537,792 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_20/LeakyRelu_20 | OpType: LeakyRelu] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_92/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 256, 52, 52], mreq=11,075,584
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_20/LeakyRelu_20:0
    StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_20/LeakyRelu_20:0: dtype=FLOAT, shape=[4, 256, 52, 52], mreq=11,075,584
  Node Mreq: 22,151,168 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_concat_8/concat_8 | OpType: Concat] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_21/LeakyRelu_21:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
    StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_12/LeakyRelu_12:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_concat_8/concat_8:0
    StatefulPartitionedCall/model/tf_op_layer_concat_8/concat_8:0: dtype=FLOAT, shape=[4, 512, 26, 26], mreq=5,537,792
  Node Mreq: 11,075,584 bytes

** Node: StatefulPartitionedCall/model/conv2d_93/BiasAdd | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_20/LeakyRelu_20:0: dtype=FLOAT, shape=[4, 256, 52, 52], mreq=11,075,584
    StatefulPartitionedCall/model/conv2d_93/Conv2D/ReadVariableOp:0: dtype=FLOAT, shape=[255, 256, 1, 1], mreq=261,120
    StatefulPartitionedCall/model/conv2d_93/BiasAdd/ReadVariableOp:0: dtype=FLOAT, shape=[255], mreq=1,020
  Outputs:
StatefulPartitionedCall/model/conv2d_93/BiasAdd:0
    StatefulPartitionedCall/model/conv2d_93/BiasAdd:0: dtype=FLOAT, shape=[4, 255, 52, 52], mreq=11,032,320
  Node Mreq: 22,370,044 bytes

** Node: StatefulPartitionedCall/model/conv2d_95/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_concat_8/concat_8:0: dtype=FLOAT, shape=[4, 512, 26, 26], mreq=5,537,792
    StatefulPartitionedCall/model/conv2d_95/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[256, 512, 1, 1], mreq=524,288
    StatefulPartitionedCall/model/conv2d_95/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[256], mreq=1,024
  Outputs:
StatefulPartitionedCall/model/batch_normalization_94/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_94/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 8,832,000 bytes

** Node: Transpose__1294 | OpType: Transpose] **
  Inputs:
    StatefulPartitionedCall/model/conv2d_93/BiasAdd:0: dtype=FLOAT, shape=[4, 255, 52, 52], mreq=11,032,320
  Outputs:
Transpose__1294:0
    Transpose__1294:0: dtype=FLOAT, shape=[4, 52, 52, 255], mreq=11,032,320
  Node Mreq: 22,064,640 bytes

** Node: Shape__1880 | OpType: Shape] **
  Inputs:
    StatefulPartitionedCall/model/conv2d_93/BiasAdd:0: dtype=FLOAT, shape=[4, 255, 52, 52], mreq=11,032,320
  Outputs:
Shape__1880:0
    Shape__1880:0: dtype=INT64, shape=[4], mreq=32
  Node Mreq: 11,032,352 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_22/LeakyRelu_22 | OpType: LeakyRelu] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_94/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_22/LeakyRelu_22:0
    StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_22/LeakyRelu_22:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,537,792 bytes

** Node: Gather__1883 | OpType: Gather] **
  Inputs:
    Shape__1880:0: dtype=INT64, shape=[4], mreq=32
    Const__1878: dtype=INT32, shape=[4], mreq=16
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_Shape/Shape:0
    StatefulPartitionedCall/model/tf_op_layer_Shape/Shape:0: dtype=INT64, shape=[4], mreq=32
  Node Mreq: 80 bytes

** Node: StatefulPartitionedCall/model/conv2d_96/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_22/LeakyRelu_22:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
    StatefulPartitionedCall/model/conv2d_96/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[512, 256, 3, 3], mreq=4,718,592
    StatefulPartitionedCall/model/conv2d_96/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[512], mreq=2,048
  Outputs:
StatefulPartitionedCall/model/batch_normalization_95/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_95/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 512, 26, 26], mreq=5,537,792
  Node Mreq: 13,027,328 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_Shape/Shape__956 | OpType: Cast] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_Shape/Shape:0: dtype=INT64, shape=[4], mreq=32
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_Shape/Shape__956:0
    StatefulPartitionedCall/model/tf_op_layer_Shape/Shape__956:0: dtype=INT32, shape=[4], mreq=16
  Node Mreq: 48 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_23/LeakyRelu_23 | OpType: LeakyRelu] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_95/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 512, 26, 26], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_23/LeakyRelu_23:0
    StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_23/LeakyRelu_23:0: dtype=FLOAT, shape=[4, 512, 26, 26], mreq=5,537,792
  Node Mreq: 11,075,584 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_strided_slice_1/strided_slice_1 | OpType: Slice] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_Shape/Shape__956:0: dtype=INT32, shape=[4], mreq=16
    const_slice__929: dtype=INT64, shape=[1], mreq=8
    const_slice__930: dtype=INT64, shape=[1], mreq=8
    const_slice__931: dtype=INT64, shape=[1], mreq=8
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_strided_slice_1/strided_slice_1:0
    StatefulPartitionedCall/model/tf_op_layer_strided_slice_1/strided_slice_1:0: dtype=INT32, shape=[1], mreq=4
  Node Mreq: 44 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_strided_slice/strided_slice | OpType: Slice] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_Shape/Shape__956:0: dtype=INT32, shape=[4], mreq=16
    const_slice__931: dtype=INT64, shape=[1], mreq=8
    const_slice__929: dtype=INT64, shape=[1], mreq=8
    const_slice__931: dtype=INT64, shape=[1], mreq=8
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_strided_slice/strided_slice:0
    StatefulPartitionedCall/model/tf_op_layer_strided_slice/strided_slice:0: dtype=INT32, shape=[1], mreq=4
  Node Mreq: 44 bytes

** Node: StatefulPartitionedCall/model/conv2d_97/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_23/LeakyRelu_23:0: dtype=FLOAT, shape=[4, 512, 26, 26], mreq=5,537,792
    StatefulPartitionedCall/model/conv2d_97/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[256, 512, 1, 1], mreq=524,288
    StatefulPartitionedCall/model/conv2d_97/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[256], mreq=1,024
  Outputs:
StatefulPartitionedCall/model/batch_normalization_96/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_96/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 8,832,000 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_Reshape/shape/Reshape/shape_Concat__970 | OpType: Concat] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_strided_slice/strided_slice:0: dtype=INT32, shape=[1], mreq=4
    StatefulPartitionedCall/model/tf_op_layer_strided_slice_1/strided_slice_1:0: dtype=INT32, shape=[1], mreq=4
    StatefulPartitionedCall/model/tf_op_layer_strided_slice_1/strided_slice_1:0: dtype=INT32, shape=[1], mreq=4
    const_fold_opt__2103: dtype=INT32, shape=[1], mreq=4
    const_fold_opt__2099: dtype=INT32, shape=[1], mreq=4
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_Reshape/shape/Reshape/shape_Concat__970:0
    StatefulPartitionedCall/model/tf_op_layer_Reshape/shape/Reshape/shape_Concat__970:0: dtype=INT32, shape=[5], mreq=20
  Node Mreq: 40 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_24/LeakyRelu_24 | OpType: LeakyRelu] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_96/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_24/LeakyRelu_24:0
    StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_24/LeakyRelu_24:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,537,792 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_Reshape/Reshape__971 | OpType: Cast] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_Reshape/shape/Reshape/shape_Concat__970:0: dtype=INT32, shape=[5], mreq=20
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_Reshape/Reshape__971:0
    StatefulPartitionedCall/model/tf_op_layer_Reshape/Reshape__971:0: dtype=INT64, shape=[5], mreq=40
  Node Mreq: 60 bytes

** Node: StatefulPartitionedCall/model/conv2d_98/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_24/LeakyRelu_24:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
    StatefulPartitionedCall/model/conv2d_98/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[512, 256, 3, 3], mreq=4,718,592
    StatefulPartitionedCall/model/conv2d_98/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[512], mreq=2,048
  Outputs:
StatefulPartitionedCall/model/batch_normalization_97/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_97/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 512, 26, 26], mreq=5,537,792
  Node Mreq: 13,027,328 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_Reshape/Reshape | OpType: Reshape] **
  Inputs:
    Transpose__1294:0: dtype=FLOAT, shape=[4, 52, 52, 255], mreq=11,032,320
    StatefulPartitionedCall/model/tf_op_layer_Reshape/Reshape__971:0: dtype=INT64, shape=[5], mreq=40
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_Reshape/Reshape:0
    StatefulPartitionedCall/model/tf_op_layer_Reshape/Reshape:0: dtype=FLOAT, shape=[], mreq=0
  Node Mreq: 11,032,360 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_25/LeakyRelu_25 | OpType: LeakyRelu] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_97/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 512, 26, 26], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_25/LeakyRelu_25:0
    StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_25/LeakyRelu_25:0: dtype=FLOAT, shape=[4, 512, 26, 26], mreq=5,537,792
  Node Mreq: 11,075,584 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_split/split | OpType: Split] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_Reshape/Reshape:0: dtype=FLOAT, shape=[], mreq=0
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_split/split:0
    StatefulPartitionedCall/model/tf_op_layer_split/split:0: dtype=FLOAT, shape=[], mreq=0
StatefulPartitionedCall/model/tf_op_layer_split/split:1
    StatefulPartitionedCall/model/tf_op_layer_split/split:1: dtype=FLOAT, shape=[], mreq=0
StatefulPartitionedCall/model/tf_op_layer_split/split:2
    StatefulPartitionedCall/model/tf_op_layer_split/split:2: dtype=FLOAT, shape=[], mreq=0
  Node Mreq: 0 bytes

** Node: StatefulPartitionedCall/model/conv2d_99/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_25/LeakyRelu_25:0: dtype=FLOAT, shape=[4, 512, 26, 26], mreq=5,537,792
    StatefulPartitionedCall/model/conv2d_99/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[256, 512, 1, 1], mreq=524,288
    StatefulPartitionedCall/model/conv2d_99/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[256], mreq=1,024
  Outputs:
StatefulPartitionedCall/model/batch_normalization_98/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_98/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 8,832,000 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_Sigmoid/Sigmoid | OpType: Sigmoid] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_split/split:1: dtype=FLOAT, shape=[], mreq=0
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_Sigmoid/Sigmoid:0
    StatefulPartitionedCall/model/tf_op_layer_Sigmoid/Sigmoid:0: dtype=FLOAT, shape=[], mreq=0
  Node Mreq: 0 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_Sigmoid_1/Sigmoid_1 | OpType: Sigmoid] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_split/split:2: dtype=FLOAT, shape=[], mreq=0
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_Sigmoid_1/Sigmoid_1:0
    StatefulPartitionedCall/model/tf_op_layer_Sigmoid_1/Sigmoid_1:0: dtype=FLOAT, shape=[], mreq=0
  Node Mreq: 0 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_26/LeakyRelu_26 | OpType: LeakyRelu] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_98/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_26/LeakyRelu_26:0
    StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_26/LeakyRelu_26:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
  Node Mreq: 5,537,792 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_concat_10/concat_10 | OpType: Concat] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_split/split:0: dtype=FLOAT, shape=[], mreq=0
    StatefulPartitionedCall/model/tf_op_layer_Sigmoid/Sigmoid:0: dtype=FLOAT, shape=[], mreq=0
    StatefulPartitionedCall/model/tf_op_layer_Sigmoid_1/Sigmoid_1:0: dtype=FLOAT, shape=[], mreq=0
  Outputs:
Identity:0
    Identity:0: dtype=FLOAT, shape=[4, 4, 4, 3, 85], mreq=65,280
  Node Mreq: 65,280 bytes

** Node: StatefulPartitionedCall/model/conv2d_102/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_26/LeakyRelu_26:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
    StatefulPartitionedCall/model/conv2d_102/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[512, 256, 3, 3], mreq=4,718,592
    StatefulPartitionedCall/model/conv2d_102/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[512], mreq=2,048
  Outputs:
StatefulPartitionedCall/model/batch_normalization_100/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_100/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Node Mreq: 8,873,984 bytes

** Node: StatefulPartitionedCall/model/conv2d_100/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_26/LeakyRelu_26:0: dtype=FLOAT, shape=[4, 256, 26, 26], mreq=2,768,896
    StatefulPartitionedCall/model/conv2d_100/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[512, 256, 3, 3], mreq=4,718,592
    StatefulPartitionedCall/model/conv2d_100/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[512], mreq=2,048
  Outputs:
StatefulPartitionedCall/model/batch_normalization_99/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_99/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 512, 26, 26], mreq=5,537,792
  Node Mreq: 13,027,328 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_28/LeakyRelu_28 | OpType: LeakyRelu] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_100/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_28/LeakyRelu_28:0
    StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_28/LeakyRelu_28:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Node Mreq: 2,768,896 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_27/LeakyRelu_27 | OpType: LeakyRelu] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_99/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 512, 26, 26], mreq=5,537,792
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_27/LeakyRelu_27:0
    StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_27/LeakyRelu_27:0: dtype=FLOAT, shape=[4, 512, 26, 26], mreq=5,537,792
  Node Mreq: 11,075,584 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_concat_9/concat_9 | OpType: Concat] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_28/LeakyRelu_28:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
    StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_5/LeakyRelu_5:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_concat_9/concat_9:0
    StatefulPartitionedCall/model/tf_op_layer_concat_9/concat_9:0: dtype=FLOAT, shape=[4, 1024, 13, 13], mreq=2,768,896
  Node Mreq: 5,537,792 bytes

** Node: StatefulPartitionedCall/model/conv2d_101/BiasAdd | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_27/LeakyRelu_27:0: dtype=FLOAT, shape=[4, 512, 26, 26], mreq=5,537,792
    StatefulPartitionedCall/model/conv2d_101/Conv2D/ReadVariableOp:0: dtype=FLOAT, shape=[255, 512, 1, 1], mreq=522,240
    StatefulPartitionedCall/model/conv2d_101/BiasAdd/ReadVariableOp:0: dtype=FLOAT, shape=[255], mreq=1,020
  Outputs:
StatefulPartitionedCall/model/conv2d_101/BiasAdd:0
    StatefulPartitionedCall/model/conv2d_101/BiasAdd:0: dtype=FLOAT, shape=[4, 255, 26, 26], mreq=2,758,080
  Node Mreq: 8,819,132 bytes

** Node: StatefulPartitionedCall/model/conv2d_103/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_concat_9/concat_9:0: dtype=FLOAT, shape=[4, 1024, 13, 13], mreq=2,768,896
    StatefulPartitionedCall/model/conv2d_103/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[512, 1024, 1, 1], mreq=2,097,152
    StatefulPartitionedCall/model/conv2d_103/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[512], mreq=2,048
  Outputs:
StatefulPartitionedCall/model/batch_normalization_101/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_101/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Node Mreq: 6,252,544 bytes

** Node: Transpose__1290 | OpType: Transpose] **
  Inputs:
    StatefulPartitionedCall/model/conv2d_101/BiasAdd:0: dtype=FLOAT, shape=[4, 255, 26, 26], mreq=2,758,080
  Outputs:
Transpose__1290:0
    Transpose__1290:0: dtype=FLOAT, shape=[4, 26, 26, 255], mreq=2,758,080
  Node Mreq: 5,516,160 bytes

** Node: Shape__1876 | OpType: Shape] **
  Inputs:
    StatefulPartitionedCall/model/conv2d_101/BiasAdd:0: dtype=FLOAT, shape=[4, 255, 26, 26], mreq=2,758,080
  Outputs:
Shape__1876:0
    Shape__1876:0: dtype=INT64, shape=[4], mreq=32
  Node Mreq: 2,758,112 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_29/LeakyRelu_29 | OpType: LeakyRelu] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_101/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_29/LeakyRelu_29:0
    StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_29/LeakyRelu_29:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Node Mreq: 2,768,896 bytes

** Node: Gather__1879 | OpType: Gather] **
  Inputs:
    Shape__1876:0: dtype=INT64, shape=[4], mreq=32
    Const__1878: dtype=INT32, shape=[4], mreq=16
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_Shape_1/Shape_1:0
    StatefulPartitionedCall/model/tf_op_layer_Shape_1/Shape_1:0: dtype=INT64, shape=[4], mreq=32
  Node Mreq: 80 bytes

** Node: StatefulPartitionedCall/model/conv2d_104/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_29/LeakyRelu_29:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
    StatefulPartitionedCall/model/conv2d_104/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[1024, 512, 3, 3], mreq=18,874,368
    StatefulPartitionedCall/model/conv2d_104/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[1024], mreq=4,096
  Outputs:
StatefulPartitionedCall/model/batch_normalization_102/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_102/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 1024, 13, 13], mreq=2,768,896
  Node Mreq: 23,031,808 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_Shape_1/Shape_1__928 | OpType: Cast] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_Shape_1/Shape_1:0: dtype=INT64, shape=[4], mreq=32
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_Shape_1/Shape_1__928:0
    StatefulPartitionedCall/model/tf_op_layer_Shape_1/Shape_1__928:0: dtype=INT32, shape=[4], mreq=16
  Node Mreq: 48 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_30/LeakyRelu_30 | OpType: LeakyRelu] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_102/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 1024, 13, 13], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_30/LeakyRelu_30:0
    StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_30/LeakyRelu_30:0: dtype=FLOAT, shape=[4, 1024, 13, 13], mreq=2,768,896
  Node Mreq: 5,537,792 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_strided_slice_3/strided_slice_3 | OpType: Slice] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_Shape_1/Shape_1__928:0: dtype=INT32, shape=[4], mreq=16
    const_slice__929: dtype=INT64, shape=[1], mreq=8
    const_slice__930: dtype=INT64, shape=[1], mreq=8
    const_slice__931: dtype=INT64, shape=[1], mreq=8
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_strided_slice_3/strided_slice_3:0
    StatefulPartitionedCall/model/tf_op_layer_strided_slice_3/strided_slice_3:0: dtype=INT32, shape=[1], mreq=4
  Node Mreq: 44 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_strided_slice_2/strided_slice_2 | OpType: Slice] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_Shape_1/Shape_1__928:0: dtype=INT32, shape=[4], mreq=16
    const_slice__931: dtype=INT64, shape=[1], mreq=8
    const_slice__929: dtype=INT64, shape=[1], mreq=8
    const_slice__931: dtype=INT64, shape=[1], mreq=8
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_strided_slice_2/strided_slice_2:0
    StatefulPartitionedCall/model/tf_op_layer_strided_slice_2/strided_slice_2:0: dtype=INT32, shape=[1], mreq=4
  Node Mreq: 44 bytes

** Node: StatefulPartitionedCall/model/conv2d_105/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_30/LeakyRelu_30:0: dtype=FLOAT, shape=[4, 1024, 13, 13], mreq=2,768,896
    StatefulPartitionedCall/model/conv2d_105/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[512, 1024, 1, 1], mreq=2,097,152
    StatefulPartitionedCall/model/conv2d_105/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[512], mreq=2,048
  Outputs:
StatefulPartitionedCall/model/batch_normalization_103/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_103/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Node Mreq: 6,252,544 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_Reshape_1/shape/Reshape_1/shape_Concat__942 | OpType: Concat] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_strided_slice_2/strided_slice_2:0: dtype=INT32, shape=[1], mreq=4
    StatefulPartitionedCall/model/tf_op_layer_strided_slice_3/strided_slice_3:0: dtype=INT32, shape=[1], mreq=4
    StatefulPartitionedCall/model/tf_op_layer_strided_slice_3/strided_slice_3:0: dtype=INT32, shape=[1], mreq=4
    const_fold_opt__2103: dtype=INT32, shape=[1], mreq=4
    const_fold_opt__2099: dtype=INT32, shape=[1], mreq=4
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_Reshape_1/shape/Reshape_1/shape_Concat__942:0
    StatefulPartitionedCall/model/tf_op_layer_Reshape_1/shape/Reshape_1/shape_Concat__942:0: dtype=INT32, shape=[5], mreq=20
  Node Mreq: 40 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_31/LeakyRelu_31 | OpType: LeakyRelu] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_103/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_31/LeakyRelu_31:0
    StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_31/LeakyRelu_31:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Node Mreq: 2,768,896 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_Reshape_1/Reshape_1__943 | OpType: Cast] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_Reshape_1/shape/Reshape_1/shape_Concat__942:0: dtype=INT32, shape=[5], mreq=20
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_Reshape_1/Reshape_1__943:0
    StatefulPartitionedCall/model/tf_op_layer_Reshape_1/Reshape_1__943:0: dtype=INT64, shape=[5], mreq=40
  Node Mreq: 60 bytes

** Node: StatefulPartitionedCall/model/conv2d_106/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_31/LeakyRelu_31:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
    StatefulPartitionedCall/model/conv2d_106/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[1024, 512, 3, 3], mreq=18,874,368
    StatefulPartitionedCall/model/conv2d_106/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[1024], mreq=4,096
  Outputs:
StatefulPartitionedCall/model/batch_normalization_104/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_104/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 1024, 13, 13], mreq=2,768,896
  Node Mreq: 23,031,808 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_Reshape_1/Reshape_1 | OpType: Reshape] **
  Inputs:
    Transpose__1290:0: dtype=FLOAT, shape=[4, 26, 26, 255], mreq=2,758,080
    StatefulPartitionedCall/model/tf_op_layer_Reshape_1/Reshape_1__943:0: dtype=INT64, shape=[5], mreq=40
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_Reshape_1/Reshape_1:0
    StatefulPartitionedCall/model/tf_op_layer_Reshape_1/Reshape_1:0: dtype=FLOAT, shape=[], mreq=0
  Node Mreq: 2,758,120 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_32/LeakyRelu_32 | OpType: LeakyRelu] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_104/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 1024, 13, 13], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_32/LeakyRelu_32:0
    StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_32/LeakyRelu_32:0: dtype=FLOAT, shape=[4, 1024, 13, 13], mreq=2,768,896
  Node Mreq: 5,537,792 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_split_1/split_1 | OpType: Split] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_Reshape_1/Reshape_1:0: dtype=FLOAT, shape=[], mreq=0
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_split_1/split_1:0
    StatefulPartitionedCall/model/tf_op_layer_split_1/split_1:0: dtype=FLOAT, shape=[], mreq=0
StatefulPartitionedCall/model/tf_op_layer_split_1/split_1:1
    StatefulPartitionedCall/model/tf_op_layer_split_1/split_1:1: dtype=FLOAT, shape=[], mreq=0
StatefulPartitionedCall/model/tf_op_layer_split_1/split_1:2
    StatefulPartitionedCall/model/tf_op_layer_split_1/split_1:2: dtype=FLOAT, shape=[], mreq=0
  Node Mreq: 0 bytes

** Node: StatefulPartitionedCall/model/conv2d_107/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_32/LeakyRelu_32:0: dtype=FLOAT, shape=[4, 1024, 13, 13], mreq=2,768,896
    StatefulPartitionedCall/model/conv2d_107/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[512, 1024, 1, 1], mreq=2,097,152
    StatefulPartitionedCall/model/conv2d_107/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[512], mreq=2,048
  Outputs:
StatefulPartitionedCall/model/batch_normalization_105/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_105/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Node Mreq: 6,252,544 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_Sigmoid_2/Sigmoid_2 | OpType: Sigmoid] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_split_1/split_1:1: dtype=FLOAT, shape=[], mreq=0
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_Sigmoid_2/Sigmoid_2:0
    StatefulPartitionedCall/model/tf_op_layer_Sigmoid_2/Sigmoid_2:0: dtype=FLOAT, shape=[], mreq=0
  Node Mreq: 0 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_Sigmoid_3/Sigmoid_3 | OpType: Sigmoid] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_split_1/split_1:2: dtype=FLOAT, shape=[], mreq=0
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_Sigmoid_3/Sigmoid_3:0
    StatefulPartitionedCall/model/tf_op_layer_Sigmoid_3/Sigmoid_3:0: dtype=FLOAT, shape=[], mreq=0
  Node Mreq: 0 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_33/LeakyRelu_33 | OpType: LeakyRelu] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_105/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_33/LeakyRelu_33:0
    StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_33/LeakyRelu_33:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
  Node Mreq: 2,768,896 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_concat_11/concat_11 | OpType: Concat] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_split_1/split_1:0: dtype=FLOAT, shape=[], mreq=0
    StatefulPartitionedCall/model/tf_op_layer_Sigmoid_2/Sigmoid_2:0: dtype=FLOAT, shape=[], mreq=0
    StatefulPartitionedCall/model/tf_op_layer_Sigmoid_3/Sigmoid_3:0: dtype=FLOAT, shape=[], mreq=0
  Outputs:
Identity_1:0
    Identity_1:0: dtype=FLOAT, shape=[4, 4, 4, 3, 85], mreq=65,280
  Node Mreq: 65,280 bytes

** Node: StatefulPartitionedCall/model/conv2d_108/Conv2D | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_33/LeakyRelu_33:0: dtype=FLOAT, shape=[4, 512, 13, 13], mreq=1,384,448
    StatefulPartitionedCall/model/conv2d_108/Conv2D_weights_fused_bn: dtype=FLOAT, shape=[1024, 512, 3, 3], mreq=18,874,368
    StatefulPartitionedCall/model/conv2d_108/Conv2D_bias_fused_bn: dtype=FLOAT, shape=[1024], mreq=4,096
  Outputs:
StatefulPartitionedCall/model/batch_normalization_106/FusedBatchNormV3:0
    StatefulPartitionedCall/model/batch_normalization_106/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 1024, 13, 13], mreq=2,768,896
  Node Mreq: 23,031,808 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_34/LeakyRelu_34 | OpType: LeakyRelu] **
  Inputs:
    StatefulPartitionedCall/model/batch_normalization_106/FusedBatchNormV3:0: dtype=FLOAT, shape=[4, 1024, 13, 13], mreq=2,768,896
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_34/LeakyRelu_34:0
    StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_34/LeakyRelu_34:0: dtype=FLOAT, shape=[4, 1024, 13, 13], mreq=2,768,896
  Node Mreq: 5,537,792 bytes

** Node: StatefulPartitionedCall/model/conv2d_109/BiasAdd | OpType: Conv] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_LeakyRelu_34/LeakyRelu_34:0: dtype=FLOAT, shape=[4, 1024, 13, 13], mreq=2,768,896
    StatefulPartitionedCall/model/conv2d_109/Conv2D/ReadVariableOp:0: dtype=FLOAT, shape=[255, 1024, 1, 1], mreq=1,044,480
    StatefulPartitionedCall/model/conv2d_109/BiasAdd/ReadVariableOp:0: dtype=FLOAT, shape=[255], mreq=1,020
  Outputs:
StatefulPartitionedCall/model/conv2d_109/BiasAdd:0
    StatefulPartitionedCall/model/conv2d_109/BiasAdd:0: dtype=FLOAT, shape=[4, 255, 13, 13], mreq=689,520
  Node Mreq: 4,503,916 bytes

** Node: Transpose__1286 | OpType: Transpose] **
  Inputs:
    StatefulPartitionedCall/model/conv2d_109/BiasAdd:0: dtype=FLOAT, shape=[4, 255, 13, 13], mreq=689,520
  Outputs:
Transpose__1286:0
    Transpose__1286:0: dtype=FLOAT, shape=[4, 13, 13, 255], mreq=689,520
  Node Mreq: 1,379,040 bytes

** Node: Shape__1872 | OpType: Shape] **
  Inputs:
    StatefulPartitionedCall/model/conv2d_109/BiasAdd:0: dtype=FLOAT, shape=[4, 255, 13, 13], mreq=689,520
  Outputs:
Shape__1872:0
    Shape__1872:0: dtype=INT64, shape=[4], mreq=32
  Node Mreq: 689,552 bytes

** Node: Gather__1875 | OpType: Gather] **
  Inputs:
    Shape__1872:0: dtype=INT64, shape=[4], mreq=32
    Const__1878: dtype=INT32, shape=[4], mreq=16
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_Shape_2/Shape_2:0
    StatefulPartitionedCall/model/tf_op_layer_Shape_2/Shape_2:0: dtype=INT64, shape=[4], mreq=32
  Node Mreq: 80 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_Shape_2/Shape_2__900 | OpType: Cast] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_Shape_2/Shape_2:0: dtype=INT64, shape=[4], mreq=32
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_Shape_2/Shape_2__900:0
    StatefulPartitionedCall/model/tf_op_layer_Shape_2/Shape_2__900:0: dtype=INT32, shape=[4], mreq=16
  Node Mreq: 48 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_strided_slice_5/strided_slice_5 | OpType: Slice] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_Shape_2/Shape_2__900:0: dtype=INT32, shape=[4], mreq=16
    const_slice__929: dtype=INT64, shape=[1], mreq=8
    const_slice__930: dtype=INT64, shape=[1], mreq=8
    const_slice__931: dtype=INT64, shape=[1], mreq=8
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_strided_slice_5/strided_slice_5:0
    StatefulPartitionedCall/model/tf_op_layer_strided_slice_5/strided_slice_5:0: dtype=INT32, shape=[1], mreq=4
  Node Mreq: 44 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_strided_slice_4/strided_slice_4 | OpType: Slice] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_Shape_2/Shape_2__900:0: dtype=INT32, shape=[4], mreq=16
    const_slice__931: dtype=INT64, shape=[1], mreq=8
    const_slice__929: dtype=INT64, shape=[1], mreq=8
    const_slice__931: dtype=INT64, shape=[1], mreq=8
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_strided_slice_4/strided_slice_4:0
    StatefulPartitionedCall/model/tf_op_layer_strided_slice_4/strided_slice_4:0: dtype=INT32, shape=[1], mreq=4
  Node Mreq: 44 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_Reshape_2/shape/Reshape_2/shape_Concat__914 | OpType: Concat] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_strided_slice_4/strided_slice_4:0: dtype=INT32, shape=[1], mreq=4
    StatefulPartitionedCall/model/tf_op_layer_strided_slice_5/strided_slice_5:0: dtype=INT32, shape=[1], mreq=4
    StatefulPartitionedCall/model/tf_op_layer_strided_slice_5/strided_slice_5:0: dtype=INT32, shape=[1], mreq=4
    const_fold_opt__2103: dtype=INT32, shape=[1], mreq=4
    const_fold_opt__2099: dtype=INT32, shape=[1], mreq=4
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_Reshape_2/shape/Reshape_2/shape_Concat__914:0
    StatefulPartitionedCall/model/tf_op_layer_Reshape_2/shape/Reshape_2/shape_Concat__914:0: dtype=INT32, shape=[5], mreq=20
  Node Mreq: 40 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_Reshape_2/Reshape_2__915 | OpType: Cast] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_Reshape_2/shape/Reshape_2/shape_Concat__914:0: dtype=INT32, shape=[5], mreq=20
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_Reshape_2/Reshape_2__915:0
    StatefulPartitionedCall/model/tf_op_layer_Reshape_2/Reshape_2__915:0: dtype=INT64, shape=[5], mreq=40
  Node Mreq: 60 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_Reshape_2/Reshape_2 | OpType: Reshape] **
  Inputs:
    Transpose__1286:0: dtype=FLOAT, shape=[4, 13, 13, 255], mreq=689,520
    StatefulPartitionedCall/model/tf_op_layer_Reshape_2/Reshape_2__915:0: dtype=INT64, shape=[5], mreq=40
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_Reshape_2/Reshape_2:0
    StatefulPartitionedCall/model/tf_op_layer_Reshape_2/Reshape_2:0: dtype=FLOAT, shape=[], mreq=0
  Node Mreq: 689,560 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_split_2/split_2 | OpType: Split] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_Reshape_2/Reshape_2:0: dtype=FLOAT, shape=[], mreq=0
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_split_2/split_2:0
    StatefulPartitionedCall/model/tf_op_layer_split_2/split_2:0: dtype=FLOAT, shape=[], mreq=0
StatefulPartitionedCall/model/tf_op_layer_split_2/split_2:1
    StatefulPartitionedCall/model/tf_op_layer_split_2/split_2:1: dtype=FLOAT, shape=[], mreq=0
StatefulPartitionedCall/model/tf_op_layer_split_2/split_2:2
    StatefulPartitionedCall/model/tf_op_layer_split_2/split_2:2: dtype=FLOAT, shape=[], mreq=0
  Node Mreq: 0 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_Sigmoid_4/Sigmoid_4 | OpType: Sigmoid] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_split_2/split_2:1: dtype=FLOAT, shape=[], mreq=0
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_Sigmoid_4/Sigmoid_4:0
    StatefulPartitionedCall/model/tf_op_layer_Sigmoid_4/Sigmoid_4:0: dtype=FLOAT, shape=[], mreq=0
  Node Mreq: 0 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_Sigmoid_5/Sigmoid_5 | OpType: Sigmoid] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_split_2/split_2:2: dtype=FLOAT, shape=[], mreq=0
  Outputs:
StatefulPartitionedCall/model/tf_op_layer_Sigmoid_5/Sigmoid_5:0
    StatefulPartitionedCall/model/tf_op_layer_Sigmoid_5/Sigmoid_5:0: dtype=FLOAT, shape=[], mreq=0
  Node Mreq: 0 bytes

** Node: StatefulPartitionedCall/model/tf_op_layer_concat_12/concat_12 | OpType: Concat] **
  Inputs:
    StatefulPartitionedCall/model/tf_op_layer_split_2/split_2:0: dtype=FLOAT, shape=[], mreq=0
    StatefulPartitionedCall/model/tf_op_layer_Sigmoid_4/Sigmoid_4:0: dtype=FLOAT, shape=[], mreq=0
    StatefulPartitionedCall/model/tf_op_layer_Sigmoid_5/Sigmoid_5:0: dtype=FLOAT, shape=[], mreq=0
  Outputs:
Identity_2:0
    Identity_2:0: dtype=FLOAT, shape=[4, 4, 4, 3, 85], mreq=65,280
  Node Mreq: 65,280 bytes

Maximum memory requirement for the model: 265,814,016 bytes (259584.00 KB / 253.50 MB)
